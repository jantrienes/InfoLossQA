[{"data": {"doc_id": 1618957, "edit_id": "75f990fc0055538f63a86ff8168f6dfa", "source": "OBJECTIVE AND DESIGN.\nDepot somatostatin analogues are well accepted as either adjuvant or primary therapy for acromegaly, and their long dosage intervals facilitate adherence to treatment. Our objective was to evaluate whether lanreotide Autogel\u00ae 120 mg, every 4\u20138 weeks, was as effective in controlling acromegaly as lanreotide microparticles 30 mg, every 1\u20132 weeks.\n\nPATIENTS DESIGN AND MEASUREMENTS.\nPatients who had used lanreotide microparticles 30 mg, \u2265 2 months prestudy, and had responded to treatment were recruited to this open, prospective, multicentre phase III trial. Three to five injections of lanreotide Autogel\u00ae 120 mg were administered. Lanreotide Autogel\u00ae 120 mg was injected every 4, 6 or 8 weeks in patients previously receiving lanreotide microparticles every 7, 10 or 14 days, respectively. GH and insulin-like growth factor (IGF)-1 levels were assessed one dosing interval after the final injections.\n\nRESULTS.\nNinety-eight patients were enrolled and 93 completed. Steady-state GH concentrations demonstrated similar efficacy between the formulations (upper 95% confidence interval of the quotient, 77\u00b77%). Mean (SE) GH levels were lower with lanreotide Autogel\u00ae than with lanreotide microparticles (3\u00b78 (0\u00b75) vs 4\u00b73 (0\u00b75) ng/ml; P < 0\u00b7001). GH levels < 2\u00b75 ng/ml were observed in 54% and 46% of patients; 40% and 35% having GH < 2\u00b75 ng/ml and normalized IGF-1 with lanreotide Autogel\u00ae and microparticles, respectively. Symptoms were controlled better with lanreotide Autogel\u00ae and treatment was well accepted.\n\nCONCLUSIONS.\nLanreotide Autogel\u00ae 120 mg every 4\u20138 weeks, is at least as effective and as well tolerated in acromegaly as lanreotide microparticles 30 mg injected every 7\u201314 days.", "target": "GOAL AND PLAN\nThe goal of this study was to see if giving lanreotide Autogel\u00ae 120 mg every 4 to 8 weeks worked as well as giving lanreotide microparticles 30 mg every week or two for treating acromegaly, a condition that makes the body produce too much growth hormone. Giving medicine less often could make it easier for people to stick with treatment.\n\nSTUDY DESIGN AND WHAT WE MEASURED.\nWe asked people to join this study if they had been using lanreotide microparticles 30 mg in the past, and it had worked for them. We gave the patients 3 to 5 shots of lanreotide Autogel\u00ae 120 mg. If they had been getting lanreotide microparticles each week before the study, we gave them lanreotide autogel\u00ae every 4 weeks. We adjusted the timing based on how often they were getting their old medication. We checked their growth hormone and insulin-like growth factor-1 levels after their last shots.\n\nWHAT WE FOUND.\nNinety-eight patients joined the study and 93 finished it. The amount of growth hormone in their bodies showed that both formulas worked about the same. On average, the growth hormone levels were slightly lower with the Autogel\u00ae than the microparticles. Symptoms were better controlled with the Autogel\u00ae and patients were happy with the treatment.\n\nCONCLUSIONS.\nUsing lanreotide Autogel\u00ae 120 mg every 4 to 8 weeks works just as well and is as well tolerated as using lanreotide microparticles 30 mg every one to two weeks in treating acromegaly.", "question": "Was the difference in GH levels between the two formulations statistically significant?", "answer": "Yes, the difference in GH levels between the two formulations was statistically significant (P < 0\u00b7001)."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 1132, "end": 1265, "score": 1, "text": "Mean (SE) GH levels were lower with lanreotide Autogel\u00ae than with lanreotide microparticles (3\u00b78 (0\u00b75) vs 4\u00b73 (0\u00b75) ng/ml; P < 0\u00b7001)", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 1059, "end": 1158, "score": 1, "text": "On average, the growth hormone levels were slightly lower with the Autogel\u00ae than the microparticles", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 1618957, "edit_id": "3de436104812f90014fd1360881e4ec4", "source": "OBJECTIVE AND DESIGN.\nDepot somatostatin analogues are well accepted as either adjuvant or primary therapy for acromegaly, and their long dosage intervals facilitate adherence to treatment. Our objective was to evaluate whether lanreotide Autogel\u00ae 120 mg, every 4\u20138 weeks, was as effective in controlling acromegaly as lanreotide microparticles 30 mg, every 1\u20132 weeks.\n\nPATIENTS DESIGN AND MEASUREMENTS.\nPatients who had used lanreotide microparticles 30 mg, \u2265 2 months prestudy, and had responded to treatment were recruited to this open, prospective, multicentre phase III trial. Three to five injections of lanreotide Autogel\u00ae 120 mg were administered. Lanreotide Autogel\u00ae 120 mg was injected every 4, 6 or 8 weeks in patients previously receiving lanreotide microparticles every 7, 10 or 14 days, respectively. GH and insulin-like growth factor (IGF)-1 levels were assessed one dosing interval after the final injections.\n\nRESULTS.\nNinety-eight patients were enrolled and 93 completed. Steady-state GH concentrations demonstrated similar efficacy between the formulations (upper 95% confidence interval of the quotient, 77\u00b77%). Mean (SE) GH levels were lower with lanreotide Autogel\u00ae than with lanreotide microparticles (3\u00b78 (0\u00b75) vs 4\u00b73 (0\u00b75) ng/ml; P < 0\u00b7001). GH levels < 2\u00b75 ng/ml were observed in 54% and 46% of patients; 40% and 35% having GH < 2\u00b75 ng/ml and normalized IGF-1 with lanreotide Autogel\u00ae and microparticles, respectively. Symptoms were controlled better with lanreotide Autogel\u00ae and treatment was well accepted.\n\nCONCLUSIONS.\nLanreotide Autogel\u00ae 120 mg every 4\u20138 weeks, is at least as effective and as well tolerated in acromegaly as lanreotide microparticles 30 mg injected every 7\u201314 days.", "target": "GOAL AND PLAN\nThe goal of this study was to see if giving lanreotide Autogel\u00ae 120 mg every 4 to 8 weeks worked as well as giving lanreotide microparticles 30 mg every week or two for treating acromegaly, a condition that makes the body produce too much growth hormone. Giving medicine less often could make it easier for people to stick with treatment.\n\nSTUDY DESIGN AND WHAT WE MEASURED.\nWe asked people to join this study if they had been using lanreotide microparticles 30 mg in the past, and it had worked for them. We gave the patients 3 to 5 shots of lanreotide Autogel\u00ae 120 mg. If they had been getting lanreotide microparticles each week before the study, we gave them lanreotide autogel\u00ae every 4 weeks. We adjusted the timing based on how often they were getting their old medication. We checked their growth hormone and insulin-like growth factor-1 levels after their last shots.\n\nWHAT WE FOUND.\nNinety-eight patients joined the study and 93 finished it. The amount of growth hormone in their bodies showed that both formulas worked about the same. On average, the growth hormone levels were slightly lower with the Autogel\u00ae than the microparticles. Symptoms were better controlled with the Autogel\u00ae and patients were happy with the treatment.\n\nCONCLUSIONS.\nUsing lanreotide Autogel\u00ae 120 mg every 4 to 8 weeks works just as well and is as well tolerated as using lanreotide microparticles 30 mg every one to two weeks in treating acromegaly.", "question": "Is it a mistake that both 54% and 46% of patients had growth hormone levels less than 2.5 ng/ml?", "answer": "It seems like a contradiction but it's not. The study is stating that in 54% of patients treated with lanreotide-Autogel\u00ae and in 46% of patients treated with lanreotide microparticles, growth hormone levels were lower than 2.5 ng/ml."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 1267, "end": 1444, "score": 1, "text": "GH levels < 2\u00b75 ng/ml were observed in 54% and 46% of patients; 40% and 35% having GH < 2\u00b75 ng/ml and normalized IGF-1 with lanreotide Autogel\u00ae and microparticles, respectively.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 1618957, "edit_id": "b00c02d3a2bc54a7bc05caab7f92d601", "source": "OBJECTIVE AND DESIGN.\nDepot somatostatin analogues are well accepted as either adjuvant or primary therapy for acromegaly, and their long dosage intervals facilitate adherence to treatment. Our objective was to evaluate whether lanreotide Autogel\u00ae 120 mg, every 4\u20138 weeks, was as effective in controlling acromegaly as lanreotide microparticles 30 mg, every 1\u20132 weeks.\n\nPATIENTS DESIGN AND MEASUREMENTS.\nPatients who had used lanreotide microparticles 30 mg, \u2265 2 months prestudy, and had responded to treatment were recruited to this open, prospective, multicentre phase III trial. Three to five injections of lanreotide Autogel\u00ae 120 mg were administered. Lanreotide Autogel\u00ae 120 mg was injected every 4, 6 or 8 weeks in patients previously receiving lanreotide microparticles every 7, 10 or 14 days, respectively. GH and insulin-like growth factor (IGF)-1 levels were assessed one dosing interval after the final injections.\n\nRESULTS.\nNinety-eight patients were enrolled and 93 completed. Steady-state GH concentrations demonstrated similar efficacy between the formulations (upper 95% confidence interval of the quotient, 77\u00b77%). Mean (SE) GH levels were lower with lanreotide Autogel\u00ae than with lanreotide microparticles (3\u00b78 (0\u00b75) vs 4\u00b73 (0\u00b75) ng/ml; P < 0\u00b7001). GH levels < 2\u00b75 ng/ml were observed in 54% and 46% of patients; 40% and 35% having GH < 2\u00b75 ng/ml and normalized IGF-1 with lanreotide Autogel\u00ae and microparticles, respectively. Symptoms were controlled better with lanreotide Autogel\u00ae and treatment was well accepted.\n\nCONCLUSIONS.\nLanreotide Autogel\u00ae 120 mg every 4\u20138 weeks, is at least as effective and as well tolerated in acromegaly as lanreotide microparticles 30 mg injected every 7\u201314 days.", "target": "GOAL AND PLAN\nThe goal of this study was to see if giving lanreotide Autogel\u00ae 120 mg every 4 to 8 weeks worked as well as giving lanreotide microparticles 30 mg every week or two for treating acromegaly, a condition that makes the body produce too much growth hormone. Giving medicine less often could make it easier for people to stick with treatment.\n\nSTUDY DESIGN AND WHAT WE MEASURED.\nWe asked people to join this study if they had been using lanreotide microparticles 30 mg in the past, and it had worked for them. We gave the patients 3 to 5 shots of lanreotide Autogel\u00ae 120 mg. If they had been getting lanreotide microparticles each week before the study, we gave them lanreotide autogel\u00ae every 4 weeks. We adjusted the timing based on how often they were getting their old medication. We checked their growth hormone and insulin-like growth factor-1 levels after their last shots.\n\nWHAT WE FOUND.\nNinety-eight patients joined the study and 93 finished it. The amount of growth hormone in their bodies showed that both formulas worked about the same. On average, the growth hormone levels were slightly lower with the Autogel\u00ae than the microparticles. Symptoms were better controlled with the Autogel\u00ae and patients were happy with the treatment.\n\nCONCLUSIONS.\nUsing lanreotide Autogel\u00ae 120 mg every 4 to 8 weeks works just as well and is as well tolerated as using lanreotide microparticles 30 mg every one to two weeks in treating acromegaly.", "question": "Who were the participants in the study?", "answer": "The participants were people who had been using lanreotide microparticles 30 mg for at least 2 months and had responded to treatment."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 404, "end": 581, "score": 1, "text": "Patients who had used lanreotide microparticles 30 mg, \u2265 2 months prestudy, and had responded to treatment were recruited to this open, prospective, multicentre phase III trial.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 1868720, "edit_id": "ffc76a6e5426e7c8f323f3d226898594", "source": "BACKGROUND.\nIt is unclear if objective selection of employees, for an intervention to prevent sickness absence, is more effective than subjective 'personal enlistment'. We hypothesize that objectively selected employees are 'at risk' for sickness absence and eligible to participate in the intervention program.\n\nMETHODS.\nThe dispatch of 8603 screening instruments forms the starting point of the objective selection process. Different stages of this process, throughout which employees either dropped out or were excluded, were described and compared with the subjective selection process. Characteristics of ineligible and ultimately selected employees, for a randomized trial, were described and quantified using sickness absence data.\n\nRESULTS.\nOverall response rate on the screening instrument was 42.0%. Response bias was found for the parameters sex and age, but not for sickness absence. Sickness absence was higher in the 'at risk' (N = 212) group (42%) compared to the 'not at risk' (N = 2503) group (25%) (OR 2.17 CI 1.63\u20132.89; p = 0.000). The selection process ended with the successful inclusion of 151 eligible, i.e. 2% of the approached employees in the trial.\n\nCONCLUSION.\nThe study shows that objective selection of employees for early intervention is effective. Despite methodological and practical problems, selected employees are actually those at risk for sickness absence, who will probably benefit more from the intervention program than others.", "target": "BACKGROUND.\nThis study looks at if picking workers based on certain facts (objective) for a program meant to stop them from taking sick days is better than just choosing them based on a hunch (subjective). The researchers think that those chosen based on solid evidence are more likely to be at risk of taking sick days, making them the ideal candidates for the program.\n\nMETHODS.\nThe researchers started by sending out 8603 surveys to begin the evidence-based selection process. They detailed and compared the different steps in this process, which involved some workers not completing the process or being ruled out, to the hunch-based selection. They studied and noted down certain characteristics of the workers who couldn't join and those who were eventually chosen for a test experiment using data regarding sick leave.\n\nRESULTS.\nThe overall response to the survey was 42.0%. There was bias in answering the survey when it came to sex and age, but not for sick leave. The rate of sick leave was higher in the 'at risk' group (42%) as compared to the 'not at risk' group (25%). The selection process ended successfully with 151 workers, or 2% of those contacted, included in the test.\n\nCONCLUSION.\nThe study found that selecting workers for this kind of program based on solid evidence is effective. Even though they faced some challenges, the researchers were able to find that the workers picked were genuinely those at risk of taking sick leave. These workers are likely to benefit more from the program than others.", "question": "How many workers were in the 'at risk' group as per the study's classification?", "answer": "The 'at risk' group consisted of 212 workers."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 896, "end": 1050, "score": 1, "text": "Sickness absence was higher in the 'at risk' (N = 212) group (42%) compared to the 'not at risk' (N = 2503) group (25%) (OR 2.17 CI 1.63\u20132.89; p = 0.000).", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 2430614, "edit_id": "c256ed647af904739fb981f05f6c831c", "source": "BACKGROUND.\nArtesunate+amodiaquine (AS+AQ) and artemether-lumefantrine (AL) are now the most frequently recommended first line treatments for uncomplicated malaria in Africa. Artesunate+chlorproguanil-dapsone (AS+CD) was a potential alternative for treatment of uncomplicated malaria. A comparison of the efficacy and safety of these three drug combinations was necessary to make evidence based drug treatment policies.\n\nMETHODS.\nFive hundred and thirty-four, glucose-6-phosphate dehydrogenase (G6PD) normal children were randomised in blocks of 15 to the AS+AQ, AL or AS+CD groups. Administration of study drugs was supervised by project staff and the children were followed up at r home on days 1,2,3,7,14 and 28 post treatment. Parasitological and clinical failures and adverse events were compared between the study groups.\n\nMAIN FINDINGS.\nIn a per-protocol analysis, the parasitological and clinical failure rate at day 28 post treatment (PCF28) was lower in the AS+AQ group compared to the AL or AS+CD groups (corrected for re-infections: 6.6% vs 13.8% and 13.8% respectively, p = 0.08; uncorrected: 14.6% vs 27.6% and 28.1% respectively, p = 0.005). In the intention to treat analysis, the rate of early treatment failure was high in all three groups (AS+AQ 13.3%; AL 15.2%; and AS+CD 9.3%, p = 0.2) primarily due to vomiting. However, the PCF28 corrected for re-infection was lower, though not significantly, in the AS+AQ group compared to the AL or the AS+CD groups (AS+AQ 18.3%; AL 24.2%; AS+CD 20.8%, p = 0.4) The incidence of adverse events was comparable between the groups.\n\nCONCLUSIONS.\nAS+AQ is an appropriate first line treatment for uncomplicated malaria in Ghana and possibly in the neighbouring countries in West Africa. The effectiveness of AL in routine programme conditions needs to be studied further in West Africa.\n\nTRIAL REGISTRATION.\nClinicalTrials.gov NCT00119145", "target": "BACKGROUND.\nThis study is about comparing three different drug combinations used to treat uncomplicated malaria. These combinations are Artesunate+amodiaquine (AS+AQ), artemether-lumefantrine (AL), and Artesunate+chlorproguanil-dapsone (AS+CD). Comparing the effectiveness and safety of these treatments will help make decisions about which medication to recommend for treating malaria.\n\nMETHODS.\nWe tested these three combinations on 534 children who were otherwise healthy. The children were divided into three groups, each receiving one of the drug combinations. They were watched closely by our project staff who delivered the medicines. We checked on them several times after the treatment - 1, 2, 3, 7, 14, and 28 days later. We were looking for whether the medication failed to get rid of the malaria, and if any child had negative side effects from the medication.\n\nMAIN FINDINGS.\nWhen comparing the results, less children in the AS+AQ group had failed treatments and signs of malaria compared to the other two groups. However, many children in all three groups threw up after taking the medication. It should be noted that the AS+AQ group's treatment failure rate was lower, though not significantly. It also helps to know, the overall rate of side effects was similar in all groups.\n\nCONCLUSIONS.\nBased on our findings, AS+AQ seems to be a suitable first choice for treating uncomplicated malaria in Ghana or in West African countries. The effectiveness of the AL combination needs to be further studied in this region.\n\nTRIAL REGISTRATION.\nThe trial is registered at ClinicalTrials.gov with the registration number NCT00119145.", "question": "What was the health condition of the children who participated in the study?", "answer": "The children who participated in the study were otherwise healthy and had normal levels of glucose-6-phosphate dehydrogenase (G6PD), an enzyme that helps red blood cells function properly."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 430, "end": 516, "score": 1, "text": "Five hundred and thirty-four, glucose-6-phosphate dehydrogenase (G6PD) normal children", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 2882922, "edit_id": "4e41aaac8d66fd15b61d867d13ab4b6d", "source": "BACKGROUND.\nA population of breast cancer patients exists who, for various reasons, never received adjuvant post-operative tamoxifen (TAM). This study was aimed to evaluate the role of late TAM in these patients.\n\nMETHODS.\nFrom 1997 to 2003, patients aged 35 to 75 years, operated more than 2 years previously for monolateral breast cancer without adjuvant TAM, with no signs of metastases and no contraindication to TAM were randomized to TAM 20 mg/day orally for 2 years or follow-up alone. Events were categorized as locoregional relapse, distant metastases, metachronous breast cancer, tumours other than breast cancer and death from any causes, whichever occurred first. The sample size (197 patients per arm, plus 10% allowance) was based on the assumption of a 30% decrease in the number of events occurring at a rate of 5% annually in the 10 years following randomization. Four hundred and thirty-three patients were randomized in the study (TAM 217, follow-up 216). Patients characteristics (TAM/follow-up) included: median age 55/55 years, median time from surgery 25/25 months (range, 25-288/25-294), in situ carcinoma 18/24, oestrogen receptor (ER) positive in 75/68, negative in 70/57, unknown in 72/91 patients. Previous adjuvant treatment included chemotherapy in 131/120 and an LHRH analogue in 11/13 patients.\n\nRESULTS.\nThirty-six patients prematurely discontinued TAM after a median of 1 month, mostly because of subjective intolerance. Eighty-three events (TAM 39, follow-up 44) occurred: locoregional relapse in 10/8, distant metastases in 14/16, metachronous breast cancer in 4/10, other tumours in 11/10 patients. Less ER-positive secondary breast cancers occurred in the TAM treated patients than in follow-up patients (1 vs 10, p = 0.005). Event-free survival was similar in both groups of patients.\n\nCONCLUSIONS.\nThis 5-year analysis revealed significantly less metachronous ER-positive breast cancers in the TAM treated patients. No other statistically significant differences have emerged thus far.", "target": "BACKGROUND.\nThis study looked at breast cancer patients who, for different reasons, didn't receive a common follow-up treatment called Tamoxifen after their surgery. The aim was to see what role, if any, Tamoxifen could still play for these patients if given later.\n\nMETHODS.\nBetween 1997 and 2003, we looked at patients aged 35-75 who had had surgery for one-sided breast cancer more than 2 years before. These patients didn't have any signs of the cancer spreading and were healthy enough to take Tamoxifen. They were split into two groups: one received 20 mg/day of Tamoxifen for two years, and the other did not. We tracked various outcomes including local and distant cancer recurrence, new breast cancers, other types of cancer, and death. We based our sample size on the hypothesis that taking Tamoxifen would result in 30% fewer events occurring over 10 years. The study included 433 people, 217 took Tamoxifen while 216 did not. The patient's characteristics were very similar in both groups.\n\nRESULTS.\nThirty-six patients stopped taking Tamoxifen after about a month, mainly due to not tolerating it well. Eighty-three significant events occurred: 10 local and 16 distant cancer recurrences, 14 new breast cancers, and 21 other cancers. In the Tamoxifen group, fewer patients developed new estrogen-receptor positive breast cancers (1 vs 10). However, the two groups showed similar overall health progress.\n\nCONCLUSIONS.\nThe 5-year analysis showed that fewer patients in the Tamoxifen group developed new estrogen-receptor positive cancers. We didn't, however, see any other significant differences between the two groups.", "question": "What were the outcomes that were tracked in the study?", "answer": "The study tracked various outcomes including local and distant cancer recurrence, new breast cancers, other types of cancer, and death."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 493, "end": 675, "score": 1, "text": "Events were categorized as locoregional relapse, distant metastases, metachronous breast cancer, tumours other than breast cancer and death from any causes, whichever occurred first.", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 617, "end": 745, "score": 1, "text": "We tracked various outcomes including local and distant cancer recurrence, new breast cancers, other types of cancer, and death.", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 2882922, "edit_id": "7f36d82f7b48f87ae13b1060c35ca2cb", "source": "BACKGROUND.\nA population of breast cancer patients exists who, for various reasons, never received adjuvant post-operative tamoxifen (TAM). This study was aimed to evaluate the role of late TAM in these patients.\n\nMETHODS.\nFrom 1997 to 2003, patients aged 35 to 75 years, operated more than 2 years previously for monolateral breast cancer without adjuvant TAM, with no signs of metastases and no contraindication to TAM were randomized to TAM 20 mg/day orally for 2 years or follow-up alone. Events were categorized as locoregional relapse, distant metastases, metachronous breast cancer, tumours other than breast cancer and death from any causes, whichever occurred first. The sample size (197 patients per arm, plus 10% allowance) was based on the assumption of a 30% decrease in the number of events occurring at a rate of 5% annually in the 10 years following randomization. Four hundred and thirty-three patients were randomized in the study (TAM 217, follow-up 216). Patients characteristics (TAM/follow-up) included: median age 55/55 years, median time from surgery 25/25 months (range, 25-288/25-294), in situ carcinoma 18/24, oestrogen receptor (ER) positive in 75/68, negative in 70/57, unknown in 72/91 patients. Previous adjuvant treatment included chemotherapy in 131/120 and an LHRH analogue in 11/13 patients.\n\nRESULTS.\nThirty-six patients prematurely discontinued TAM after a median of 1 month, mostly because of subjective intolerance. Eighty-three events (TAM 39, follow-up 44) occurred: locoregional relapse in 10/8, distant metastases in 14/16, metachronous breast cancer in 4/10, other tumours in 11/10 patients. Less ER-positive secondary breast cancers occurred in the TAM treated patients than in follow-up patients (1 vs 10, p = 0.005). Event-free survival was similar in both groups of patients.\n\nCONCLUSIONS.\nThis 5-year analysis revealed significantly less metachronous ER-positive breast cancers in the TAM treated patients. No other statistically significant differences have emerged thus far.", "target": "BACKGROUND.\nThis study looked at breast cancer patients who, for different reasons, didn't receive a common follow-up treatment called Tamoxifen after their surgery. The aim was to see what role, if any, Tamoxifen could still play for these patients if given later.\n\nMETHODS.\nBetween 1997 and 2003, we looked at patients aged 35-75 who had had surgery for one-sided breast cancer more than 2 years before. These patients didn't have any signs of the cancer spreading and were healthy enough to take Tamoxifen. They were split into two groups: one received 20 mg/day of Tamoxifen for two years, and the other did not. We tracked various outcomes including local and distant cancer recurrence, new breast cancers, other types of cancer, and death. We based our sample size on the hypothesis that taking Tamoxifen would result in 30% fewer events occurring over 10 years. The study included 433 people, 217 took Tamoxifen while 216 did not. The patient's characteristics were very similar in both groups.\n\nRESULTS.\nThirty-six patients stopped taking Tamoxifen after about a month, mainly due to not tolerating it well. Eighty-three significant events occurred: 10 local and 16 distant cancer recurrences, 14 new breast cancers, and 21 other cancers. In the Tamoxifen group, fewer patients developed new estrogen-receptor positive breast cancers (1 vs 10). However, the two groups showed similar overall health progress.\n\nCONCLUSIONS.\nThe 5-year analysis showed that fewer patients in the Tamoxifen group developed new estrogen-receptor positive cancers. We didn't, however, see any other significant differences between the two groups.", "question": "How many patients were in each group?", "answer": "There were 217 patients in the TAM group and 216 patients in the follow-up group."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 950, "end": 972, "score": 1, "text": "TAM 217, follow-up 216", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 3136370, "edit_id": "2b0210e7290d757cab5874eba223b2d9", "source": "Most patients with fibromyalgia use complementary and alternative medicine (CAM). Properly designed controlled trials are necessary to assess the effectiveness of these practices. This study was a randomized, double-blind, placebo-controlled, early phase trial. Fifty patients seen at a fibromyalgia outpatient treatment program were randomly assigned to a daily soy or placebo (casein) shake. Outcome measures were scores of the Fibromyalgia Impact Questionnaire (FIQ) and the Center for Epidemiologic Studies Depression Scale (CES-D) at baseline and after 6 weeks of intervention. Analysis was with standard statistics based on the null hypothesis, and separation test for early phase CAM comparative trials. Twenty-eight patients completed the study. Use of standard statistics with intent-to-treat analysis showed that total FIQ scores decreased by 14% in the soy group (P = .02) and by 18% in the placebo group (P < .001). The difference in change in scores between the groups was not significant (P = .16). With the same analysis, CES-D scores decreased in the soy group by 16% (P = .004) and in the placebo group by 15% (P = .05). The change in scores was similar in the groups (P = .83). Results of statistical analysis using the separation test and intent-to-treat analysis revealed no benefit of soy compared with placebo. Shakes that contain soy and shakes that contain casein, when combined with a multidisciplinary fibromyalgia treatment program, provide a decrease in fibromyalgia symptoms. Separation between the effects of soy and casein (control) shakes did not favor the intervention. Therefore, large-sample studies using soy for patients with fibromyalgia are probably not indicated.", "target": "This study looked at whether using soy products could help people with fibromyalgia, a condition that causes pain all over the body, to feel better. The researchers randomly divided 50 people with fibromyalgia into two groups. One group drank a soy shake every day, and the other group drank a placebo shake (containing casein, a protein found in milk) that didn't contain any soy. They compared how the two groups were doing both before the study started and after six weeks of drinking the shakes.\n\nThe main result was that both groups felt somewhat better after six weeks, but there was no real difference between the people who drank the soy shakes and those who drank the placebo shakes. The researchers concluded that, based on these results, there's probably no point in doing bigger studies to see whether soy is useful for people with fibromyalgia, because it didn't seem to make a difference in this study.", "question": "What type of medicine do most patients with fibromyalgia use?", "answer": "Most patients with fibromyalgia use complementary and alternative medicine (CAM)."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 0, "end": 81, "score": 1, "text": "Most patients with fibromyalgia use complementary and alternative medicine (CAM).", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 3137438, "edit_id": "af34ea735b33c6108da26bdaea39c38a", "source": "OBJECTIVES.\nUsing the fluid filtration method, an in vitro study was conducted to evaluate the effects of medication with calcium hydroxide on the sealing ability of the New Endodontic Cement (NEC) apical barrier in the short and long terms.\n\nMETHODS.\nFifty extracted single rooted teeth were prepared and apical resorption produced using acid sulfuric for four days. The teeth were randomly divided into two experimental groups (n=20) and two control groups. In group 1, calcium hydroxide was placed into all canals for one week and in group 2, no medication was used. In both groups, a 4 mm NEC apical plug was placed in the canals and the remaining portion of the canals was filled with gutta-percha. The amount of microleakage of all samples was evaluated after one week and three months. The data were statistically analyzed using two-way ANOVA.\n\nRESULTS.\nThere was no significant difference between the two groups in either time period (P>.05). In both group 1 and group 2, microleakage increased after three months but this increase was not statistically significant (P>.05).\n\nCONCLUSIONS.\nAccording to the result of this study, medication with calcium hydroxide had no adverse effect on the short- and long-term sealing properties of an NEC apical plug.", "target": "GOAL\nThe goal of this experiment was to figure out if using a specific medicine called calcium hydroxide affected the quality of a dental seal made with New Endodontic Cement (NEC) in both the short and long term.\n\nHOW WE DID IT\nWe took 50 extracted teeth and treated them with acid for four days to imitate decay. After that, we separated them randomly into 2 test groups and 2 control groups. In the first test group, we applied calcium hydroxide to all teeth for a week. In the second test group, we didn't use any medicine. In both groups, we sealed the roots with a 4 mm NEC plug and filled the rest of the root with a common filling material. We measured the leakage in all samples after one week and after three months. We then analyzed the results statistically to understand if there were any significant differences.\n\nWHAT WE FOUND\nThere wasn't any notable difference between the two groups at either time interval. In both groups, leakage increased after three months but this increase was not substantial enough to be statistically meaningful.\n\nWHAT IT MEANS\nBased on our findings, using calcium hydroxide medicine doesn't harm the short or long term quality of a seal made with NEC.", "question": "Where was the study conducted?", "answer": "The study was conducted in a laboratory setting, specifically an in vitro study."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 47, "end": 64, "score": 1, "text": "an in vitro study", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 22, "end": 32, "score": 1, "text": "experiment", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 3214395, "edit_id": "2eae46d8a9d06370507f30600a430b06", "source": "BACKGROUND.\nInduction of anesthesia is the most crucial period of general anesthesia. Inhalational induction is the most commonly used technique in pediatric anesthesia. Tracheal intubation can be done after reaching the deep levels of anesthesia. The depth of anesthesia is often difficult to be judged. Bispectral index is a measure of the effects of anesthesia on brain. This study was designed to evaluate the efficacy of bispectral index (BIS) in clarifying suitable depth of anesthesia for tracheal intubation during inhalational induction of anesthesia.\n\nMETHODS.\nIn a clinical trial, ninety patients, ASA I & II, 1 to 6 years old, scheduled for elective surgery were enrolled into the study. After starting BIS monitoring, patients randomly were divided into three groups. Then, anesthesia was induced by gradual increase of halothane in 50% mixture of oxygen (O2) and N2O and continued until target BIS (60 \u00b1 2, 50 \u00b1 2 and 40 \u00b1 2) achieved. After tracheal intubation, the duration of laryngoscopy and the presence of laryngospasm, bronchospasm, laryngoscopy failure, the movement of extremities and the changes in SpO2 and BIS were recorded. The data were analyzed by chi-square and ANOVA at 0.05 level of significance.\n\nRESULTS.\nBIS could not determine the appropriate level of anesthesia for tracheal intubation in this setting. There were no differences in laryngoscopy duration and the occurrence of laryngospasm, bronchospasm, laryngoscopy failure, extremity movement and awakening time among three groups.\n\nCONCLUSIONS.\nThese results confirmed that there was no significant difference in the incidence of complications related to intubation at different BIS values (from 60 to 40) during inhalation induction, and probably to achieve an adequate or more reliable depth of anesthesia, the lower values of BIS is required.", "target": "BACKGROUND.\nGetting the right level of anesthesia for a surgery is very important. For children, the most common method is to have them breathe in the anesthetic. A tube may need to be put down the throat once the child is deeply asleep. It can be hard to tell exactly how deep the sleep is. One way to measure this is using something called a Bispectral index (BIS). In this study, we wanted to see how well the BIS can tell us when a child is asleep enough for the tube to be safely put in.\n\nMETHODS.\nWe did a test with ninety children who were aged 1 to 6 years and were about to have surgery. We started to monitor their BIS and separated them randomly into three groups. The anesthesia was started by gradually increasing the amount of anesthetic in a mix of oxygen and nitrous oxide. We kept increasing until the BIS reached certain target levels. After the tube was put in, we noted how long the process took, whether there were any complications like trouble breathing, if the child moved, and how long they stayed asleep. \n\nRESULTS.\nThe BIS didn't help us to know the best level of anesthesia for putting the tube in. There was no difference in how long it took, whether there were any problems, or how long the children stayed asleep between the three groups. \n\nCONCLUSIONS.\nOur results showed that there wasn't a significant difference in problems related to putting in the tube at different BIS levels. To make sure the level of anesthesia is deep enough, we might need to aim for lower BIS values.\n", "question": "What were the specific measures used to evaluate the success of tracheal intubation in this study?", "answer": "The specific measures used to evaluate the success of tracheal intubation in this study were laryngoscopy duration, the occurrence of laryngospasm, bronchospasm, laryngoscopy failure, extremity movement and awakening time."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 1340, "end": 1519, "score": 1, "text": "There were no differences in laryngoscopy duration and the occurrence of laryngospasm, bronchospasm, laryngoscopy failure, extremity movement and awakening time among three groups", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 1127, "end": 1268, "score": 1, "text": "There was no difference in how long it took, whether there were any problems, or how long the children stayed asleep between the three groups", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 3232074, "edit_id": "ea5888dc4f87e82c3ee9a6f196340129", "source": "BACKGROUND AND THE PURPOSE OF THE STUDY.\nDiabetic neuropathy is the most common diabetic complication that often is accompanied by significant morbidity, mortality and economic burden. The purpose of this study was evaluation of effect of Semelil (ANGIPARSTM), a new herbal drug for treatment of diabetic foot ulcers or diabetic peripheral neuropathy.\n\nMETHODS.\nIn this double blind clinical trial, 49 type 2 diabetes patients with different degrees of neuropathy were evaluated in two groups (ANGIPARSTM and placebo groups). All patients were assessed at the start and 12 weeks after treatment, with laboratory tests, United Kingdom screening test, Michigan neuropathy screening score, Michigan diabetic neuropathy score, vibration perception thresholds, nerve conduction study, monofilament test and visual analog scale.\n\nRESULTS.\nMichigan diabetic neuropathy score was decreased notably in ANGIPARSTM group. In the nerve conduction study, appropriate meaningful changes were observed in the distal latency and amplitude in the motor Ulnar nerve in ANGIPARSTM group.\n\nCONCLUSION.\nThe results showed limited evidence of efficacy of ANGIPARSTM in diabetic neuropathy treatment and more studies with a larger sample size and longer duration are required.", "target": "WHY THE STUDY WAS DONE:\nThe study aimed to find out whether a new herbal medicine called Semelil (or ANGIPARSTM) has any positive effects on diabetic foot ulcers. Diabetic foot ulcers are a common condition in people with diabetes, and often lead to significant health problems and costs.\n\nHOW THE STUDY WAS DONE:\nIn the study, 49 people with type 2 diabetes and varying degrees of foot ulcers were divided into two groups. One group was given the new medicine and the other was given a placebo (a treatment with no active ingredient). The patients went through a series of tests before and after the study to measure the effects of the medicine.\n\nWHAT THE STUDY FOUND:\nThe study found some evidence that the new medicine had a positive effect on the patients' foot ulcers. There were noticeable changes in the motor Ulnar nerve, which is one of the nerves in the arm that can be affected by diabetes.\n\nTHE STUDY'S CONCLUSIONS:\nThe study concluded that while the medicine had some effect, more research with larger groups of people and over longer periods of time is needed to truly gauge its effectiveness.", "question": "What tests were conducted before and after the study?", "answer": "The patients underwent a series of tests before and after the study, including laboratory tests, United Kingdom screening test, Michigan neuropathy screening score, Michigan diabetic neuropathy score, vibration perception thresholds, nerve conduction study, monofilament test and visual analog scale. The study lasted for 12 weeks."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 526, "end": 822, "score": 1, "text": "All patients were assessed at the start and 12 weeks after treatment, with laboratory tests, United Kingdom screening test, Michigan neuropathy screening score, Michigan diabetic neuropathy score, vibration perception thresholds, nerve conduction study, monofilament test and visual analog scale.", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 536, "end": 646, "score": 1, "text": "The patients went through a series of tests before and after the study to measure the effects of the medicine.", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 3269796, "edit_id": "6248dcc9089c279471daf9f59ff8e4fb", "source": "The purpose of this study was to compare a novel bone marrow device with the standard marrow needle in a prospective, randomized study in a teaching hospital employing hematologists-in-training. The new device, the OnControl Bone Marrow (OBM) Biopsy System, utilizes a battery-powered drill to insert the needle. Fifty-four bone marrows (27 standard and 27 OBM) were performed by 11 fellows under the observation and supervision of 3 attending hematologists and 1 research technologist. The primary endpoint of the study, the mean length of the marrow biopsy specimens, a surrogate for marrow quality, was determined by a pathologist in a blinded manner. The mean length of the marrow biopsy specimens was significantly longer (56%) for the OBM group (15.3 mm) than for the standard bone marrow (SBM) group (9.8 mm), P<0.003. An objectively determined secondary endpoint; mean procedure time, skin-to-skin; also favored the OBM group (175 s) versus the SBM group (292 s), P<0.007. Several subjective secondary endpoints also favored the OBM group. Only minor adverse events were encountered in the OBM and SBM study groups. It was concluded that bone marrow procedures (BMPs) performed by hematologists-in-training were significantly faster and superior in quality when performed with the OBM compared to the SBM. These data suggest that the OBM may be considered a new standard of care for adult hematology patients. OBM also appears to be a superior method for training hematology fellows.", "target": "The goal of this research was to compare a newly developed bone marrow device with the regular bone marrow needle. The study took place in a teaching hospital, with medical trainees overseen by experienced doctors and a research technician. The new device, called the OnControl Bone Marrow (OBM) Biopsy System, is powered by a battery-operated drill to insert its needle.\n\nThe research carried out 54 bone marrow tests, half done with the standard needle and half done with the new OnControl device. The main goal measured was the average length of the bone marrow samples taken out, as longer samples usually mean better quality. The ones taken out by the OnControl device were, on average, over half as long again as the ones taken out with the regular needle.\n\nThe researchers also timed the procedures and found that the OnControl device completed its tests significantly faster than the regular needle did. Other measures also favored the OnControl device. There were only a few minor problems in both groups of tests.\n\nTherefore, the researchers concluded that bone marrow tests carried out by doctors-in-training are faster and provide better results when the OnControl device is used compared to the regular needle. Consequently, this device could be favored as a new norm for adult patients needing hematology, and it is a better tool for teaching medical trainees in hematology.", "question": "How does the OnControl device work?", "answer": "The OnControl device uses a battery-powered drill to insert the needle, which allows for a faster and more efficient bone marrow biopsy compared to the standard needle."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 195, "end": 312, "score": 1, "text": "The new device, the OnControl Bone Marrow (OBM) Biopsy System, utilizes a battery-powered drill to insert the needle.", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 249, "end": 376, "score": 1, "text": "device, called the OnControl Bone Marrow (OBM) Biopsy System, is powered by a battery-operated drill to insert its needle.\n\nThe", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 3570228, "edit_id": "54b310d6fa82cc92c8f18832d93b98c0", "source": "The current study aimed to observe the effects of sufentanil and remifentanil combined with propofol in target-controlled infusion (TCI) on perioperative stress reaction in elderly patients. A total of 80 elderly patients requiring general anesthesia were recruited. They were divided into four groups (each n=20) according to different target concentrations of remifentanil and sufentanil. These target concentrations were: 4 ng/ml remifentanil + 0.2 ng/ml sufentanil for group I; 3 ng/ml remifentanil + 0.3 ng/ml sufentanil for group II; 2 ng/ml remifentanil + 0.5 ng/ml sufentanil for anesthesia induction and post-intubation 3 ng/ml remifentanil + 0.2 ng/ml sufentanil for anesthesia maintenance for group III; and 5 ng/ml remifentanil for anesthesia induction and post-intubation 4 ng/ml remifentanil for anesthesia maintenance for group IV. Norepinephrine (NE), epinephrine (E) and angiotensin II (Ang II) levels in plasma were measured prior to the induction of anesthesia, as well as at several different time-points following surgery. The numbers of intraoperative severe hemodynamic fluctuation, postoperative eye-opening and extubation time, and post-extubation restlessness and pain scores were recorded. Group IV had a larger circulation fluctuation control number and higher levels of NE, E and Ang II at 3 h after surgery than any other group (P<0.01). Although group IV had shorter postoperative eye-opening and extubation times compared with the other groups (P<0.05), it also had higher restlessness and pain scores (P<0.01). The combined use of sufentanil and remifentanil stabilizes perioperative hemodynamics and reduces stress hormone levels.", "target": "The aim of this study was to understand how specific drugs - sufentanil and remifentanil, used together with propofol, affected stress reactions during and after surgery in elderly patients. Eighty older patients who needed general anesthesia were selected and grouped into fours based on different levels of remifentanil and sufentanil used. Blood samples were taken before and after surgery at different times to measure certain hormone levels related to stress. We also observed and recorded various factors such as changes in blood flow during surgery, time taken for patients to open their eyes and to remove the breathing tube post surgery, as well as their levels of restlessness and pain after the breathing tube was removed. \n\nThe group that used only remifentanil had higher blood flow changes and stress hormone levels three hours post surgery compared to the other groups. Even though patients in this group woke up and had their breathing tubes removed sooner after surgery, they also reported higher levels of restlessness and pain. The conclusion is that using sufentanil and remifentanil together stabilizes blood flow during surgery and lowers stress hormone levels.", "question": "What are the specific hormones that were measured and how are they related to stress?", "answer": "The specific hormones that were measured are norepinephrine (NE), epinephrine (E) and angiotensin II (Ang II). These hormones are released during stress and play a role in regulating blood flow and blood pressure."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 847, "end": 928, "score": 1, "text": "Norepinephrine (NE), epinephrine (E) and angiotensin II (Ang II) levels in plasma", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 808, "end": 829, "score": 1, "text": "stress hormone levels", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 3608893, "edit_id": "b1d18fc4d6902b2224322882a775888a", "source": "OBJECTIVE.\nThis study examined the efficacy of a commercially available, portion-controlled diet (PCD) on body weight and HbA1c over 6 months in obese patients with type 2 diabetes.\n\nRESEARCH DESIGN AND METHODS.\nOne-hundred participants with a mean\u00b1s.d. age of 55.6\u00b110.6 year, body weight of 102.9\u00b118.4 kg and HbA1c of 7.7\u00b11.3% were randomly assigned to a 9-session group lifestyle intervention that included a PCD or to a 9-session group program of diabetes self-management education (DSME). Participants in the two groups were prescribed the same goals for energy intake (1250\u20131550 kcal per day) and physical activity (200 min per week).\n\nRESULTS.\nWhile both groups produced significant improvements in weight and HbA1c after 6 months of treatment, PCD participants lost 7.3 kg [95% confidence interval (CI): \u22125.8 to \u22128.8 kg], compared with 2.2 kg (95% CI: \u22120.7 to \u22123.7 kg) in the DSME group (P<0.0001). Significantly more PCD than DSME participants lost \u2a7e5% of initial weight (54.0% vs 14.0%, P<0.0001) and \u2a7e10% (26.0% vs 6.0%, P<0.0001). HbA1c declined by 0.7% (95% CI: \u22120.4 to \u22121.0%) in the PCD group, compared with 0.4% (95% CI: \u22120.1 to \u22120.7%) in DSME (P<0.026). Across both groups, larger weight losses were associated with greater reductions in HbA1c (r=0.52, P<0.0001).\n\nCONCLUSIONS.\nThese findings demonstrate that a commercially available portion-controlled meal plan can induce clinically meaningful improvements in weight and glycemic control in obese individuals with type 2 diabetes. These data have implications for the management of obesity in primary care, as now provided by the Centers for Medicare and Medicaid Services.", "target": "OBJECTIVE\nThe purpose of this study is to see how effective a ready-to-eat, portion-controlled diet is on weight and blood sugar levels over six months in overweight patients with Type 2 diabetes.\n\nRESEARCH DESIGN AND METHODS\nWe had 100 participants on average about 55 years old, weighing about 102.9 kilos, with a blood sugar level of 7.7%. They were placed randomly into two groups. One group used the portion-controlled diet as part of a nine-session lifestyle program, while the other group had a nine-session program focused on teaching them to manage Type-2 diabetes. Both groups had the same goals for daily calorie intake (1250-1550 calories) and weekly exercise (200 minutes).\n\nRESULTS\nOn the whole, both groups improved in weight and blood sugar levels after 6 months. However, those on the portion-controlled diet lost an average of 7.3 kilos compared to 2.2 kilos in the diabetes management group. More people in the portion-controlled diet group lost at least 5% of their starting weight and 10% of their starting weight. Blood sugar levels also decreased more in the portion-controlled group compared to the diabetes management group. Across both groups, the more weight lost, the better the decrease in blood sugar levels.\n\nCONCLUSION\nThe findings show that ready-to-eat, portion-controlled meals can significantly improve weight and blood sugar control in overweight people with Type 2 diabetes. These results matter to doctors and health services who want to help patients deal with being overweight.", "question": "What were the ages, weights, and HbA1c levels of the participants in the study?", "answer": "The participants had a mean age of 55.6 years, a mean weight of 102.9 kg, and a mean HbA1c level of 7.7%."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 212, "end": 492, "score": 1, "text": "One-hundred participants with a mean\u00b1s.d. age of 55.6\u00b110.6 year, body weight of 102.9\u00b118.4 kg and HbA1c of 7.7\u00b11.3% were randomly assigned to a 9-session group lifestyle intervention that included a PCD or to a 9-session group program of diabetes self-management education (DSME).", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 3608893, "edit_id": "c9261c44403fed31d3e441d30605f7fc", "source": "OBJECTIVE.\nThis study examined the efficacy of a commercially available, portion-controlled diet (PCD) on body weight and HbA1c over 6 months in obese patients with type 2 diabetes.\n\nRESEARCH DESIGN AND METHODS.\nOne-hundred participants with a mean\u00b1s.d. age of 55.6\u00b110.6 year, body weight of 102.9\u00b118.4 kg and HbA1c of 7.7\u00b11.3% were randomly assigned to a 9-session group lifestyle intervention that included a PCD or to a 9-session group program of diabetes self-management education (DSME). Participants in the two groups were prescribed the same goals for energy intake (1250\u20131550 kcal per day) and physical activity (200 min per week).\n\nRESULTS.\nWhile both groups produced significant improvements in weight and HbA1c after 6 months of treatment, PCD participants lost 7.3 kg [95% confidence interval (CI): \u22125.8 to \u22128.8 kg], compared with 2.2 kg (95% CI: \u22120.7 to \u22123.7 kg) in the DSME group (P<0.0001). Significantly more PCD than DSME participants lost \u2a7e5% of initial weight (54.0% vs 14.0%, P<0.0001) and \u2a7e10% (26.0% vs 6.0%, P<0.0001). HbA1c declined by 0.7% (95% CI: \u22120.4 to \u22121.0%) in the PCD group, compared with 0.4% (95% CI: \u22120.1 to \u22120.7%) in DSME (P<0.026). Across both groups, larger weight losses were associated with greater reductions in HbA1c (r=0.52, P<0.0001).\n\nCONCLUSIONS.\nThese findings demonstrate that a commercially available portion-controlled meal plan can induce clinically meaningful improvements in weight and glycemic control in obese individuals with type 2 diabetes. These data have implications for the management of obesity in primary care, as now provided by the Centers for Medicare and Medicaid Services.", "target": "OBJECTIVE\nThe purpose of this study is to see how effective a ready-to-eat, portion-controlled diet is on weight and blood sugar levels over six months in overweight patients with Type 2 diabetes.\n\nRESEARCH DESIGN AND METHODS\nWe had 100 participants on average about 55 years old, weighing about 102.9 kilos, with a blood sugar level of 7.7%. They were placed randomly into two groups. One group used the portion-controlled diet as part of a nine-session lifestyle program, while the other group had a nine-session program focused on teaching them to manage Type-2 diabetes. Both groups had the same goals for daily calorie intake (1250-1550 calories) and weekly exercise (200 minutes).\n\nRESULTS\nOn the whole, both groups improved in weight and blood sugar levels after 6 months. However, those on the portion-controlled diet lost an average of 7.3 kilos compared to 2.2 kilos in the diabetes management group. More people in the portion-controlled diet group lost at least 5% of their starting weight and 10% of their starting weight. Blood sugar levels also decreased more in the portion-controlled group compared to the diabetes management group. Across both groups, the more weight lost, the better the decrease in blood sugar levels.\n\nCONCLUSION\nThe findings show that ready-to-eat, portion-controlled meals can significantly improve weight and blood sugar control in overweight people with Type 2 diabetes. These results matter to doctors and health services who want to help patients deal with being overweight.", "question": "What does \"commercially available\" mean in this context?", "answer": "\"Commercially available\" means that the diet is something that can be bought or purchased from a store or other commercial source."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 47, "end": 102, "score": 1, "text": "a commercially available, portion-controlled diet (PCD)", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 1274, "end": 1312, "score": 1, "text": "ready-to-eat, portion-controlled meals", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 3608893, "edit_id": "c37c0b0d67cb1776c4f32f30e5e2f084", "source": "OBJECTIVE.\nThis study examined the efficacy of a commercially available, portion-controlled diet (PCD) on body weight and HbA1c over 6 months in obese patients with type 2 diabetes.\n\nRESEARCH DESIGN AND METHODS.\nOne-hundred participants with a mean\u00b1s.d. age of 55.6\u00b110.6 year, body weight of 102.9\u00b118.4 kg and HbA1c of 7.7\u00b11.3% were randomly assigned to a 9-session group lifestyle intervention that included a PCD or to a 9-session group program of diabetes self-management education (DSME). Participants in the two groups were prescribed the same goals for energy intake (1250\u20131550 kcal per day) and physical activity (200 min per week).\n\nRESULTS.\nWhile both groups produced significant improvements in weight and HbA1c after 6 months of treatment, PCD participants lost 7.3 kg [95% confidence interval (CI): \u22125.8 to \u22128.8 kg], compared with 2.2 kg (95% CI: \u22120.7 to \u22123.7 kg) in the DSME group (P<0.0001). Significantly more PCD than DSME participants lost \u2a7e5% of initial weight (54.0% vs 14.0%, P<0.0001) and \u2a7e10% (26.0% vs 6.0%, P<0.0001). HbA1c declined by 0.7% (95% CI: \u22120.4 to \u22121.0%) in the PCD group, compared with 0.4% (95% CI: \u22120.1 to \u22120.7%) in DSME (P<0.026). Across both groups, larger weight losses were associated with greater reductions in HbA1c (r=0.52, P<0.0001).\n\nCONCLUSIONS.\nThese findings demonstrate that a commercially available portion-controlled meal plan can induce clinically meaningful improvements in weight and glycemic control in obese individuals with type 2 diabetes. These data have implications for the management of obesity in primary care, as now provided by the Centers for Medicare and Medicaid Services.", "target": "OBJECTIVE\nThe purpose of this study is to see how effective a ready-to-eat, portion-controlled diet is on weight and blood sugar levels over six months in overweight patients with Type 2 diabetes.\n\nRESEARCH DESIGN AND METHODS\nWe had 100 participants on average about 55 years old, weighing about 102.9 kilos, with a blood sugar level of 7.7%. They were placed randomly into two groups. One group used the portion-controlled diet as part of a nine-session lifestyle program, while the other group had a nine-session program focused on teaching them to manage Type-2 diabetes. Both groups had the same goals for daily calorie intake (1250-1550 calories) and weekly exercise (200 minutes).\n\nRESULTS\nOn the whole, both groups improved in weight and blood sugar levels after 6 months. However, those on the portion-controlled diet lost an average of 7.3 kilos compared to 2.2 kilos in the diabetes management group. More people in the portion-controlled diet group lost at least 5% of their starting weight and 10% of their starting weight. Blood sugar levels also decreased more in the portion-controlled group compared to the diabetes management group. Across both groups, the more weight lost, the better the decrease in blood sugar levels.\n\nCONCLUSION\nThe findings show that ready-to-eat, portion-controlled meals can significantly improve weight and blood sugar control in overweight people with Type 2 diabetes. These results matter to doctors and health services who want to help patients deal with being overweight.", "question": "What were the specific goals for energy intake and physical activity in the study?", "answer": "The participants were aiming for a daily energy intake of 1250-1550 kcal and 200 minutes of physical activity per week."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 493, "end": 639, "score": 1, "text": "Participants in the two groups were prescribed the same goals for energy intake (1250\u20131550 kcal per day) and physical activity (200 min per week).", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 575, "end": 686, "score": 1, "text": "Both groups had the same goals for daily calorie intake (1250-1550 calories) and weekly exercise (200 minutes).", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 3620559, "edit_id": "fa3befa6afe49c79366b071a83d43486", "source": "BACKGROUND.\nThis study was designed to determine whether small diameter needles for oocyte retrieval alter oocyte yields in patients undergoing IVF in comparison to standard large diameter needles.\n\nMETHODS.\nWe conducted a prospective pilot study of 21 consecutive favorable prognosis patients. In each patient one ovary was randomly allocated to retrieval with either a 20 G/ 35 mm (thin) or 17 G/ 35 mm (standard) needle, the other ovary was then retrieved with the opposite needle.\n\nRESULTS.\nThe standard diameter needle was used to collect a total of 215 oocytes from 355 aspirated follicles (60.6%) compared to 203 oocytes from 352 aspirated follicles (57.7%) with the thinner needle (p = 0.23). Stratifying outcomes by anti-Mu\u0308llerian hormone (AMH), as indicator of ovarian reserve, and by body mass index (BMI) the oocyte yields, still, did not differ (AMH, r (17) = \u22120.20, p = 0.44; BMI, r (17) =0.02, p = 0.96). Outcomes also did not vary among women with diminished ovarian reserve (p = 0.17) and in women with normal ovarian reserve (p = 1.00). Operating time was, however, significantly increased by 3.3 minutes per ovary (z = \u22123.08, p = 0.002) with the thinner needle.\n\nCONCLUSIONS.\nNeedle diameter does not affect oocyte yield, including in obese patients and patients with diminished ovarian reserve. Thinner needles appear to significantly prolong operating time.", "target": "BACKGROUND.\nWe wanted to see if the size of the needle used to collect a woman's eggs during in vitro fertilization (IVF) affected the number of eggs we could get.\n\nMETHODS.\nWe did a test run with 21 women who were likely to have good results. We randomly picked which ovary to use a standard size needle and which to use a thinner needle on.\n\nRESULTS.\nWith the standard needle, we collected 215 eggs from 355 attempts (60.6%). With the thinner needle, we got 203 eggs from 352 attempts (57.7%). A hormone that tells us how many eggs a woman has left didn't change these results, nor did the woman's weight. There also wasn't a difference in results whether a woman had a normal or low amount of eggs left. However, using the thin needle did make the process about 3.3 minutes longer per ovary.\n\nCONCLUSIONS.\nThe size of the needle doesn't seem to affect how many eggs we can get, including in overweight women and women with fewer eggs left. But using thinner needles makes the procedure take longer.", "question": "What were the specific sizes of the needles used in the study?", "answer": "The study used a 20 G/ 35 mm needle for the thin needle and a 17 G/ 35 mm needle for the standard needle."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 371, "end": 422, "score": 1, "text": "20 G/ 35 mm (thin) or 17 G/ 35 mm (standard) needle", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 3620559, "edit_id": "e7a05f0d559923dea09f6604b37808ba", "source": "BACKGROUND.\nThis study was designed to determine whether small diameter needles for oocyte retrieval alter oocyte yields in patients undergoing IVF in comparison to standard large diameter needles.\n\nMETHODS.\nWe conducted a prospective pilot study of 21 consecutive favorable prognosis patients. In each patient one ovary was randomly allocated to retrieval with either a 20 G/ 35 mm (thin) or 17 G/ 35 mm (standard) needle, the other ovary was then retrieved with the opposite needle.\n\nRESULTS.\nThe standard diameter needle was used to collect a total of 215 oocytes from 355 aspirated follicles (60.6%) compared to 203 oocytes from 352 aspirated follicles (57.7%) with the thinner needle (p = 0.23). Stratifying outcomes by anti-Mu\u0308llerian hormone (AMH), as indicator of ovarian reserve, and by body mass index (BMI) the oocyte yields, still, did not differ (AMH, r (17) = \u22120.20, p = 0.44; BMI, r (17) =0.02, p = 0.96). Outcomes also did not vary among women with diminished ovarian reserve (p = 0.17) and in women with normal ovarian reserve (p = 1.00). Operating time was, however, significantly increased by 3.3 minutes per ovary (z = \u22123.08, p = 0.002) with the thinner needle.\n\nCONCLUSIONS.\nNeedle diameter does not affect oocyte yield, including in obese patients and patients with diminished ovarian reserve. Thinner needles appear to significantly prolong operating time.", "target": "BACKGROUND.\nWe wanted to see if the size of the needle used to collect a woman's eggs during in vitro fertilization (IVF) affected the number of eggs we could get.\n\nMETHODS.\nWe did a test run with 21 women who were likely to have good results. We randomly picked which ovary to use a standard size needle and which to use a thinner needle on.\n\nRESULTS.\nWith the standard needle, we collected 215 eggs from 355 attempts (60.6%). With the thinner needle, we got 203 eggs from 352 attempts (57.7%). A hormone that tells us how many eggs a woman has left didn't change these results, nor did the woman's weight. There also wasn't a difference in results whether a woman had a normal or low amount of eggs left. However, using the thin needle did make the process about 3.3 minutes longer per ovary.\n\nCONCLUSIONS.\nThe size of the needle doesn't seem to affect how many eggs we can get, including in overweight women and women with fewer eggs left. But using thinner needles makes the procedure take longer.", "question": "How significant was the increase in operating time with the thinner needle?", "answer": "The increase in operating time with the thinner needle was statistically significant, with a p-value of 0.002. A p-value less than 0.05 is generally considered statistically significant, meaning the results are unlikely to have occurred by chance."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 1056, "end": 1181, "score": 1, "text": "Operating time was, however, significantly increased by 3.3 minutes per ovary (z = \u22123.08, p = 0.002) with the thinner needle.", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 716, "end": 794, "score": 1, "text": "using the thin needle did make the process about 3.3 minutes longer per ovary.", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 3659039, "edit_id": "9af8c3a026f606d214e7fa304b9169df", "source": "BACKGROUND.\nEicosapentaenoic acid (EPA) and docosahexaenoic acid (DHA) are functionally the most important omega-3 polyunsaturated fatty acids (PUFAs). Oral supply of these fatty acids increases their levels in plasma and cell membranes, often at the expense of the omega-6 PUFAs arachidonic acid (ARA) and linoleic acid. This results in an altered pattern of lipid mediator production to one which is less pro-inflammatory. We investigated whether short term intravenous supply of omega-3 PUFAs could change the levels of EPA, DHA, ARA and linoleic acid in plasma and erythrocytes in patients with hepatic colorectal metastases.\n\nMETHODS.\nTwenty patients were randomised to receive a 72 hour infusion of total parenteral nutrition with (treatment group) or without (control group) omega-3 PUFAs. EPA, DHA, ARA and linoleic acid were measured in plasma phosphatidylcholine (PC) and erythrocytes at several times points up to the end of infusion and 5 to 12 days (mean 9 days) after stopping the infusion.\n\nRESULTS.\nThe treatment group showed increases in plasma PC EPA and DHA and erythrocyte EPA and decreases in plasma PC and erythrocyte linoleic acid, with effects most evident late in the infusion period. Plasma PC and erythrocyte EPA and linoleic acid all returned to baseline levels after the 5\u201312 day washout. Plasma PC DHA remained elevated above baseline after washout.\n\nCONCLUSIONS.\nIntravenous supply of omega-3 PUFAs results in a rapid increase of EPA and DHA in plasma PC and of EPA in erythrocytes. These findings suggest that infusion of omega-3 PUFAs could be used to induce a rapid effect especially in targeting inflammation.\n\nTRIAL REGISTRATION.\nhttp://www.clinicaltrials.gov identifier NCT00942292", "target": "BACKGROUND.\nOmega-3 fatty acids, such as Eicosapentaenoic acid (EPA) and docosahexaenoic acid (DHA), are very important for our body. When we take these acids orally, their levels increase in our blood and cell walls, which reduces inflammation. This study examined whether giving omega-3 fatty acids directly into a patient's veins could change the amounts of EPA, DHA, and other fatty acids in the blood of patients with liver cancer that originated from the colon or rectum.\n\nMETHODS.\nTwenty patients were chosen at random to receive a 3-day intravenous nutrition treatment, either with or without (control group) omega-3 fatty acids. The fatty acids EPA, DHA, and others were measured in the blood plasma and red blood cells several times during and after the treatment.\n\nRESULTS.\nThe group of patients who received omega-3 fatty acids showed increases in EPA and DHA levels and decreases in other fatty acid levels. These changes were have been found to be most significant late in the treatment period. Except for DHA levels, all others returned to normal 5-12 days after stopping the treatment. \n\nCONCLUSIONS.\nGiving omega-3 fatty acids directly into a patient's veins leads to a quick increase in some fatty acids, which suggests that this method could be used to quickly target inflammation especially.\n\nTRIAL REGISTRATION.\nThis trial was officially registered with the identifier NCT00942292 at www.clinicaltrials.gov.", "question": "What happened to the erythrocyte EPA and linoleic acid levels after the 5-12 day washout period?", "answer": "The erythrocyte EPA and linoleic acid levels returned to their baseline levels after the 5-12 day washout period."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 1210, "end": 1317, "score": 1, "text": "Plasma PC and erythrocyte EPA and linoleic acid all returned to baseline levels after the 5\u201312 day washout.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 3730064, "edit_id": "267de85d34bedb6955fee68a8808637c", "source": "PURPOSE.\nTo compare the short term effects of bevacizumab and ranibizumab injections on the regression of corneal neovascularization (NV).\n\nMETHODS.\nSixteen eyes of 16 patients with corneal NV were randomly assigned for an injection with 2.5 mg of bevacizumab (group 1, n = 8) or 1 mg of ranibizumab (group 2, n = 8) through subconjunctival and intrastromal routes. The patients were prospectively followed-up for one month after the injections. Corneal NV areas, as shown on corneal slit-lamp photographs stored in JPEG format, were calculated using Image J software before the injection, one week after the injection, and one month after the injection. The corneal NV areas were compared before and after the injections.\n\nRESULTS.\nSeven women and nine men, with an average age of 51 years, presented with corneal NV secondary to herpetic keratitis (7 cases), graft rejection (6), chemical burn (1), pemphigoid (1), and recurrent ulcer (1). In group I, the preoperative corneal NV area (8.75 \u00b1 4.33%) was significantly decreased to 5.62 \u00b1 3.86% one week after the injection and to 6.35 \u00b1 3.02% one month after the injection (p = 0.012, 0.012, respectively). The corneal NV area in group 2 also exhibited a significant change, from 7.37 \u00b1 4.33% to 6.72 \u00b1 4.16% one week after the injection (p = 0.012). However, no significant change was observed one month after the injection. The mean decrease in corneal NV area one month after injection in group 1 (28.4 \u00b1 9.01%) was significantly higher than in group 2 (4.51 \u00b1 11.64%, p = 0.001).\n\nCONCLUSIONS.\nBevacizumab injection resulted in a more effective and stable regression of corneal NV compared to the ranibizumab injection. The potency and dose of these two drugs for the regression of corneal NV require further investigation.", "target": "PURPOSE.\nThis study aims to compare the short-term effects of two kinds of injections, namely, bevacizumab and ranibizumab, on the shrinking of unusual blood vessels in the cornea (the clear, dome-shaped surface that covers the eye).\n\nMETHODS.\nSixteen patients suffering from abnormal blood vessels in the cornea were randomly chosen to receive one of either a bevacizumab or ranibizumab injection. They were checked before the injection, a week after the injection, and a month after the injection to measure how much their blood vessels shrunk. \n\nRESULTS.\nThe patients, aged around 51, developed abnormal blood vessels in the cornea due to various reasons like eye infections or chemical burns. After the bevacizumab injection, a clear reduction in unusual blood vessels was noticed both a week and a month after the treatment. The ranibizumab injection also resulted in reduced abnormal vessels after a week, but the change was not significant a month later. In group 1, treated with bevacizumab, the shrinkage in unusual vessels was significantly higher than in group 2, treated with ranibizumab.\n\nCONCLUSIONS.\nThe study concluded that bevacizumab injection was more effective in reducing the unusual blood vessel growth in the cornea compared to the ranibizumab injection. However, further research is needed to understand the effectiveness and the right dosage of these two treatments.", "question": "What were the specific percentages of decrease in the unusual blood vessels in the cornea in the two groups?", "answer": "The mean decrease in the area of unusual blood vessels in the cornea one month after injection was 28.4% in the group treated with bevacizumab and 4.51% in the group treated with ranibizumab."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 1378, "end": 1535, "score": 1, "text": "The mean decrease in corneal NV area one month after injection in group 1 (28.4 \u00b1 9.01%) was significantly higher than in group 2 (4.51 \u00b1 11.64%, p = 0.001).", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 962, "end": 1100, "score": 1, "text": "In group 1, treated with bevacizumab, the shrinkage in unusual vessels was significantly higher than in group 2, treated with ranibizumab.", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 3730064, "edit_id": "00e85aad85a758334b84c46b5e4c6199", "source": "PURPOSE.\nTo compare the short term effects of bevacizumab and ranibizumab injections on the regression of corneal neovascularization (NV).\n\nMETHODS.\nSixteen eyes of 16 patients with corneal NV were randomly assigned for an injection with 2.5 mg of bevacizumab (group 1, n = 8) or 1 mg of ranibizumab (group 2, n = 8) through subconjunctival and intrastromal routes. The patients were prospectively followed-up for one month after the injections. Corneal NV areas, as shown on corneal slit-lamp photographs stored in JPEG format, were calculated using Image J software before the injection, one week after the injection, and one month after the injection. The corneal NV areas were compared before and after the injections.\n\nRESULTS.\nSeven women and nine men, with an average age of 51 years, presented with corneal NV secondary to herpetic keratitis (7 cases), graft rejection (6), chemical burn (1), pemphigoid (1), and recurrent ulcer (1). In group I, the preoperative corneal NV area (8.75 \u00b1 4.33%) was significantly decreased to 5.62 \u00b1 3.86% one week after the injection and to 6.35 \u00b1 3.02% one month after the injection (p = 0.012, 0.012, respectively). The corneal NV area in group 2 also exhibited a significant change, from 7.37 \u00b1 4.33% to 6.72 \u00b1 4.16% one week after the injection (p = 0.012). However, no significant change was observed one month after the injection. The mean decrease in corneal NV area one month after injection in group 1 (28.4 \u00b1 9.01%) was significantly higher than in group 2 (4.51 \u00b1 11.64%, p = 0.001).\n\nCONCLUSIONS.\nBevacizumab injection resulted in a more effective and stable regression of corneal NV compared to the ranibizumab injection. The potency and dose of these two drugs for the regression of corneal NV require further investigation.", "target": "PURPOSE.\nThis study aims to compare the short-term effects of two kinds of injections, namely, bevacizumab and ranibizumab, on the shrinking of unusual blood vessels in the cornea (the clear, dome-shaped surface that covers the eye).\n\nMETHODS.\nSixteen patients suffering from abnormal blood vessels in the cornea were randomly chosen to receive one of either a bevacizumab or ranibizumab injection. They were checked before the injection, a week after the injection, and a month after the injection to measure how much their blood vessels shrunk. \n\nRESULTS.\nThe patients, aged around 51, developed abnormal blood vessels in the cornea due to various reasons like eye infections or chemical burns. After the bevacizumab injection, a clear reduction in unusual blood vessels was noticed both a week and a month after the treatment. The ranibizumab injection also resulted in reduced abnormal vessels after a week, but the change was not significant a month later. In group 1, treated with bevacizumab, the shrinkage in unusual vessels was significantly higher than in group 2, treated with ranibizumab.\n\nCONCLUSIONS.\nThe study concluded that bevacizumab injection was more effective in reducing the unusual blood vessel growth in the cornea compared to the ranibizumab injection. However, further research is needed to understand the effectiveness and the right dosage of these two treatments.", "question": "What were the specific causes of the unusual blood vessel growth in the cornea in the patients?", "answer": "The patients developed unusual blood vessels in the cornea due to various reasons including herpetic keratitis, which is an eye infection caused by the herpes simplex virus (7 cases), graft rejection (6 cases), chemical burn (1 case), pemphigoid, which is a rare autoimmune disorder that can cause blistering of the skin (1 case), and recurrent ulcer (1 case)."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 733, "end": 941, "score": 1, "text": "Seven women and nine men, with an average age of 51 years, presented with corneal NV secondary to herpetic keratitis (7 cases), graft rejection (6), chemical burn (1), pemphigoid (1), and recurrent ulcer (1).", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 3730064, "edit_id": "3f9dfae05cc72e7ef1d4211f71a0f7d7", "source": "PURPOSE.\nTo compare the short term effects of bevacizumab and ranibizumab injections on the regression of corneal neovascularization (NV).\n\nMETHODS.\nSixteen eyes of 16 patients with corneal NV were randomly assigned for an injection with 2.5 mg of bevacizumab (group 1, n = 8) or 1 mg of ranibizumab (group 2, n = 8) through subconjunctival and intrastromal routes. The patients were prospectively followed-up for one month after the injections. Corneal NV areas, as shown on corneal slit-lamp photographs stored in JPEG format, were calculated using Image J software before the injection, one week after the injection, and one month after the injection. The corneal NV areas were compared before and after the injections.\n\nRESULTS.\nSeven women and nine men, with an average age of 51 years, presented with corneal NV secondary to herpetic keratitis (7 cases), graft rejection (6), chemical burn (1), pemphigoid (1), and recurrent ulcer (1). In group I, the preoperative corneal NV area (8.75 \u00b1 4.33%) was significantly decreased to 5.62 \u00b1 3.86% one week after the injection and to 6.35 \u00b1 3.02% one month after the injection (p = 0.012, 0.012, respectively). The corneal NV area in group 2 also exhibited a significant change, from 7.37 \u00b1 4.33% to 6.72 \u00b1 4.16% one week after the injection (p = 0.012). However, no significant change was observed one month after the injection. The mean decrease in corneal NV area one month after injection in group 1 (28.4 \u00b1 9.01%) was significantly higher than in group 2 (4.51 \u00b1 11.64%, p = 0.001).\n\nCONCLUSIONS.\nBevacizumab injection resulted in a more effective and stable regression of corneal NV compared to the ranibizumab injection. The potency and dose of these two drugs for the regression of corneal NV require further investigation.", "target": "PURPOSE.\nThis study aims to compare the short-term effects of two kinds of injections, namely, bevacizumab and ranibizumab, on the shrinking of unusual blood vessels in the cornea (the clear, dome-shaped surface that covers the eye).\n\nMETHODS.\nSixteen patients suffering from abnormal blood vessels in the cornea were randomly chosen to receive one of either a bevacizumab or ranibizumab injection. They were checked before the injection, a week after the injection, and a month after the injection to measure how much their blood vessels shrunk. \n\nRESULTS.\nThe patients, aged around 51, developed abnormal blood vessels in the cornea due to various reasons like eye infections or chemical burns. After the bevacizumab injection, a clear reduction in unusual blood vessels was noticed both a week and a month after the treatment. The ranibizumab injection also resulted in reduced abnormal vessels after a week, but the change was not significant a month later. In group 1, treated with bevacizumab, the shrinkage in unusual vessels was significantly higher than in group 2, treated with ranibizumab.\n\nCONCLUSIONS.\nThe study concluded that bevacizumab injection was more effective in reducing the unusual blood vessel growth in the cornea compared to the ranibizumab injection. However, further research is needed to understand the effectiveness and the right dosage of these two treatments.", "question": "Which injection resulted in a more stable decrease in abnormal blood vessels?", "answer": "The bevacizumab injection led to a more stable decrease in the size of the abnormal blood vessels in the cornea compared to the ranibizumab injection."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 1550, "end": 1675, "score": 1, "text": "Bevacizumab injection resulted in a more effective and stable regression of corneal NV compared to the ranibizumab injection.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 3798949, "edit_id": "cc11a4f7d4c177890eb98b82a748d90c", "source": "BACKGROUND.\nThe conduct of clinical trials should be an integral part of routine patient care. Treating patients in trials incurs additional costs over and above standard of care (SOC), but the extent of the cost burden is not known. We undertook a retrospective cost attribution analysis to quantitate the treatment costs associated with cancer clinical trial protocols conducted over a 2 year period.\n\nMETHODS.\nAll patients entered into oncology (non-haematology) clinical trials involving investigational medicinal products in 2009 and 2010 in a single UK institution were identified. The trial protocols on which they were treated were analysed to identify the treatment costs for the experimental arm(s) of the trial and the equivalent SOC had the patient not been entered in the trial. The treatment cost difference was calculated by subtracting the experimental treatment cost from SOC cost. For randomised trials, an average treatment cost was estimated by taking into account the number of arms and randomisation ratio. An estimate of the annual treatment costs was calculated.\n\nRESULTS.\nA total of 357 adult oncology patients were treated on 53 different trial protocols: 40 phase III, 2 randomised II/III and 11 phase II design. A total of 27 trials were academic, non-commercial sponsored trials and 26 were commercial sponsored trials. When compared with SOC, the average treatment cost per patient was an excess of \u00a3431 for a non-commercial trial (range \u00a36393 excess to \u00a36005 saving) and a saving of \u00a39294 for a commercial trial (range \u00a30 to \u00a371 480). There was an overall treatment cost saving of \u00a3388 719 in 2009 and \u00a3496 556 in 2010, largely attributable to pharmaceutical company provision of free drug supplies.\n\nCONCLUSION.\nOn an average, non-commercial trial protocols were associated with a small per patient excess treatment cost, whereas commercial trials were associated with a substantially higher cost saving. Taking into account the total number of patients recruited annually, treatment of patients on clinical trial protocols was associated with considerable cost savings across both the non-commercial and commercial portfolio.", "target": "BACKGROUND\nClinical trials are part of regular medical care. These trials, though, can cost more than standard treatments. We looked at cancer clinical trials over two years to figure out how much extra they cost.\n\nMETHODS\nWe found and studied all patients who took part in drug-based cancer clinical trials in 2009 and 2010 at one hospital in the UK. We compared the cost of the treatments in the trials and the usual treatments the patients could have received. We figured out the difference in cost between these two. For studies that compared treatments, we estimated the average treatment cost. We also estimated the yearly costs.\n\nRESULTS\nDuring those two years, 357 adult cancer patients took part in 53 different research studies. Some of these were designed by universities and other non-profit groups, while others were sponsored by drug companies. On average, the university trials cost an extra \u00a3431 per patient. The drug company trials, on the other hand, saved an average of \u00a39294 per patient. This is largely because these companies supplied the drugs for free. In total, these trials saved about \u00a3885,275 over the two years.\n\nCONCLUSION\nIn general, trials designed by universities cost a little more per patient. Drug company trials, though, saved much more money. Given the large number of patients that take part in these trials every year, they can lead to big savings, regardless of who runs them.", "question": "What factors were considered while estimating the average treatment cost in the original text?", "answer": "In the original text, the estimation of the average treatment cost considered the randomisation ratio. This means they took into account the ratio of patients assigned to the treatment group compared to those assigned to the control group."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 899, "end": 1028, "score": 1, "text": "For randomised trials, an average treatment cost was estimated by taking into account the number of arms and randomisation ratio.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 3814649, "edit_id": "4c5be9b7b49f3fe4ae9855e77dfd0376", "source": "BACKGROUND.\nThe present studies evaluated the effects of cryoprotectants, the vitrification procedure and time in the warming solution containing sucrose on cleavage and embryo development of immature (GV stage) bovine cumulus-oocyte complexes (COCs).\n\nMETHODS.\nTwo experiments were conducted. In Experiment 1, COCs (n = 420) were randomly assigned to four groups: 1) Control group: no treatment; 2) VS1 group: COCs were exposed to vitrification solution 1 (VS1) containing 7.5% ethylene glycol [EG] + 7.5% dimethyl sulfoxide [DMSO] + 20% calf serum [CS] in TCM-199 at 37 C for 5 min; 3) VS1 + VS2 group: COCs were exposed to VS1 for 5 min followed by VS2 (15% EG + 15% DMSO + 17.1% sucrose + 20% CS) at 37 C for 45\u201360 sec; and 4) Vitrified group: COCs were exposed to VS1 and VS2, loaded on cryotops, vitrified in liquid nitrogen and then warmed in TCM-199 + 17.1% sucrose + 20% CS at 37 C for 1 min. In Experiment 2, COCs (n = 581) were assigned to the same groups, but those in VS1, VS1 + VS2 and Vitrified groups were sub-divided and exposed to the warming solution for either 1 or 5 min. After treatment and/or warming, all COCs in both experiments underwent in vitro maturation, in vitro fertilization and in vitro culture.\n\nRESULTS.\nCleavage and blastocyst rates did not differ among Control, VS1 and VS1 + VS2 groups in either experiment. In Experiment 2, there was no effect of time in the warming solution.  However, both cleavage and blastocyst rates were lower (P < 0.001) in the Vitrified group than in the Control, VS1 and VS1 + VS2 groups (40.9 and 1.6% vs 92.2 and 34.4%, 79.4 and 25.2%, and 80.2 and 20.8%, respectively in Experiment 1, and 25.0 and 1.7% vs 75.3 and 27.2%, 67.9 and 19.5%, and 62.7 and 22.5%, respectively in Experiment 2).\n\nCONCLUSIONS.\nThe permeating cryoprotectants (EG and DMSO) present in VS1 and VS2 solutions and the time in the warming solution containing sucrose had no adverse effects on cleavage and blastocyst rates of immature bovine COCs. However, cleavage rate and early embryo development were reduced following the vitrification and warming.", "target": "BACKGROUND\nThis study checked how deep freezing (vitrification) and other related factors affect the growth and development of immature cow egg cells (also called COCs).\n\nMETHODS\nWe did two experiments. In the first experiment, we had 420 COCs separated into four groups: Group 1 received no treatment. Group 2 was exposed to a special freezing mixture for 5 minutes. Group 3 got the same freeze mix, then a second mix for 45-60 seconds. Group 4 went through the same steps as group 3, but these COCs were also fast-frozen in liquid nitrogen and then warmed up quickly. In the second experiment, we treated 581 COCs the same way but also had some of the COCs from groups 2, 3 and 4 spend either 1 or 5 minutes in a warming solution. All COCs from both experiments were then grown and fertilized in a lab.\n\nRESULTS\nWe noticed that the rate at which the COCs grew and developed was the same for groups 1, 2 and 3, no matter how long they spent in the warming solution. But for the group 4 COCs\u2014the ones that had been fast-frozen and heated up again\u2014their growth and development rates were much lower.\n\nCONCLUSIONS\nWe concluded that the freezing mixes and the time spent in the warming solution did not negatively affect the COCs. The fast-freezing and quick warming, however, did decrease how well these cow egg cells grew and developed.", "question": "What were the details of Experiment 2?", "answer": "In Experiment 2, 581 COCs were assigned to the same groups as in Experiment 1, but those in VS1, VS1 + VS2 and Vitrified groups were sub-divided and exposed to the warming solution for either 1 or 5 minutes."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 902, "end": 1092, "score": 1, "text": "In Experiment 2, COCs (n = 581) were assigned to the same groups, but those in VS1, VS1 + VS2 and Vitrified groups were sub-divided and exposed to the warming solution for either 1 or 5 min.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 3892495, "edit_id": "b038175db989c38e569a7f37b29898eb", "source": "The purpose of this study was to determine the effects of a pre-exercise meal on the plasma human growth hormone (hGH) response and fat oxidation during walking. Subjects (n=8) were randomly provided with either 1 g/kg body weight of glucose in 200 mL water (CHO) or 200 mL water alone (CON) 30 min prior to exercise and subsequently walked on a treadmill at 50% of VO2max for 60 min. Plasma hGH concentrations were significantly higher in subjects who received CHO compared to those who received CON at 15 and 30 min. The fat oxidation rate in the CHO was significantly lower than the CON while walking for 5~15, 25~35 and 45~55 min. Plasma FFA levels were also significantly lower in the CHO compared to the CON at 30, 45 and 60 min. Plasma glucose levels in the CHO were significantly lower while plasma insulin levels were significantly higher than in the CON at 15 and 30 min. Therefore, the results of this study suggest that the elevation of plasma hGH levels due to the intake of a pre-exercise meal may not be strongly related to fat oxidation and plasma free fatty acid (FFA) levels during low-intensity exercise.", "target": "This study was about seeing how having a meal before exercising affected growth hormone levels in the blood and the burning of fat during walking exercise. The people in the study (8 of them) were given either a glucose drink or just water half an hour before they started walking on a treadmill at half of their maximum exercise output for an hour. \n\nThe people who had the glucose drink had significantly more growth hormone in their blood, compared to those who only had water, after 15 and 30 minutes. However, the rate at which they were burning fat was significantly lower at certain time intervals (5-15 minutes, 25-35 minutes, and 45-55 minutes into their walk). Their level of free fatty acids in the blood was also lower after 30, 45, and 60 minutes of walking. The glucose drinkers had lower blood sugar levels but higher insulin levels after 15 and 30 minutes. \n\nIn conclusion, this study suggests that having a meal before exercising might raise growth hormone levels in the blood, but it doesn't seem to be strongly tied to fat burning and free fatty acid levels in the blood during mild exercise like walking.", "question": "What exactly was compared between the subjects who had the glucose drink and those who had water in terms of free fatty acids?", "answer": "The levels of free fatty acids (FFA) in the plasma of the subjects were compared."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 635, "end": 735, "score": 1, "text": "Plasma FFA levels were also significantly lower in the CHO compared to the CON at 30, 45 and 60 min.", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 671, "end": 771, "score": 1, "text": "Their level of free fatty acids in the blood was also lower after 30, 45, and 60 minutes of walking.", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 3892495, "edit_id": "0a9390fbc81d975dbc1f9c99c7aa13d1", "source": "The purpose of this study was to determine the effects of a pre-exercise meal on the plasma human growth hormone (hGH) response and fat oxidation during walking. Subjects (n=8) were randomly provided with either 1 g/kg body weight of glucose in 200 mL water (CHO) or 200 mL water alone (CON) 30 min prior to exercise and subsequently walked on a treadmill at 50% of VO2max for 60 min. Plasma hGH concentrations were significantly higher in subjects who received CHO compared to those who received CON at 15 and 30 min. The fat oxidation rate in the CHO was significantly lower than the CON while walking for 5~15, 25~35 and 45~55 min. Plasma FFA levels were also significantly lower in the CHO compared to the CON at 30, 45 and 60 min. Plasma glucose levels in the CHO were significantly lower while plasma insulin levels were significantly higher than in the CON at 15 and 30 min. Therefore, the results of this study suggest that the elevation of plasma hGH levels due to the intake of a pre-exercise meal may not be strongly related to fat oxidation and plasma free fatty acid (FFA) levels during low-intensity exercise.", "target": "This study was about seeing how having a meal before exercising affected growth hormone levels in the blood and the burning of fat during walking exercise. The people in the study (8 of them) were given either a glucose drink or just water half an hour before they started walking on a treadmill at half of their maximum exercise output for an hour. \n\nThe people who had the glucose drink had significantly more growth hormone in their blood, compared to those who only had water, after 15 and 30 minutes. However, the rate at which they were burning fat was significantly lower at certain time intervals (5-15 minutes, 25-35 minutes, and 45-55 minutes into their walk). Their level of free fatty acids in the blood was also lower after 30, 45, and 60 minutes of walking. The glucose drinkers had lower blood sugar levels but higher insulin levels after 15 and 30 minutes. \n\nIn conclusion, this study suggests that having a meal before exercising might raise growth hormone levels in the blood, but it doesn't seem to be strongly tied to fat burning and free fatty acid levels in the blood during mild exercise like walking.", "question": "How much higher were the growth hormone levels in the CHO group compared to the CON group?", "answer": "The growth hormone levels in the CHO group were significantly higher than the CON group by 15 and 30 minutes."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 385, "end": 518, "score": 1, "text": "Plasma hGH concentrations were significantly higher in subjects who received CHO compared to those who received CON at 15 and 30 min.", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 352, "end": 505, "score": 1, "text": "The people who had the glucose drink had significantly more growth hormone in their blood, compared to those who only had water, after 15 and 30 minutes.", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 3893439, "edit_id": "c7a2d02b7eb86ad6ebde91248660ef0c", "source": "BACKGROUND.\nPersistent neuroinflammation and disruptions in brain energy metabolism is commonly seen in traumatic brain injury (TBI). Because of the lack of success of most TBI interventions and the documented benefits of environmental enrichment (EE) in enhancing brain plasticity, here we focused our study on use of EE in regulating injury-induced neuroinflammation and disruptions in energy metabolism in the prefrontal cortex and hippocampus. Adult male Wistar rats were used in the study and randomly assigned to receive either: mild TBI (mTBI) using the controlled cortical injury model or sham surgery. Following surgery, rats from each group were further randomized to either: EE housing or standard laboratory housing (CON). After 4 weeks of recovery, cognitive testing was performed using the non-matching-to-sample and delayed non-matching-to-sample tasks. After completion of behavioral testing, levels of the pro-inflammatory cytokines IL-1\u03b2 and TNF-\u03b1 and the anti-inflammatory cytokine IL-10 were measured. In addition, levels of AMPK (adenosine monophosphate-activated protein kinase), phosphorylated AMPK and uMtCK (ubiquitous mitochondrial creatine kinase) were assessed as measures of brain energy homeostasis.\n\nRESULTS.\nOur results showed that EE: (1) decreased the pro-inflammatory cytokines IL-1\u03b2 and TNF-\u03b1 and enhanced levels of the anti-inflammatory cytokine IL-10 after mTBI; (2) mitigated mTBI-induced cognitive impairment; and (3) attenuated mTBI-induced downregulation in pAMPK/AMPK ratio and uMtCK levels.\n\nCONCLUSIONS.\nOur data demonstrated the potential of EE to modulate the persistent: (1) neuroinflammatory response seen following mTBI, and (2) persistent disturbance in brain energy homeostasis. It is possible that through the mechanism of modulating neuroinflammation, EE housing was able to restore the disruption in energy metabolism and enhanced functional recovery after mTBI.", "target": "BACKGROUND.\nBrain injuries often lead to long-lasting inflammation and energy disruptions in brain activities. Despite several medical treatments, their effectiveness has been limited. However, it is known that environment enrichment (EE) - an uplifting environment - can help in boosting brain recovery. This study therefore looked into how EE can help in reducing inflammation and restoring energy balance in the brain after a minor brain injury. We conducted our study on adult male rats, which either had a minor brain injury or a fake surgery. These rats were then placed in either an EE or normal living conditions. After four weeks, we tested their cognitive abilities and measured the levels of inflammatory proteins in their brain. We also checked for levels of certain proteins that regulate brain energy balance.\n\nRESULTS.\nOur findings showed that EE: (1) reduced the inflammation-causing proteins and increased healing proteins following a minor brain injury; (2) lessened the cognitive problems caused by the minor brain injury; and (3) diminished the decline in energy regulating proteins from the minor brain injury.\n\nCONCLUSIONS.\nOur study suggests that EE can help to control persistent: (1) inflammation in the brain after a minor brain injury, and (2) the ongoing disruption in brain energy balance. Through these effects, EE could help to fix the energy imbalance and improve brain recovery after a minor injury.", "question": "What type of rats were used in the study and how were they assigned to the groups?", "answer": "Adult male Wistar rats were used in the study and randomly assigned to receive either mild TBI (mTBI) using the controlled cortical injury model or sham surgery."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 448, "end": 610, "score": 1, "text": "Adult male Wistar rats were used in the study and randomly assigned to receive either: mild TBI (mTBI) using the controlled cortical injury model or sham surgery.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 3921228, "edit_id": "9955f61d1ba8e59d8941e0bb9ed30c69", "source": "BACKGROUND.\nAmygdala hemodynamic responses to positive stimuli are attenuated in major depressive disorder (MDD), and normalize with remission. Real-time functional MRI neurofeedback (rtfMRI-nf) offers a non-invasive method to modulate this regional activity. We examined whether depressed participants can use rtfMRI-nf to enhance amygdala responses to positive autobiographical memories, and whether this ability alters symptom severity.\n\nMETHODS.\nUnmedicated MDD subjects were assigned to receive rtfMRI-nf from either left amygdala (LA; experimental group, n = 14) or the horizontal segment of the intraparietal sulcus (HIPS; control group, n = 7) and instructed to contemplate happy autobiographical memories (AMs) to raise the level of a bar representing the hemodynamic signal from the target region to a target level. This 40s Happy condition alternated with 40s blocks of rest and counting backwards. A final Transfer run without neurofeedback information was included.\n\nRESULTS.\nParticipants in the experimental group upregulated their amygdala responses during positive AM recall. Significant pre-post scan decreases in anxiety ratings and increases in happiness ratings were evident in the experimental versus control group. A whole brain analysis showed that during the transfer run, participants in the experimental group had increased activity compared to the control group in left superior temporal gyrus and temporal polar cortex, and right thalamus.\n\nCONCLUSIONS.\nUsing rtfMRI-nf from the left amygdala during recall of positive AMs, depressed subjects were able to self-regulate their amygdala response, resulting in improved mood. Results from this proof-of-concept study suggest that rtfMRI-nf training with positive AM recall holds potential as a novel therapeutic approach in the treatment of depression.", "target": "BACKGROUND:\nCertain parts of the brain called the amygdala respond less to happy things in people with depression, but this can improve when they start feeling better. One way to boost this activity in the brain is by using a special type of MRI (a brain imaging technique) known as real-time functional MRI neurofeedback (rtfMRI-nf). We wanted to see if people with depression could use this technique to increase their brain's response to positive personal memories, and if this could affect their symptoms.\n\nMETHODS:\nWe worked with people who have depression but are not taking medication. We divided these individuals into two groups: one was shown rtfMRI-nf from the left amygdala and the other from a different brain area (as a comparison). These individuals were asked to think about happy personal memories to increase the level of a certain signal in the targeted brain area. They did this activity for 40 seconds, followed by rest and counting backwards. Lastly, they did another brain scan without feedback information.\n\nRESULTS:\nPeople in the first group were able to increase their amygdala's response when remembering positive personal memories. Compared to the second group, these individuals also showed a significant decrease in anxiety and an increase in happiness after scanning. When they were not given feedback, their brain activity in certain areas was increased compared to the control group.\n\nCONCLUSION:\nOur research suggests that people with depression were able to control their brain's response to happy memories using this special type of MRI known as rtfMRI-nf. This resulted in an improved mood. These findings provide preliminary evidence that such brain training using positive memory recall could potentially be a new way to treat depression.", "question": "Is the real-time functional MRI neurofeedback (rtfMRI-nf) technique invasive or non-invasive?", "answer": "The rtfMRI-nf technique is non-invasive, which means it doesn't require surgery or the insertion of objects into the body. The process is conducted externally by using magnets and radio waves to create images."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 144, "end": 259, "score": 1, "text": "Real-time functional MRI neurofeedback (rtfMRI-nf) offers a non-invasive method to modulate this regional activity.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 3921228, "edit_id": "5005e6915b7e78034df8aa830f2936b0", "source": "BACKGROUND.\nAmygdala hemodynamic responses to positive stimuli are attenuated in major depressive disorder (MDD), and normalize with remission. Real-time functional MRI neurofeedback (rtfMRI-nf) offers a non-invasive method to modulate this regional activity. We examined whether depressed participants can use rtfMRI-nf to enhance amygdala responses to positive autobiographical memories, and whether this ability alters symptom severity.\n\nMETHODS.\nUnmedicated MDD subjects were assigned to receive rtfMRI-nf from either left amygdala (LA; experimental group, n = 14) or the horizontal segment of the intraparietal sulcus (HIPS; control group, n = 7) and instructed to contemplate happy autobiographical memories (AMs) to raise the level of a bar representing the hemodynamic signal from the target region to a target level. This 40s Happy condition alternated with 40s blocks of rest and counting backwards. A final Transfer run without neurofeedback information was included.\n\nRESULTS.\nParticipants in the experimental group upregulated their amygdala responses during positive AM recall. Significant pre-post scan decreases in anxiety ratings and increases in happiness ratings were evident in the experimental versus control group. A whole brain analysis showed that during the transfer run, participants in the experimental group had increased activity compared to the control group in left superior temporal gyrus and temporal polar cortex, and right thalamus.\n\nCONCLUSIONS.\nUsing rtfMRI-nf from the left amygdala during recall of positive AMs, depressed subjects were able to self-regulate their amygdala response, resulting in improved mood. Results from this proof-of-concept study suggest that rtfMRI-nf training with positive AM recall holds potential as a novel therapeutic approach in the treatment of depression.", "target": "BACKGROUND:\nCertain parts of the brain called the amygdala respond less to happy things in people with depression, but this can improve when they start feeling better. One way to boost this activity in the brain is by using a special type of MRI (a brain imaging technique) known as real-time functional MRI neurofeedback (rtfMRI-nf). We wanted to see if people with depression could use this technique to increase their brain's response to positive personal memories, and if this could affect their symptoms.\n\nMETHODS:\nWe worked with people who have depression but are not taking medication. We divided these individuals into two groups: one was shown rtfMRI-nf from the left amygdala and the other from a different brain area (as a comparison). These individuals were asked to think about happy personal memories to increase the level of a certain signal in the targeted brain area. They did this activity for 40 seconds, followed by rest and counting backwards. Lastly, they did another brain scan without feedback information.\n\nRESULTS:\nPeople in the first group were able to increase their amygdala's response when remembering positive personal memories. Compared to the second group, these individuals also showed a significant decrease in anxiety and an increase in happiness after scanning. When they were not given feedback, their brain activity in certain areas was increased compared to the control group.\n\nCONCLUSION:\nOur research suggests that people with depression were able to control their brain's response to happy memories using this special type of MRI known as rtfMRI-nf. This resulted in an improved mood. These findings provide preliminary evidence that such brain training using positive memory recall could potentially be a new way to treat depression.", "question": "What were the other activities the participants performed apart from thinking about positive personal memories?", "answer": "In addition to recalling happy personal memories, other activities included periods of rest lasting 40 seconds each."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 826, "end": 909, "score": 1, "text": "This 40s Happy condition alternated with 40s blocks of rest and counting backwards.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 3921228, "edit_id": "99224b080c9714c3570ac9a4c2be474b", "source": "BACKGROUND.\nAmygdala hemodynamic responses to positive stimuli are attenuated in major depressive disorder (MDD), and normalize with remission. Real-time functional MRI neurofeedback (rtfMRI-nf) offers a non-invasive method to modulate this regional activity. We examined whether depressed participants can use rtfMRI-nf to enhance amygdala responses to positive autobiographical memories, and whether this ability alters symptom severity.\n\nMETHODS.\nUnmedicated MDD subjects were assigned to receive rtfMRI-nf from either left amygdala (LA; experimental group, n = 14) or the horizontal segment of the intraparietal sulcus (HIPS; control group, n = 7) and instructed to contemplate happy autobiographical memories (AMs) to raise the level of a bar representing the hemodynamic signal from the target region to a target level. This 40s Happy condition alternated with 40s blocks of rest and counting backwards. A final Transfer run without neurofeedback information was included.\n\nRESULTS.\nParticipants in the experimental group upregulated their amygdala responses during positive AM recall. Significant pre-post scan decreases in anxiety ratings and increases in happiness ratings were evident in the experimental versus control group. A whole brain analysis showed that during the transfer run, participants in the experimental group had increased activity compared to the control group in left superior temporal gyrus and temporal polar cortex, and right thalamus.\n\nCONCLUSIONS.\nUsing rtfMRI-nf from the left amygdala during recall of positive AMs, depressed subjects were able to self-regulate their amygdala response, resulting in improved mood. Results from this proof-of-concept study suggest that rtfMRI-nf training with positive AM recall holds potential as a novel therapeutic approach in the treatment of depression.", "target": "BACKGROUND:\nCertain parts of the brain called the amygdala respond less to happy things in people with depression, but this can improve when they start feeling better. One way to boost this activity in the brain is by using a special type of MRI (a brain imaging technique) known as real-time functional MRI neurofeedback (rtfMRI-nf). We wanted to see if people with depression could use this technique to increase their brain's response to positive personal memories, and if this could affect their symptoms.\n\nMETHODS:\nWe worked with people who have depression but are not taking medication. We divided these individuals into two groups: one was shown rtfMRI-nf from the left amygdala and the other from a different brain area (as a comparison). These individuals were asked to think about happy personal memories to increase the level of a certain signal in the targeted brain area. They did this activity for 40 seconds, followed by rest and counting backwards. Lastly, they did another brain scan without feedback information.\n\nRESULTS:\nPeople in the first group were able to increase their amygdala's response when remembering positive personal memories. Compared to the second group, these individuals also showed a significant decrease in anxiety and an increase in happiness after scanning. When they were not given feedback, their brain activity in certain areas was increased compared to the control group.\n\nCONCLUSION:\nOur research suggests that people with depression were able to control their brain's response to happy memories using this special type of MRI known as rtfMRI-nf. This resulted in an improved mood. These findings provide preliminary evidence that such brain training using positive memory recall could potentially be a new way to treat depression.", "question": "Which type of run was conducted at the end of the experiment?", "answer": "A \"Transfer\" run was conducted at the end of the experiment, meaning participants performed the recall task, but without neurofeedback\u2014no visual bar was showing their brain activity."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 910, "end": 978, "score": 1, "text": "A final Transfer run without neurofeedback information was included.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 3984795, "edit_id": "7a2eaf828fa53f4769e16c0430166501", "source": "To evaluate the effects of probiotic (VSL#3) and omega-3 fatty acid on insulin sensitivity, blood lipids, and inflammation, we conducted a clinical trial in 60 overweight (BMI > 25), healthy adults, aged 40\u201360 years. After initial screening the subjects were randomized into four groups with 15 per group. The four groups received, respectively, placebo, omega-3 fatty acid, probiotic VSL#3, or both omega-3 and probiotic, for 6 weeks. Blood and fecal samples were collected at baseline and after 6 weeks. The probiotic (VSL#3) supplemented group had significant reduction in total cholesterol, triglyceride, LDL, and VLDL and had increased HDL (P < 0.05) value. VSL#3 improved insulin sensitivity (P < 0.01), decreased hsCRP, and favorably affected the composition of gut microbiota. Omega-3 had significant effect on insulin sensitivity and hsCRP but had no effect on gut microbiota. Addition of omega-3 fatty acid with VSL#3 had more pronounced effect on HDL, insulin sensitivity and hsCRP. Subjects with low HDL, insulin resistance, and high hsCRP had significantly lower total lactobacilli and bifidobacteria count and higher E. coli and bacteroides count.", "target": "We ran a study with 60 adults who were a bit overweight but otherwise healthy, all between 40 and 60 years old. The aim was to see the effects of probiotics (specifically, VSL#3) and omega-3 fatty acids on our body\u2019s response to insulin, cholesterol levels in the blood, and inflammation. \n\nParticipants were randomly sorted into four groups. The first group was given a placebo; the second group took omega-3 fatty acids; the third group took the probiotic VSL#3; the fourth group had both omega-3 and the probiotic, for a period of 6 weeks. We collected blood and stool samples at the start and end of the study.\n\nThe group that took the probiotic VSL#3 showed a significant reduction in bad cholesterol and triglycerides, along with an increase in good cholesterol. This probiotic also improved the body's response to insulin (which reduces risk of diabetes), reduced inflammation, and positively changed gut bacteria composition. \n\nOmega-3 alone improved the body's response to insulin and reduced inflammation, but didn't appear to affect gut bacteria. However, when omega-3 was used with VSL#3, the effects on good cholesterol, body's response to insulin, and inflammation were more pronounced.\n\nWe noticed that people with low amounts of good cholesterol, insulin resistance, and high inflammation had worse gut bacteria composition. They had significantly less 'good' bacteria (Lactobacilli and Bifidobacteria) and more of some specific 'bad' bacteria (E. coli and Bacteroides).", "question": "How were the levels of hsCRP in the subjects at the start of the study?", "answer": "At the start of the study, the subjects had high hsCRP levels. High hsCRP indicates inflammation in the body."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 886, "end": 993, "score": 1, "text": "Addition of omega-3 fatty acid with VSL#3 had more pronounced effect on HDL, insulin sensitivity and hsCRP.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 4006208, "edit_id": "167a0e0aa69ae343c159b21e92f7573d", "source": "BACKGROUND.\nDue to increasing resistance to antibiotics and rising incidence of oral diseases, there is a need for alternative treatment modalities to combat oral diseases. The aim of the present study was to access the effect of Aloe vera mouthwash on the dental plaque in the experimental period of 4 days and to compare it with the bench mark control chlorhexidine and placebo (saline water).\n\nMATERIAL AND METHODS.\nA total of 300 systemically healthy subjects were randomly allocated into 3 groups: Aloe vera mouthwash group (n=100), control group (=100)-chlorhexidene group and saline water-Placebo (n=100). To begin with, Gingival index (GI) and plaque index (PI) were recorded. Then, baseline plaque scores were brought to zero by professionally cleaning the teeth with scaling and polishing. After randomization of the participants into three groups they were refrained from regular mechanical oral hygiene measures. Subjects were asked to swish with respective mouthwash (Aloe vera mouthwash, 0.2%chlorhexidine gluconate mouthwash, or normal saline) as per therapeutic dose for 4 days.\n\nRESULTS.\nThe results showed that Aloe vera mouthrinse is equally effective in reducing plaque as Chlorhexidine compared to placebo over a period of 4 days. There was a significant reduction on plaque in Aloe vera and chlorhexidine groups and no statistically significant difference was observed among them (p>0.05). Aloe vera mouthwash showed no side effects.\n\nCONCLUSION.\nThe results of the present study indicated that Aloe vera may prove an effective mouthwash due to its ability in reducing dental plaque.", "target": "BACKGROUND.\nThere's a growing problem with antibiotics not working as effectively, and more people are experiencing oral diseases. This study was to see if Aloe vera mouthwash could help with oral health issues, particularly dental plaque. Specifically, we wanted to see how Aloe vera mouthwash worked over four days, compared to the usual mouthwash (chlorhexidine) and a mouthwash that isn't supposed to do anything (saline water).\n\nMaterial and Methods.\n300 healthy volunteers were split into three equal groups. One group used Aloe vera mouthwash, another used chlorhexidine mouthwash (the usual stuff), and the third used saline water (which doesn't do anything). At the start, we tested the health of everyone's gums (ginigval index) and how much plaque they had (plaque index). We then cleaned everyone's teeth professionally so everyone started with no plaque. For the next four days, the volunteers only used their assigned mouthwash, without brushing or flossing. \n\nRESULTS.\nThe study found that both the Aloe vera mouthwash and chlorhexidine mouthwash were equally good at reducing plaque over those four days. Meanwhile, the saline water didn't do much (as expected). The difference in plaque reduction between the Aloe vera mouthwash and chlorhexidine mouthwash wasn't significant enough to matter. Also, no one reported any bad side effects from the Aloe vera mouthwash.\n\nCONCLUSION.\nBased on this study, Aloe vera could be a good alternative mouthwash. It was successful in reducing dental plaque, just as effective as the usual chlorhexidine mouthwash, but without any side effects.", "question": "Was there a significant reduction in plaque in both the Aloe vera and chlorhexidine groups?", "answer": "Yes, there was a significant reduction in plaque in both the Aloe vera and chlorhexidine groups. The study found that the reduction in plaque was statistically significant in both groups (p>0.05)."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 1252, "end": 1411, "score": 1, "text": "There was a significant reduction on plaque in Aloe vera and chlorhexidine groups and no statistically significant difference was observed among them (p>0.05).", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 4065461, "edit_id": "498ce4fb99cef7b240aa7f412f45f64b", "source": "BACKGROUND.\nThis study investigated the effect of combining oral dexamethasone with either nebulized racemic epinephrine or salbutamol compared to bronchodilators alone for the treatment of infants with bronchiolitis.\n\nMATERIALS AND METHODS.\nThis was a double-blind, randomized controlled trial on infants (1 to 12 months) who were diagnosed in the emergency department with moderate-to-severe bronchiolitis. The primary outcome was the rate of hospital admission within 7 days of the first dose of treatment, and the secondary outcomes were changes in respiratory distress assessment instrument score, heart rate, respiratory rate, and oxygen saturation (O2 Sat) over a 4-hour observation period. Infants (n = 162) were randomly assigned to four groups: A (dexamethasone + racemic epinephrine) = 45, B (placebo and racemic epinephrine) =39, C (dexamethasone and salbutamol) = 40, or D (placebo and salbutamol) = 38.\n\nRESULTS.\nPatients who had received dexamethasone + epinephrine exhibited similar admission rates compared to placebo + epinephrine or salbutamol (P = 0.64). Similarly, no statistically significant difference was observed in the rate of hospitalization for patients who received dexamethasone + salbutamol compared to those who received placebo + epinephrine or salbutamol (P = 0.51). Clinical parameters were improved at the end of the 4-hour observation period for all treatment groups. Treatment with dexamethasone + epinephrine resulted in a statistically significant change in HR over time (P < 0.005) compared to the other groups.\n\nCONCLUSIONS.\nThis study adds to a body of evidence suggesting that corticosteroids have no role in the management of bronchiolitis for young infants who are first time wheezers with no risk of atopy.", "target": "BACKGROUND.\nThis research looked at how well infants with a common lung infection called bronchiolitis responded to different combinations of medicines. \n\nMATERIALS AND METHODS.\nThe study investigated the effects on babies between 1 to 12 months old. The babies were divided into four groups and were given different combinations of drugs. The major goal was to see if combining these drugs could reduce the need for hospital stays. \n\nRESULTS.\nThe study showed that the combination of dexamethasone and epinephrine resulted in the same number of hospital admissions as the other combinations. This was also the case for the combination of dexamethasone and salbutamol. However, the babies receiving these combinations showed improvements in their breathing and heart rates. \n\nCONCLUSIONS.\nThe study concluded that this does not support the use of corticosteroids (like dexamethasone) in managing bronchiolitis in young first-time wheezing infants.", "question": "Where were the infants diagnosed with bronchiolitis?", "answer": "The infants were diagnosed in the emergency department of a hospital."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 12, "end": 217, "score": 1, "text": "This study investigated the effect of combining oral dexamethasone with either nebulized racemic epinephrine or salbutamol compared to bronchodilators alone for the treatment of infants with bronchiolitis.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 4106715, "edit_id": "99ce09a9097d9812934ab4c3eaeb1d82", "source": "NicVAX\u00ae, a nicotine vaccine (3'AmNic-rEPA), has been clinically evaluated to determine if higher antibody concentrations are associated with higher smoking abstinence rates and if doses and frequency of administration are associated with increased antibody response. This randomized, double-blinded, placebo-controlled multicenter clinical trial (N=301 smokers) tested 200 and 400 \u03bcg doses administered 4 or 5 times over 6 months compared to placebo. 3'AmNic-rEPA recipients with the highest serum anti-nicotine antibody response (top 30% by AUC) were significantly more likely to attain 8 weeks continuous abstinence from weeks 19 through 26 than the placebo recipients (24.6% vs. 12.0%, p=0.024, OR=2.69, 95% CI, 1.14\u20136.37). The 5 injection 400 \u03bcg dose regimen had the greatest antibody response and had significantly higher abstinence rates than placebo. This study demonstrates proof-of-concept that 3'AmNic-rEPA elicits antibodies to nicotine and is associated with higher continuous abstinence rates, justifying its further development as a treatment for nicotine dependence.", "target": "Scientists have been testing a new nicotine vaccine, called NicVAX\u00ae, to see if it can help smokers quit. They wanted to know if more of the vaccine in the body leads to better quit rates and if giving more doses of the vaccine increases its effectiveness.\n\nThey conducted a study with 301 smokers, where some received either 200 or 400 \u03bcg doses of the vaccine, four or five times over six months, and others received a fake form of the vaccine (placebo). They found out that those who had the most significant immune response to the vaccine (the top 30%) were more likely to quit smoking for at least eight weeks compared to those who took the placebo (24.6% vs. 12.0%).\n\nInterestingly, those who had the regimen of five shots of the higher dose (400 \u03bcg) were more likely to quit smoking than the placebo group too.\n\nSo, this study shows that NicVAX\u00ae can stimulate the body to produce nicotine antibodies and help smokers quit. This encourages further research to develop the vaccine as a potential treatment for nicotine addiction.", "question": "How was the study designed to ensure its validity?", "answer": "The study was a randomized, double-blinded, placebo-controlled multicenter clinical trial. This means that the participants were randomly assigned to either the vaccine or placebo group, neither the participants nor the researchers knew which group each participant was in (double-blinded), and the study was conducted at multiple centers to increase the diversity of the participants and the generalizability of the results."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 267, "end": 450, "score": 1, "text": "This randomized, double-blinded, placebo-controlled multicenter clinical trial (N=301 smokers) tested 200 and 400 \u03bcg doses administered 4 or 5 times over 6 months compared to placebo.", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 257, "end": 454, "score": 1, "text": "They conducted a study with 301 smokers, where some received either 200 or 400 \u03bcg doses of the vaccine, four or five times over six months, and others received a fake form of the vaccine (placebo).", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 4202567, "edit_id": "66b08dac0ec61841289f459392c18b70", "source": "INTRODUCTION.\nWorking memory plays a critical role in cognitive processes which are central to our daily life. Neuroimaging studies have shown that one of the most important areas corresponding to the working memory is the dorsolateral prefrontal cortex (DLFPC). This study was aimed to assess whether bilateral modulation of the DLPFC using a noninvasive brain stimulation, namely transcranial direct current stimulation (tDCS), modifies the working memory function in healthy adults.\n\nMETHODS.\nIn a randomized sham-controlled cross-over study, 60 subjects (30 Males) received sham and active tDCS in two subgroups (anode left/cathode right and anode right/cathode left) of the DLPFC. Subjects were presented working memory n-back task while the reaction time and accuracy were recorded.\n\nRESULTS.\nA repeated measures, mixed design ANOVA indicated a significant difference between the type of stimulation (sham vs. active) in anodal stimulation of the left DLPFC with cathodal stimulation of the right DLPFC [F(1,55)= 5.29, P=0.019], but not the inverse polarity worsened accuracy in the 2-back working memory task. There were also no statistically significant changes in speed of working memory [F(1,55)= 0.458,P=0.502] related to type or order of stimulation.\n\nDISCUSSION.\nThe results would imply to a polarity dependence of bilateral tDCS of working memory. Left anodal/ right cathodal stimulation of DLPFC could impair working memory, while the reverser stimulation had no effect. Meaning that bilateral stimulation of DLFC would not be a useful procedure to improve working memory. Further studies are required to understand subtle effects of different tDCS stimulation/inhibition electrode positioning on the working memory.", "target": "INTRODUCTION.\nWorking memory is essential for how we learn, remember, and interact with the world. One area of the brain, the dorsolateral prefrontal cortex (DLFPC), is particularly important for working memory. Our goal in this study was to see if we could change how the DLPFC works to improve memory using a safe, non-invasive method called transcranial direct current stimulation (tDCS).\n\nMETHODS.\nWe had 60 people (half men, half women) take part in our study. We split them into two groups and used tDCS to stimulate different sides of their DLPFC. All participants were given tasks to test their working memory while we measured their speed and accuracy.\n\nRESULTS.\nOur analysis indicated that the type of stimulation mattered. When we stimulated the left side of the DLPFC and reduced activity on the right side, it clearly messed with participants' memory accuracy. However, doing the opposite didn't have any noticeable effect. No changes in speed were seen either way.\n\nDISCUSSION.\nOur results suggest that how we use tDCS on working memory matters, and that stimulating the left side of the DLPFC while reducing activity on the right could disrupt memory. This means that using tDCS on both sides of this part of the brain may not be helpful for improving memory. We need more research to understand better how different uses of tDCS can affect working memory.", "question": "Can you explain the role of working memory in cognitive processes?", "answer": "Working memory is responsible for temporarily holding and manipulating information in our minds. It is a critical component of cognitive processes such as learning, problem-solving, and decision-making."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 14, "end": 110, "score": 1, "text": "Working memory plays a critical role in cognitive processes which are central to our daily life.", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 14, "end": 98, "score": 1, "text": "Working memory is essential for how we learn, remember, and interact with the world.", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 4302388, "edit_id": "b3456d58ef84a4089f1e2339c43528a9", "source": "Dietary intake/status of the trace mineral Se may affect the risk of developing hypertensive conditions of pregnancy, i.e. pre-eclampsia and pregnancy-induced hypertension (PE/PIH). In the present study, we evaluated Se status in UK pregnant women to establish whether pre-pregnant Se status or Se supplementation affected the risk of developing PE/PIH. The samples originated from the SPRINT (Selenium in PRegnancy INTervention) study that randomised 230 UK primiparous women to treatment with Se (60 \u03bcg/d) or placebo from 12 weeks of gestation. Whole-blood Se concentration was measured at 12 and 35 weeks, toenail Se concentration at 16 weeks, plasma selenoprotein P (SEPP1) concentration at 35 weeks and plasma glutathione peroxidase (GPx3) activity at 12, 20 and 35 weeks. Demographic data were collected at baseline. Participants completed a FFQ. UK pregnant women had whole-blood Se concentration lower than the mid-range of other populations, toenail Se concentration considerably lower than US women, GPx3 activity considerably lower than US and Australian pregnant women, and low baseline SEPP1 concentration (median 3\u00b700, range 0\u00b790\u20135\u00b780 mg/l). Maternal age, education and social class were positively associated with Se status. After adjustment, whole-blood Se concentration was higher in women consuming Brazil nuts (P= 0\u00b7040) and in those consuming more than two seafood portions per week (P= 0\u00b7054). A stepwise logistic regression model revealed that among the Se-related risk factors, only toenail Se (OR 0\u00b738, 95 % CI 0\u00b717, 0\u00b787, P= 0\u00b7021) significantly affected the OR for PE/PIH. On excluding non-compliers with Se treatment, Se supplementation also significantly reduced the OR for PE/PIH (OR 0\u00b730, 95 % CI 0\u00b709, 1\u00b700, P= 0\u00b7049). In conclusion, UK women have low Se status that increases their risk of developing PE/PIH. Therefore, UK women of childbearing age need to improve their Se status.", "target": "This abstract is about a study that explored the connection between a mineral called selenium (Se) and high blood pressure conditions during pregnancy, specifically, pregnancy-induced hypertension (PIH) and pre-eclampsia (PE). Mothers-to-be who consume inadequate amounts of selenium may be more likely to develop these conditions.\n\nThe study involved 230 first-time mothers in the UK who were randomly chosen to either receive a selenium supplement or a placebo from the 12th week of pregnancy onwards. Researchers took multiple measurements and assessments related to the women's selenium levels throughout the pregnancy.\n\nThe researchers found that the selenium levels of pregnant women in the UK were lower compared to those of pregnant women in other countries. Factors like age, level of education, and social class positively impacted selenium levels. Women who ate Brazil nuts or consumed more than two seafood servings a week also showed higher selenium levels. \n\nThe research revealed that the lower the selenium level in the toenails (which is an indicator of the body's selenium status), the higher the chances were for a woman to develop PIH or PE. Women who took the selenium supplement were found to be less at risk of developing these conditions.\n\nTo sum up, the study concluded that women in the UK planning to have children should increase their selenium intake, as low levels of this mineral may increase their chances of developing PIH or PE.", "question": "How did maternal age, education, and social class affect selenium status?", "answer": "Maternal age, education, and social class were positively associated with selenium status, meaning that older, more educated, and higher social class women tended to have higher selenium levels."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 1156, "end": 1239, "score": 1, "text": "Maternal age, education and social class were positively associated with Se status.", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 767, "end": 858, "score": 1, "text": "Factors like age, level of education, and social class positively impacted selenium levels.", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 4302388, "edit_id": "25c78c9fd9cfede7f033a7a04c5b0fd3", "source": "Dietary intake/status of the trace mineral Se may affect the risk of developing hypertensive conditions of pregnancy, i.e. pre-eclampsia and pregnancy-induced hypertension (PE/PIH). In the present study, we evaluated Se status in UK pregnant women to establish whether pre-pregnant Se status or Se supplementation affected the risk of developing PE/PIH. The samples originated from the SPRINT (Selenium in PRegnancy INTervention) study that randomised 230 UK primiparous women to treatment with Se (60 \u03bcg/d) or placebo from 12 weeks of gestation. Whole-blood Se concentration was measured at 12 and 35 weeks, toenail Se concentration at 16 weeks, plasma selenoprotein P (SEPP1) concentration at 35 weeks and plasma glutathione peroxidase (GPx3) activity at 12, 20 and 35 weeks. Demographic data were collected at baseline. Participants completed a FFQ. UK pregnant women had whole-blood Se concentration lower than the mid-range of other populations, toenail Se concentration considerably lower than US women, GPx3 activity considerably lower than US and Australian pregnant women, and low baseline SEPP1 concentration (median 3\u00b700, range 0\u00b790\u20135\u00b780 mg/l). Maternal age, education and social class were positively associated with Se status. After adjustment, whole-blood Se concentration was higher in women consuming Brazil nuts (P= 0\u00b7040) and in those consuming more than two seafood portions per week (P= 0\u00b7054). A stepwise logistic regression model revealed that among the Se-related risk factors, only toenail Se (OR 0\u00b738, 95 % CI 0\u00b717, 0\u00b787, P= 0\u00b7021) significantly affected the OR for PE/PIH. On excluding non-compliers with Se treatment, Se supplementation also significantly reduced the OR for PE/PIH (OR 0\u00b730, 95 % CI 0\u00b709, 1\u00b700, P= 0\u00b7049). In conclusion, UK women have low Se status that increases their risk of developing PE/PIH. Therefore, UK women of childbearing age need to improve their Se status.", "target": "This abstract is about a study that explored the connection between a mineral called selenium (Se) and high blood pressure conditions during pregnancy, specifically, pregnancy-induced hypertension (PIH) and pre-eclampsia (PE). Mothers-to-be who consume inadequate amounts of selenium may be more likely to develop these conditions.\n\nThe study involved 230 first-time mothers in the UK who were randomly chosen to either receive a selenium supplement or a placebo from the 12th week of pregnancy onwards. Researchers took multiple measurements and assessments related to the women's selenium levels throughout the pregnancy.\n\nThe researchers found that the selenium levels of pregnant women in the UK were lower compared to those of pregnant women in other countries. Factors like age, level of education, and social class positively impacted selenium levels. Women who ate Brazil nuts or consumed more than two seafood servings a week also showed higher selenium levels. \n\nThe research revealed that the lower the selenium level in the toenails (which is an indicator of the body's selenium status), the higher the chances were for a woman to develop PIH or PE. Women who took the selenium supplement were found to be less at risk of developing these conditions.\n\nTo sum up, the study concluded that women in the UK planning to have children should increase their selenium intake, as low levels of this mineral may increase their chances of developing PIH or PE.", "question": "What are the specific conditions that the study found selenium may help prevent in pregnant women?", "answer": "The study found that selenium may help prevent pre-eclampsia and pregnancy-induced hypertension (PE/PIH) in pregnant women."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 0, "end": 181, "score": 1, "text": "Dietary intake/status of the trace mineral Se may affect the risk of developing hypertensive conditions of pregnancy, i.e. pre-eclampsia and pregnancy-induced hypertension (PE/PIH).", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 4302388, "edit_id": "8cd25e7dd00ee0ab42f1dc4a824c640b", "source": "Dietary intake/status of the trace mineral Se may affect the risk of developing hypertensive conditions of pregnancy, i.e. pre-eclampsia and pregnancy-induced hypertension (PE/PIH). In the present study, we evaluated Se status in UK pregnant women to establish whether pre-pregnant Se status or Se supplementation affected the risk of developing PE/PIH. The samples originated from the SPRINT (Selenium in PRegnancy INTervention) study that randomised 230 UK primiparous women to treatment with Se (60 \u03bcg/d) or placebo from 12 weeks of gestation. Whole-blood Se concentration was measured at 12 and 35 weeks, toenail Se concentration at 16 weeks, plasma selenoprotein P (SEPP1) concentration at 35 weeks and plasma glutathione peroxidase (GPx3) activity at 12, 20 and 35 weeks. Demographic data were collected at baseline. Participants completed a FFQ. UK pregnant women had whole-blood Se concentration lower than the mid-range of other populations, toenail Se concentration considerably lower than US women, GPx3 activity considerably lower than US and Australian pregnant women, and low baseline SEPP1 concentration (median 3\u00b700, range 0\u00b790\u20135\u00b780 mg/l). Maternal age, education and social class were positively associated with Se status. After adjustment, whole-blood Se concentration was higher in women consuming Brazil nuts (P= 0\u00b7040) and in those consuming more than two seafood portions per week (P= 0\u00b7054). A stepwise logistic regression model revealed that among the Se-related risk factors, only toenail Se (OR 0\u00b738, 95 % CI 0\u00b717, 0\u00b787, P= 0\u00b7021) significantly affected the OR for PE/PIH. On excluding non-compliers with Se treatment, Se supplementation also significantly reduced the OR for PE/PIH (OR 0\u00b730, 95 % CI 0\u00b709, 1\u00b700, P= 0\u00b7049). In conclusion, UK women have low Se status that increases their risk of developing PE/PIH. Therefore, UK women of childbearing age need to improve their Se status.", "target": "This abstract is about a study that explored the connection between a mineral called selenium (Se) and high blood pressure conditions during pregnancy, specifically, pregnancy-induced hypertension (PIH) and pre-eclampsia (PE). Mothers-to-be who consume inadequate amounts of selenium may be more likely to develop these conditions.\n\nThe study involved 230 first-time mothers in the UK who were randomly chosen to either receive a selenium supplement or a placebo from the 12th week of pregnancy onwards. Researchers took multiple measurements and assessments related to the women's selenium levels throughout the pregnancy.\n\nThe researchers found that the selenium levels of pregnant women in the UK were lower compared to those of pregnant women in other countries. Factors like age, level of education, and social class positively impacted selenium levels. Women who ate Brazil nuts or consumed more than two seafood servings a week also showed higher selenium levels. \n\nThe research revealed that the lower the selenium level in the toenails (which is an indicator of the body's selenium status), the higher the chances were for a woman to develop PIH or PE. Women who took the selenium supplement were found to be less at risk of developing these conditions.\n\nTo sum up, the study concluded that women in the UK planning to have children should increase their selenium intake, as low levels of this mineral may increase their chances of developing PIH or PE.", "question": "Among the selenium-related risk factors, which one significantly influenced the odds ratio for developing high blood pressure conditions during pregnancy?", "answer": "Among the selenium-related risk factors, only the selenium concentration in the toenails significantly influenced the odds of developing high blood pressure conditions during pregnancy."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 1240, "end": 1414, "score": 1, "text": "After adjustment, whole-blood Se concentration was higher in women consuming Brazil nuts (P= 0\u00b7040) and in those consuming more than two seafood portions per week (P= 0\u00b7054).", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 4302388, "edit_id": "9311ab6b7838229fd4b967bf4a45dce7", "source": "Dietary intake/status of the trace mineral Se may affect the risk of developing hypertensive conditions of pregnancy, i.e. pre-eclampsia and pregnancy-induced hypertension (PE/PIH). In the present study, we evaluated Se status in UK pregnant women to establish whether pre-pregnant Se status or Se supplementation affected the risk of developing PE/PIH. The samples originated from the SPRINT (Selenium in PRegnancy INTervention) study that randomised 230 UK primiparous women to treatment with Se (60 \u03bcg/d) or placebo from 12 weeks of gestation. Whole-blood Se concentration was measured at 12 and 35 weeks, toenail Se concentration at 16 weeks, plasma selenoprotein P (SEPP1) concentration at 35 weeks and plasma glutathione peroxidase (GPx3) activity at 12, 20 and 35 weeks. Demographic data were collected at baseline. Participants completed a FFQ. UK pregnant women had whole-blood Se concentration lower than the mid-range of other populations, toenail Se concentration considerably lower than US women, GPx3 activity considerably lower than US and Australian pregnant women, and low baseline SEPP1 concentration (median 3\u00b700, range 0\u00b790\u20135\u00b780 mg/l). Maternal age, education and social class were positively associated with Se status. After adjustment, whole-blood Se concentration was higher in women consuming Brazil nuts (P= 0\u00b7040) and in those consuming more than two seafood portions per week (P= 0\u00b7054). A stepwise logistic regression model revealed that among the Se-related risk factors, only toenail Se (OR 0\u00b738, 95 % CI 0\u00b717, 0\u00b787, P= 0\u00b7021) significantly affected the OR for PE/PIH. On excluding non-compliers with Se treatment, Se supplementation also significantly reduced the OR for PE/PIH (OR 0\u00b730, 95 % CI 0\u00b709, 1\u00b700, P= 0\u00b7049). In conclusion, UK women have low Se status that increases their risk of developing PE/PIH. Therefore, UK women of childbearing age need to improve their Se status.", "target": "This abstract is about a study that explored the connection between a mineral called selenium (Se) and high blood pressure conditions during pregnancy, specifically, pregnancy-induced hypertension (PIH) and pre-eclampsia (PE). Mothers-to-be who consume inadequate amounts of selenium may be more likely to develop these conditions.\n\nThe study involved 230 first-time mothers in the UK who were randomly chosen to either receive a selenium supplement or a placebo from the 12th week of pregnancy onwards. Researchers took multiple measurements and assessments related to the women's selenium levels throughout the pregnancy.\n\nThe researchers found that the selenium levels of pregnant women in the UK were lower compared to those of pregnant women in other countries. Factors like age, level of education, and social class positively impacted selenium levels. Women who ate Brazil nuts or consumed more than two seafood servings a week also showed higher selenium levels. \n\nThe research revealed that the lower the selenium level in the toenails (which is an indicator of the body's selenium status), the higher the chances were for a woman to develop PIH or PE. Women who took the selenium supplement were found to be less at risk of developing these conditions.\n\nTo sum up, the study concluded that women in the UK planning to have children should increase their selenium intake, as low levels of this mineral may increase their chances of developing PIH or PE.", "question": "What specific risk factors were found to affect the risk of developing PE/PIH in the study?", "answer": "The study found that toenail Se was the only Se-related risk factor that significantly affected the risk of developing PE/PIH."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 1415, "end": 1598, "score": 1, "text": "A stepwise logistic regression model revealed that among the Se-related risk factors, only toenail Se (OR 0\u00b738, 95 % CI 0\u00b717, 0\u00b787, P= 0\u00b7021) significantly affected the OR for PE/PIH.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 4313493, "edit_id": "e1b586d9fbdee458c18821f4bf0446c0", "source": "AIMS.\nThe aim was to compare efficacy and cost-effectiveness of bimatoprost 0.03% and brimonidine 0.2% in primary open-angle glaucoma (POAG)/ocular hypertension (OHT).\n\nSETTINGS AND DESIGN.\nOpen, randomized, cross-over, comparative study.\n\nMATERIALS AND METHODS.\nForty patients of POAG or OHT with intraocular pressure (IOP) <30 mm Hg were included in the study after a written informed consent. The patients were divided randomly into two groups of 20 patients each. Patients of group A were administered bimatoprost 0.03% eye drops once daily, and those of group B brimonidine 0.2% eye drops twice daily for a period of 4 weeks. After a washout period of 4 weeks, the patients were crossed over that is, group A was administered brimonidine 0.2% and group B bimatoprost 0.03%. Fall in IOP at 4 weeks was recorded. The daily cost of each drug was calculated by maximum retail price and the average number of drops per bottle. The cost-effectiveness was then calculated as the cost of drug/mm Hg fall in IOP.\n\nSTATISTICS.\nIndependent samples t-test was used to compare the efficacy of both drugs.\n\nRESULTS.\nIOP lowering with bimatoprost (8.9 \u00b1 1.598 mm Hg) was significantly (P < 0.0001) higher than brimonidine (6.55 \u00b1 1.26 mm Hg). The number of drops/ml were 33.43 \u00b1 0.52 and 25.49 \u00b1 0.26, respectively, for bimatoprost and brimonidine. Treatment with bimatoprost was costlier than brimonidine with daily costs/eye Rs. 4.02 \u00b1 0.06 and 3.14 \u00b1 0.03, yearly costs/eye Rs. 1467.46 \u00b1 20.74 and 1147.75 \u00b1 11.15, respectively. Bimatoprost was more cost-effective than brimonidine with the cost-effectiveness ratio (CER) respectively Rs. 13.10 \u00b1 2.61/mm Hg and Rs. 13.96 \u00b1 2.86/mm Hg. Incremental CER Rs. 10.43/mm Hg implies lower costs/mm Hg extra IOP lowering by bimatoprost than Rs. 13.96 for brimonidine.\n\nCONCLUSION.\nIn spite of being costlier, bimatoprost is more efficacious and cost-effective than brimonidine.", "target": "GOAL:\nWe wanted to see if two particular eye drops, bimatoprost 0.03% and brimonidine 0.2%, work well and are good value for money for people with a specific eye condition causing increased eye pressure (called primary open-angle glaucoma) or high eye pressure (ocular hypertension).\n\nHOW WE DID IT:\nWe carried out a study involving 40 volunteers who had these conditions but only mild eye pressure. We randomly divided them into two different groups. Half of them were given bimatoprost drops once a day, while the other half used brimonidine drops twice a day, for a month. After resting for a month, we switched the groups: the first group started using brimonidine, and the second group used bimatoprost. We recorded the drop in eye pressure after a month for both groups. We then calculated the cost per day of both treatments, and how much it cost per unit of pressure dropped (cost-effectiveness).\n\nHOW WE FIGURED OUT THE RESULTS:\nWe used a common statistical method to compare how effective both drugs were.\n\nRESULTS:\nWe found that bimatoprost was significantly more effective, reducing eye pressure more than brimonidine. However, bimatoprost was also more expensive on a per drop basis than brimonidine. Despite the higher price, when looking at the cost in relation to how much it lowers eye pressure, bimatoprost ended up being a more cost-effective option than brimonidine.\n\nCONCLUSION:\nAlthough it's a bit more expensive, bimatoprost is more effective and gives you more bang for your buck than brimonidine when it comes to treating these eye conditions.", "question": "How was the daily cost of each drug calculated?", "answer": "The daily cost of each drug was calculated by multiplying the maximum retail price by the average number of drops per bottle."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 816, "end": 926, "score": 1, "text": "The daily cost of each drug was calculated by maximum retail price and the average number of drops per bottle.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 4313493, "edit_id": "be1c51319df253d5e52c1ffb5d352c1a", "source": "AIMS.\nThe aim was to compare efficacy and cost-effectiveness of bimatoprost 0.03% and brimonidine 0.2% in primary open-angle glaucoma (POAG)/ocular hypertension (OHT).\n\nSETTINGS AND DESIGN.\nOpen, randomized, cross-over, comparative study.\n\nMATERIALS AND METHODS.\nForty patients of POAG or OHT with intraocular pressure (IOP) <30 mm Hg were included in the study after a written informed consent. The patients were divided randomly into two groups of 20 patients each. Patients of group A were administered bimatoprost 0.03% eye drops once daily, and those of group B brimonidine 0.2% eye drops twice daily for a period of 4 weeks. After a washout period of 4 weeks, the patients were crossed over that is, group A was administered brimonidine 0.2% and group B bimatoprost 0.03%. Fall in IOP at 4 weeks was recorded. The daily cost of each drug was calculated by maximum retail price and the average number of drops per bottle. The cost-effectiveness was then calculated as the cost of drug/mm Hg fall in IOP.\n\nSTATISTICS.\nIndependent samples t-test was used to compare the efficacy of both drugs.\n\nRESULTS.\nIOP lowering with bimatoprost (8.9 \u00b1 1.598 mm Hg) was significantly (P < 0.0001) higher than brimonidine (6.55 \u00b1 1.26 mm Hg). The number of drops/ml were 33.43 \u00b1 0.52 and 25.49 \u00b1 0.26, respectively, for bimatoprost and brimonidine. Treatment with bimatoprost was costlier than brimonidine with daily costs/eye Rs. 4.02 \u00b1 0.06 and 3.14 \u00b1 0.03, yearly costs/eye Rs. 1467.46 \u00b1 20.74 and 1147.75 \u00b1 11.15, respectively. Bimatoprost was more cost-effective than brimonidine with the cost-effectiveness ratio (CER) respectively Rs. 13.10 \u00b1 2.61/mm Hg and Rs. 13.96 \u00b1 2.86/mm Hg. Incremental CER Rs. 10.43/mm Hg implies lower costs/mm Hg extra IOP lowering by bimatoprost than Rs. 13.96 for brimonidine.\n\nCONCLUSION.\nIn spite of being costlier, bimatoprost is more efficacious and cost-effective than brimonidine.", "target": "GOAL:\nWe wanted to see if two particular eye drops, bimatoprost 0.03% and brimonidine 0.2%, work well and are good value for money for people with a specific eye condition causing increased eye pressure (called primary open-angle glaucoma) or high eye pressure (ocular hypertension).\n\nHOW WE DID IT:\nWe carried out a study involving 40 volunteers who had these conditions but only mild eye pressure. We randomly divided them into two different groups. Half of them were given bimatoprost drops once a day, while the other half used brimonidine drops twice a day, for a month. After resting for a month, we switched the groups: the first group started using brimonidine, and the second group used bimatoprost. We recorded the drop in eye pressure after a month for both groups. We then calculated the cost per day of both treatments, and how much it cost per unit of pressure dropped (cost-effectiveness).\n\nHOW WE FIGURED OUT THE RESULTS:\nWe used a common statistical method to compare how effective both drugs were.\n\nRESULTS:\nWe found that bimatoprost was significantly more effective, reducing eye pressure more than brimonidine. However, bimatoprost was also more expensive on a per drop basis than brimonidine. Despite the higher price, when looking at the cost in relation to how much it lowers eye pressure, bimatoprost ended up being a more cost-effective option than brimonidine.\n\nCONCLUSION:\nAlthough it's a bit more expensive, bimatoprost is more effective and gives you more bang for your buck than brimonidine when it comes to treating these eye conditions.", "question": "What was the number of drops per ml for each drug?", "answer": "The number of drops per ml for bimatoprost was 33.43 \u00b1 0.52, and for brimonidine, it was 25.49 \u00b1 0.26."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 1233, "end": 1338, "score": 1, "text": "The number of drops/ml were 33.43 \u00b1 0.52 and 25.49 \u00b1 0.26, respectively, for bimatoprost and brimonidine.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 4323432, "edit_id": "c2b21bf8c3fc9290453f1e75e60e5087", "source": "BACKGROUND/AIMS.\nSuppression of gastrointestinal (GI) peristalsis during GI endoscopy commonly requires antispasmodic agents such as hyoscine butylbromide, atropine, glucagon, and cimetropium bromide. This study examined the efficacy of oral phloroglucin for the suppression of peristalsis, its impact on patient compliance, and any associated complications, and compared it with intravenous or intramuscular cimetropium bromide administration.\n\nMETHODS.\nThis was a randomized, investigator-blind, prospective comparative study. A total of 172 patients were randomized into two groups according to the following medications administered prior to upper endoscopy: oral phloroglucin (group A, n=86), and cimetropium bromide (group B, n=86). The numbers and the degrees of peristalsis events at the antrum and second duodenal portion were assessed for 30 seconds.\n\nRESULTS.\nA significantly higher number of gastric peristalsis events was observed in group A (0.49 vs. 0.08, p<0.001), but the difference was not clinically significant. No significant difference between both groups was found in the occurrence of duodenal peristalsis events (1.79 vs. 1.63, p=0.569). The incidence of dry mouth was significantly higher with cimetropium bromide than with phloroglucin (50% vs. 15.1%, p<0.001).\n\nCONCLUSIONS.\nOral phloroglucin can be used as an antispasmodic agent during upper endoscopy, and shows antispasmodic efficacy and adverse effects similar to those of cimetropium bromide.", "target": "BACKGROUND/GOALS\nDuring certain stomach and gut examinations (like endoscopy), it's common to use medications that help relax these areas. This study looked at how well taking a certain medication, called phloroglucin, worked for this purpose, and how well it was tolerated by patients. Its effects were compared to another medication known as cimetropium bromide that's normally given by injection.\n\nMETHODS\nThe study was conducted blindly and participants were randomly divided into two groups. Each group was given a different medication before the endoscopy. Group A received phloroglucin orally, and group B received cimetropium bromide. The researchers then looked at the number and intensity of muscle contractions in two specific parts of the digestive system for 30 seconds.\n\nRESULTS\nThey found that the group taking phloroglucin had more stomach muscle contractions, but the difference wasn't important in a clinical sense. There was no significant difference in muscle contractions in the first part of the small intestine between the two groups. More patients who received cimetropium bromide reported dry mouth than those who took phloroglucin.\n\nCONCLUSIONS\nPhloroglucin taken orally appears to work as effectively as cimetropium bromide for relaxing the stomach and gut during an endoscopy. It also seems to have similar side effects. The advantage of phloroglucin is that it's less likely to cause dry mouth.", "question": "Where in the digestive system did the researchers assess the number and intensity of muscle contractions?", "answer": "The researchers assessed the number and intensity of muscle contractions at the antrum, which is the lower portion of the stomach, and the second portion of the duodenum, which is the first part of the small intestine."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 739, "end": 860, "score": 1, "text": "The numbers and the degrees of peristalsis events at the antrum and second duodenal portion were assessed for 30 seconds.", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 643, "end": 783, "score": 1, "text": "The researchers then looked at the number and intensity of muscle contractions in two specific parts of the digestive system for 30 seconds.", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 4334515, "edit_id": "8f8f30a7d90806dd5bcbe25df3417717", "source": "BACKGROUND.\nThe World Health Organization stresses the importance of accessible and (cost)effective caregiver support, given the expected increase in the number of people with dementia and the detrimental impact on the mental health of family caregivers.\n\nMETHODS.\nThis study assessed the effectiveness of the Internet intervention 'Mastery over Dementia'. In a RCT, 251 caregivers, of whom six were lost at baseline, were randomly assigned to two groups. Caregivers in the experimental group (N = 149) were compared to caregivers who received a minimal intervention consisting of e-bulletins (N = 96). Outcomes were symptoms of depression (Center for Epidemiologic Studies Depression Scale: CES-D) and anxiety (Hospital Anxiety and Depression Scale: HADS-A). All data were collected via the Internet, and an intention-to-treat analysis was carried out.\n\nRESULTS.\nAlmost all caregivers were spouses or children (in-law). They were predominantly female and lived with the care recipient in the same household. Age of the caregivers varied from 26 to 87 years. Level of education varied from primary school to university, with almost half of them holding a bachelor's degree or higher. Regression analyses showed that caregivers in the experimental group showed significantly lower symptoms of depression (p = .034) and anxiety (p = .007) post intervention after adjustment for baseline differences in the primary outcome scores and the functional status of the patients with dementia. Effect sizes were moderate for symptoms of anxiety (.48) and small for depressive symptoms (.26).\n\nCONCLUSIONS.\nThe Internet course 'Mastery over Dementia' offers an effective treatment for family caregivers of people with dementia reducing symptoms of depression and anxiety. The results of this study justify further development of Internet interventions for family caregivers of people with dementia and suggest that such interventions are promising for keeping support for family caregivers accessible and affordable. The findings are even more promising because future generations of family caregivers will be more familiar with the Internet.\n\nTRIAL REGISTRATION.\nDutch Trial Register NTR-2051 www.trialregister.nl/trialreg/admin/rctview.asp?TC=2051", "target": "BACKGROUND:\nThe World Health Organization emphasizes that support for caregivers, especially those taking care of people with dementia, should be both affordable and easy to access. This is due to the growing number of people who have dementia and the negative effects on the mental health of the family members who care for them.\n\nMETHODS:\nWe ran a study to see if an online program called 'Mastery over Dementia' could help. We had 251 caregivers participate, but 6 dropped out right at the beginning. The caregivers were randomly split into two groups. One group (149 people) used the online program and we compared them to the second group (96 people) who only received informational emails. We wanted to see if there was a change in signs of depression and anxiety. The caregivers answered all our questions through the internet and we made sure to include everyone's data in the final analysis.\n\nRESULTS:\nMost of the caregivers were husbands, wives, or children of the person with dementia. Most of them were women who lived in the same house as the person they were caring for. Their ages ranged from 26 to 87 and their education background varied greatly, with about half having at least a college degree. We discovered that the caregivers who used the online program had noticeably less signs of depression and anxiety after using the program.\n\nCONCLUSIONS:\nOur study shows that the 'Mastery over Dementia' online program can be a useful tool for family caregivers of people with dementia since it reduces signs of depression and anxiety. This suggests that developing more online resources like this could be beneficial for family caregivers, making support more accessible and financially manageable. This is promising for the future generations of caregivers who will likely be familiar with using the internet.\n\nTRIAL REGISTRATION:\nYou can find more details about this study in the Dutch Trial Register under the code NTR-2051.", "question": "How did the researchers measure the levels of depression in the caregivers?", "answer": "The researchers measured the levels of depression in the caregivers using a tool called the Center for Epidemiologic Studies Depression Scale (CES-D)."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 603, "end": 759, "score": 1, "text": "Outcomes were symptoms of depression (Center for Epidemiologic Studies Depression Scale: CES-D) and anxiety (Hospital Anxiety and Depression Scale: HADS-A).", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 4360612, "edit_id": "94625ddaa66c680d725e2e5c7ca21285", "source": "BACKGROUND.\nSacroiliac (SI) joint pain is a prevalent, underdiagnosed cause of lower back pain. SI joint fusion can relieve pain and improve quality of life in patients who have failed nonoperative care. To date, no study has concurrently compared surgical and non-surgical treatments for chronic SI joint dysfunction.\n\nMETHODS.\nWe conducted a prospective randomized controlled trial of 148 subjects with SI joint dysfunction due to degenerative sacroiliitis or sacroiliac joint disruptions who were assigned to either minimally invasive SI joint fusion with triangular titanium implants (N=102) or non-surgical management (NSM, n=46). SI joint pain scores, Oswestry Disability Index (ODI), Short-Form 36 (SF-36) and EuroQol-5D (EQ-5D) were collected at baseline and at 1, 3 and 6 months after treatment commencement. Six-month success rates, defined as the proportion of treated subjects with a 20-mm improvement in SI joint pain in the absence of severe device-related or neurologic SI joint-related adverse events or surgical revision, were compared using Bayesian methods.\n\nRESULTS.\nSubjects (mean age 51, 70% women) were highly debilitated at baseline (mean SI joint VAS pain score 82, mean ODI score 62). Six-month follow-up was obtained in 97.3%. By 6 months, success rates were 81.4% in the surgical group vs. 23.9% in the NSM group (difference of 56.6%, 95% posterior credible interval 41.4-70.0%, posterior probability of superiority >0.999). Clinically important (\u226515 point) ODI improvement at 6 months occurred in 75% of surgery subjects vs. 27.3% of NSM subjects. At six months, quality of life improved more in the surgery group and satisfaction rates were high. The mean number of adverse events in the first six months was slightly higher in the surgical group compared to the non-surgical group (1.3 vs. 1.0 events per subject, p=0.1857).\n\nCONCLUSIONS.\nSix-month follow-up from this level 1 study showed that minimally invasive SI joint fusion using triangular titanium implants was more effective than non-surgical management in relieving pain, improving function and improving quality of life in patients with SI joint dysfunction due to degenerative sacroiliitis or SI joint disruptions.\n\nCLINICAL RELEVANCE.\nMinimally invasive SI joint fusion is an acceptable option for patients with chronic SI joint dysfunction due to degenerative sacroiliitis and sacroiliac joint disruptions unresponsive to non-surgical treatments.", "target": "BACKGROUND.\nLower back pain is often caused by a problem in the area where your spine connects to your hips, called the sacroiliac joint. Sometimes, this pain can be treated by using surgery to fuse or join together parts of this joint. However, we don't have any studies yet that have compared how patients do with this surgery versus without it.\n\nMETHODS.\nWe set up a study with 148 patients who had problems with their sacroiliac joint. We randomly picked some to get a special kind of low-impact surgery (102 people), while others (46 people) were treated without surgery. We measured how much pain and disability our patients were feeling when the study started. Then, we checked on them 1, 3, and 6 months after treatment to see if there was an improvement. \n\nRESULTS.\nOur patients, most of whom were women and averaged 51 years of age, were having a lot of trouble with pain and disability at the start of the study. We were able to follow up with almost all of them at the six-month mark. By then, about 81.4% of the surgery patients were doing significantly better, compared to 23.9% of the non-surgery group. Also, 75% of the surgery group showed great improvement in how they were able to move around and do daily activities versus 27.3% in the non-surgery group. Finally, the surgery patients generally felt happier and more satisfied. \nHowever, it's worth mentioning that slightly more surgery patients experienced complications or side effects than non-surgery patients.\n\nCONCLUSIONS.\nAfter six months, the results of our high-level study show that the low-impact surgery is much more effective than non-surgery treatment in reducing pain, improving motion, and increasing the happiness of patients who have problems with their sacroiliac joint.\n\nCLINICAL RELEVANCE. \nThis less-invasive surgery could be a good treatment option for patients with sacroiliac joint problems who aren't finding relief from non-surgical treatments.", "question": "What measures were used to assess the subjects' pain and disability?", "answer": "The study used several measures to assess the subjects' pain and disability. These included the SI joint pain scores, the Oswestry Disability Index (ODI), the Short-Form 36 (SF-36), and the EuroQol-5D (EQ-5D). These measures were collected at the start of the study and at 1, 3, and 6 months after treatment began."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 636, "end": 817, "score": 1, "text": "SI joint pain scores, Oswestry Disability Index (ODI), Short-Form 36 (SF-36) and EuroQol-5D (EQ-5D) were collected at baseline and at 1, 3 and 6 months after treatment commencement.", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 577, "end": 667, "score": 1, "text": "We measured how much pain and disability our patients were feeling when the study started.", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 4472927, "edit_id": "9defba365b580c28d182d4c651fb21db", "source": "Different amounts of ingested alcohol can have distinct effects on the human body. However, there is limited research on chronic alcohol consumption with Helicobacter pylori infection. We sought to investigate the relationship between the cytokine profile, oxidative balance and H. pylori infection in subjects with chronic alcohol consumption. A total of 142 subjects were divided into three groups: 59 subjects with chronic alcohol ingestion and H. pylori infection (group A); 53 subjects with chronic alcohol ingestion without H. pylori infection (group B); and 30 control subjects (group C). The serum levels of CagA, interleukin (IL)-10, E-selectin, TNF-\u03b1, malondialdehyde (MDA) and superoxide dismutase (SOD) activity were measured by enzyme-linked immunosorbent assay (ELISA). We found that the ages and serum H. pylori CagA levels among the three groups, as well as both the mean drinking age and the mean daily alcohol consumption between groups A and B, were matched and comparable. Comparing the BMIs among the three groups, the BMI differences were found to be statistically significant (F=3.921, P<0.05). Compared with group C, the BMIs in groups A and B were significantly higher (P<0.001 and P<0.01, respectively); however, the BMI differences between group A and group B were not statistically significant (P>0.05). Additionally, no differences in the serum CagA levels were found in comparisons among the groups (all P>0.05). The serum IL-10 and E-selectin levels in group A were significantly lower than those in group B (serum IL-10: P<0.05; E-selectin: P<0.05). The serum IL-10 in group A was significantly higher than that in group C (P<0.01); the serum E-selectin levels in group A did not significantly differ compared with those in group C (P>0.05). Furthermore, the serum IL-10 and E-selectin levels in group B were significantly higher than those in group C (serum IL-10: P<0.001; E-selectin: P<0.05); however, the serum TNF-\u03b1 levels did not differ among groups (all P>0.05). Although the serum levels of MDA and SOD in groups A and B were slightly lower than those in group C, there were no significant differences among groups (all P>0.05). In conclusion, we believe that H. pylori infection might cause a significant inhibition of certain cytokine profiles in subjects with chronic alcohol ingestion. Moreover, chronically ingested alcohol may exert an adjusted inflammatory effect, but there was no association between H. pylori infection, chronic alcohol consumption and oxidative balance.", "target": "We wanted to understand how long-term alcohol intake relates to a specific stomach infection caused by a bacteria called H. pylori. We studied various body responses and inflammation markers in three groups of people, totaling 142 subjects in all. Group A consisted of 59 people who drink alcohol regularly and have the H. pylori infection. Group B had 53 subjects who drink alcohol regularly but do not have the infection. Finally, Group C was the control group of 30 people who neither drink alcohol regularly nor are infected.\n\nBody mass index (BMI), a measure of body size based on height and weight, was generally higher in those who drank alcohol frequently whether infected with H. pylori or not. However, the difference in BMI wasn't significant between those who were infected and those who weren't.\n\nGenerally, certain substances that signify inflammation were different between the groups. For example, lower levels of two inflammation markers, IL-10 and E-selectin, were found in those who drank alcohol and were infected with H. pylori compared to those that weren't infected. Those who drank alcohol but weren't infected showed higher levels of these markers than the control group.\n\nHowever, the levels of another inflammation marker, TNF-\u03b1, were not very different among the groups. Levels of substances that signify cell damage were also not significantly different among the groups.\n\nTo sum it all up, we think that the H. pylori infection might weaken certain inflammation responses in those who drink alcohol regularly. Also, regular alcohol drinking might adjust inflammation levels. However, we found no relationship between the infection or regular alcohol drinking and cell damage.", "question": "What was the main goal of the study?", "answer": "The main goal of the study was to understand how long-term alcohol intake relates to a specific stomach infection caused by a bacteria called H. pylori."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 185, "end": 344, "score": 1, "text": "We sought to investigate the relationship between the cytokine profile, oxidative balance and H. pylori infection in subjects with chronic alcohol consumption.", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 0, "end": 130, "score": 1, "text": "We wanted to understand how long-term alcohol intake relates to a specific stomach infection caused by a bacteria called H. pylori", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 4472927, "edit_id": "2534faf9e80de0bac9381938829be212", "source": "Different amounts of ingested alcohol can have distinct effects on the human body. However, there is limited research on chronic alcohol consumption with Helicobacter pylori infection. We sought to investigate the relationship between the cytokine profile, oxidative balance and H. pylori infection in subjects with chronic alcohol consumption. A total of 142 subjects were divided into three groups: 59 subjects with chronic alcohol ingestion and H. pylori infection (group A); 53 subjects with chronic alcohol ingestion without H. pylori infection (group B); and 30 control subjects (group C). The serum levels of CagA, interleukin (IL)-10, E-selectin, TNF-\u03b1, malondialdehyde (MDA) and superoxide dismutase (SOD) activity were measured by enzyme-linked immunosorbent assay (ELISA). We found that the ages and serum H. pylori CagA levels among the three groups, as well as both the mean drinking age and the mean daily alcohol consumption between groups A and B, were matched and comparable. Comparing the BMIs among the three groups, the BMI differences were found to be statistically significant (F=3.921, P<0.05). Compared with group C, the BMIs in groups A and B were significantly higher (P<0.001 and P<0.01, respectively); however, the BMI differences between group A and group B were not statistically significant (P>0.05). Additionally, no differences in the serum CagA levels were found in comparisons among the groups (all P>0.05). The serum IL-10 and E-selectin levels in group A were significantly lower than those in group B (serum IL-10: P<0.05; E-selectin: P<0.05). The serum IL-10 in group A was significantly higher than that in group C (P<0.01); the serum E-selectin levels in group A did not significantly differ compared with those in group C (P>0.05). Furthermore, the serum IL-10 and E-selectin levels in group B were significantly higher than those in group C (serum IL-10: P<0.001; E-selectin: P<0.05); however, the serum TNF-\u03b1 levels did not differ among groups (all P>0.05). Although the serum levels of MDA and SOD in groups A and B were slightly lower than those in group C, there were no significant differences among groups (all P>0.05). In conclusion, we believe that H. pylori infection might cause a significant inhibition of certain cytokine profiles in subjects with chronic alcohol ingestion. Moreover, chronically ingested alcohol may exert an adjusted inflammatory effect, but there was no association between H. pylori infection, chronic alcohol consumption and oxidative balance.", "target": "We wanted to understand how long-term alcohol intake relates to a specific stomach infection caused by a bacteria called H. pylori. We studied various body responses and inflammation markers in three groups of people, totaling 142 subjects in all. Group A consisted of 59 people who drink alcohol regularly and have the H. pylori infection. Group B had 53 subjects who drink alcohol regularly but do not have the infection. Finally, Group C was the control group of 30 people who neither drink alcohol regularly nor are infected.\n\nBody mass index (BMI), a measure of body size based on height and weight, was generally higher in those who drank alcohol frequently whether infected with H. pylori or not. However, the difference in BMI wasn't significant between those who were infected and those who weren't.\n\nGenerally, certain substances that signify inflammation were different between the groups. For example, lower levels of two inflammation markers, IL-10 and E-selectin, were found in those who drank alcohol and were infected with H. pylori compared to those that weren't infected. Those who drank alcohol but weren't infected showed higher levels of these markers than the control group.\n\nHowever, the levels of another inflammation marker, TNF-\u03b1, were not very different among the groups. Levels of substances that signify cell damage were also not significantly different among the groups.\n\nTo sum it all up, we think that the H. pylori infection might weaken certain inflammation responses in those who drink alcohol regularly. Also, regular alcohol drinking might adjust inflammation levels. However, we found no relationship between the infection or regular alcohol drinking and cell damage.", "question": "What is the topic of the research?", "answer": "The topic of the research is the relationship between chronic alcohol consumption and Helicobacter pylori infection."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 83, "end": 183, "score": 1, "text": "However, there is limited research on chronic alcohol consumption with Helicobacter pylori infection", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 4493951, "edit_id": "4942602e3c0a2b113940c43501dc931a", "source": "BACKGROUND.\nLow-dose haloperidol is known to be effective for the prevention of postoperative nausea and vomiting (PONV). However, precise dose-response studies have not been completed, especially in patients at high risk for PONV who require combination therapy. This study sought to identify which dose of haloperidol 1mg or 2mg could be combined with dexamethasone without adverse effects in high-risk patients undergoing gynecological laparoscopic surgery.\n\nMETHODS.\nFemale adults (n = 150) with three established PONV risk factors based on Apfel's score were randomized into one of three study groups. At the end of anesthesia, groups H0, H1, and H2 were given intravenous (IV) saline, haloperidol 1 mg, and haloperidol 2 mg, respectively. All patients were given dexamethasone 5 mg during the induction of anesthesia. The overall early (0\u20132 h) and late (2\u201324 h) incidences of nausea, vomiting, rescue anti-emetic administration, pain, and adverse effects (cardiac arrhythmias and extrapyramidal effects) were assessed postoperatively. The sedation score was recorded in the postanesthesia care unit (PACU).\n\nRESULTS.\nThe total incidence of PONV over 24 h was significantly lower in groups H1 (29 %) and H2 (24 %) than in group H0 (54 %; P = 0.003), but there was no significant difference between groups H1 and H2. In the PACU, group H2 had a higher sedation score than groups H1 and H0 (P < 0.001).\n\nCONCLUSIONS.\nFor high-risk PONV patients undergoing gynecological laparoscopic surgery, when used with dexamethasone, 1-mg haloperidol was equally effective as 2 mg in terms of preventing PONV with the less sedative effect.\n\nTRIAL REGISTRATION.\nClinicalTrials.gov (NCT01639599).", "target": "BACKGROUND.\nThis study looked at the best dosage of a drug called haloperidol to use in combination with another drug, dexamethasone, to prevent nausea and vomiting after surgery. The focus was on people who were at high risk of nausea and vomiting, specifically women having keyhole surgery on their reproductive organs.\n\nMETHODS.\nThe study involved 150 adult women who had a high risk of nausea and vomiting after surgery. They were divided into three groups. At the end of the anesthesia, the first group was given a harmless saline solution, the second group was given 1 mg of haloperidol, and the third group was given 2 mg of haloperidol. Everyone was given 5 mg of dexamethasone when they were first put to sleep for the surgery. The researchers then kept track of nausea, vomiting, use of other medicines to stop vomiting, pain, and side effects in the next 24 hours. They also assessed how sleepy the patients were after the surgery in the recovery room.\n\nRESULTS.\nOverall, fewer people felt sick or vomited in the 24 hours after surgery in the groups given haloperidol (29% in the 1 mg group and 24% in the 2 mg group) compared to the group given saline (54%). But there was no difference in results between the 1 mg and 2 mg haloperidol groups. The people given 2 mg of haloperidol were sleepier than the others after the surgery.\n\nCONCLUSIONS.\nFor women having keyhole surgery on their reproductive organs who are at high risk of feeling sick or vomiting after surgery, 1 mg of haloperidol worked just as well as 2 mg in preventing these issues when used with dexamethasone. Plus, they didn't get as sleepy with the 1 mg dose.\n\nTRIAL REGISTRATION.\nThis trial was registered at ClinicalTrials.gov with the code NCT01639599.\n", "question": "What sort of procedure are the women in the study going through?", "answer": "The women in the study are going through gynecological laparoscopic surgery. This is a minimally invasive surgery on the female reproductive organs."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 1321, "end": 1405, "score": 1, "text": "In the PACU, group H2 had a higher sedation score than groups H1 and H0 (P < 0.001).", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 4517637, "edit_id": "453ac4607061c9537fe188aeec6909d2", "source": "BACKGROUND.\nInfants undergoing cardiac surgery are at risk of a negative protein balance, due to increased proteolysis in response to surgery and the cardiopulmonary bypass circuit, and limited intake. The aim of the study was to quantify the effect on protein kinetics of a short-term high-protein (HP) diet in infants following cardiac surgery.\n\nMETHODS.\nIn a prospective, double-blinded, randomized trial we compared the effects of a HP (5 g \u00b7 kg\u22121 \u00b7 d\u22121) versus normal protein (NP, 2 g \u00b7 kg\u22121 \u00b7 d\u22121) enteral diet on protein kinetics in children <24 months, on day 2 following surgical repair of congenital heart disease. Valine kinetics and fractional albumin synthesis rate (FSRalb) were measured with mass spectrometry using [1-13C]valine infusion. The Mann\u2013Whitney U test was used to investigate differences between group medians. Additionally, the Hodges-Lehmann procedure was used to create a confidence interval with a point estimate of median differences between groups.\n\nRESULTS.\nTwenty-eight children (median age 9 months, median weight 7 kg) participated in the study, of whom in only 20 subjects isotopic data could be used for final calculations. Due to underpowering of our study, we could not draw conclusions on the primary outcome parameters. We observed valine synthesis rate of 2.73 (range: 0.94 to 3.36) and 2.26 (1.85 to 2.73) \u03bcmol \u00b7 kg\u22121 \u00b7 min\u22121 in the HP and NP diet, respectively. The net valine balance was 0.54 (\u22120.73 to 1.75) and 0.24 (\u22120.20 to 0.63) \u03bcmol \u00b7 kg\u22121 \u00b7 min\u22121 in the HP and NP group. Between groups, there was no difference in FSRalb. We observed increased oxidation and BUN in the HP diet, compared to the NP diet, as a plausible explanation of the metabolic fate of surplus protein.\n\nCONCLUSIONS.\nIt is plausible that the surplus protein in the HP group has caused the increase of valine oxidation and ureagenesis, compared to the NP group. Because too few patients had completed the study, we were unable to draw conclusions on the effect of a HP diet on protein synthesis and balance. We present our results as new hypothesis generating data.\n\nTRIAL REGISTRATION.\nDutch Trial Register NTR2334.", "target": "BACKGROUND.\nBabies who have heart surgery may not get enough protein. This is because having surgery and using a heart-lung machine during the operation might break down protein faster than normal, and these babies might not eat enough to replace it. This study was done to see how giving these babies more protein after surgery would affect their protein levels.\n\nMETHODS.\nWe conducted a study where we randomly chose some babies to get a lot of protein and some to get a normal amount. This was done on the second day after they had surgery to fix heart defects they were born with. We did a special test to measure how much of a kind of protein called \"valine\" their bodies were making. We also measured how much of another protein called \"albumin\" their bodies were making. We then compared the results between the two groups.\n\nRESULTS.\n28 babies, who were around 9 months old and weighed about 7 kg, took part in the study. However, we could only use the data from 20 of them for our final results. Because we didn't have enough data, we couldn't make conclusions about protein levels. There was no difference in albumin production between the two groups. However, we saw that the babies getting a lot of protein had higher levels of valine and another substance called BUN, which is an indicator of how much protein a person is getting.\n\nCONCLUSIONS.\nIt looks like the extra protein in the diet of the high-protein group might have increased the levels of valine and BUN. However, because we didn't have enough data, we can't say for sure that a high-protein diet would change protein levels in these babies. Therefore, the results from our study should be taken as a starting point for further research.\n\nTRIAL REGISTRATION.\nThis trial was registered with the Dutch Trial Register (NTR2334).", "question": "Why were the researchers unable to draw conclusions on the effect of a HP diet on protein synthesis and balance?", "answer": "The study was underpowered due to too few patients completing it, which made it impossible to draw conclusions on the effect of a HP diet on protein synthesis and balance."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 1884, "end": 2029, "score": 1, "text": "Because too few patients had completed the study, we were unable to draw conclusions on the effect of a HP diet on protein synthesis and balance.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 4577567, "edit_id": "93dcbf6eefeac7f0f7f17a827f07913c", "source": "Stride length analysis represents an easy method for assessing race walking kinematics. However, the stride parameters emerging from such an analysis have never been used to design a training protocol aimed at increasing stride length. With this aim, we investigated the effects of stride frequency manipulation during three weeks of uphill (2%) training on stride length at iso-efficiency speed. Twelve male race walkers were randomly allocated to one of two training groups: stride frequency manipulation (RWM, n=6) and free stride frequency (RWF, n=6). Results. Kinematic parameters measured before and after the 3-week training in RWM showed increased stride length (4.54%; p<0.0001) and contact time (4.58%; p<0.001); inversely, a decreased stride frequency (4.44%; p<0.0001) and internal work (7.09%; p<0.05) were found. In RWF the effect of the training showed a decrease in stride length (1.18%; p<0.0001) and contact time (<1%; p<0.0001) with respect to baseline conditions and an increased stride frequency and internal work of 1.19% (p<0.0001). These results suggest that using slopes (2%) as RWM could help coaches to provide some training methods that would improve an athlete's performance, through increasing stride length without altering his or her race walking technique or metabolic demands.", "target": "This study looked at whether manipulating the speed of steps (stride frequency) during uphill training could increase the distance covered in a single step (stride length) in race walking. The researchers took twelve male race walkers and split them randomly into two groups. One group had structured step frequency during their training, and the other had no specific step frequency set.\n\nThe results showed that the group with structured step frequency saw an increase in the distance of their step and the time their foot was in contact with the ground. Simultaneously, the speed of their steps and energy used decreased. The group without specific step frequency had a decrease in the distance of their step and foot contact time but saw an increase in the speed of their steps and energy used.\n\nThis research suggests that training on slopes with specific step frequencies could offer coaches a useful technique to improve race walkers\u2019 performance by increasing the distance of their steps without changing the walker's style or creating extra energy demand.", "question": "How is stride length analysis regarded in terms of ease in carrying it out?", "answer": "Stride length analysis is considered an easy method to execute."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 0, "end": 87, "score": 1, "text": "Stride length analysis represents an easy method for assessing race walking kinematics.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 4599047, "edit_id": "afc39ab93bb7c40833c63f723f305018", "source": "PURPOSE.\nThis report provides the 3-year clinical outcomes from the randomized, controlled US Food and Drug Administration Investigational Device Exemption trial of the Superion\u00ae for the treatment of moderate degenerative lumbar spinal stenosis.\n\nPATIENTS AND METHODS.\nThe Superion\u00ae was evaluated in the treatment of subjects aged 45 years or older suffering from symptoms of intermittent neurogenic claudication, secondary to a confirmed diagnosis of moderate degenerative lumbar spinal stenosis at one or two contiguous levels from L1 to L5. Patients were treated between June 2008 and December 2011 at 31 investigational sites. Three hundred ninety-one subjects were included in the randomized study group consisting of 190 Superion\u00ae and 201 X-STOP\u00ae control subjects. The primary composite endpoint was individual patient success based on four components: improvement in two of three domains of the Zurich Claudication Questionnaire, no reoperations at the index level, no major implant/procedure-related complications, and no clinically significant confounding treatments.\n\nRESULTS.\nAt 3 years, the proportion of subjects achieving the primary composite endpoint was greater for Superion\u00ae (63/120, 52.5%) than for X-STOP\u00ae (49/129, 38.0%) (P=0.023) and the corresponding success rates exceeded 80% for each of the individual components of the primary endpoint in the Superion\u00ae group (range: 81%\u201391%). Improvements in back and leg pain severity as well as back- and disease-specific functional outcomes were also maintained through 36 months.\n\nCONCLUSION.\nThe 3-year outcomes from this randomized controlled trial demonstrate durable clinical improvement consistently across all clinical outcomes for the Superion\u00ae in the treatment of patients with moderate degenerative lumbar spinal stenosis.", "target": "PURPOSE:\nThis report talks about a 3-year study conducted on a treatment device named Superion\u00ae. The device was used for patients dealing with moderate lower back spinal degeneration, which was approved for testing by the US Food and Drug Administration. \n\nPATIENTS AND METHODS:\nPeople aged 45 years and above, suffering from moderate lower back spinal degeneration, were tested using the Superion\u00ae device. This was done between 2008 and 2011 at 31 different testing sites. In total, 391 people participated in the study. These included 190 patients treated with Superion\u00ae and 201 others who were given an alternative, X-STOP\u00ae, for comparison. The success of the treatment was judged based on improvements in patients in various areas, no repeat operations, no severe complications from the implant or procedure, and no significant additional treatments needed.\n\nRESULTS:\nThree years after treatment, a larger percentage of the Superion\u00ae treated patients showed successful recovery (around 52.5%) compared to those with X-STOP\u00ae (around 38%). For each separate aspect of recovery, over 80% of the Superion\u00ae patients showed improvements. These patients also maintained less severity of back and leg pain, and better back-functioning and disease-related outcomes over the 36 months.\n\nCONCLUSION:\nThe study results, after three years, consistently show the Superion\u00ae device to be effective in treating patients with moderate lower back spinal degeneration. The positive outcomes remained stable throughout the time-frame.", "question": "What was the specific population that the Superion\u00ae was tested for?", "answer": "The Superion\u00ae was tested for patients aged 45 years or older suffering from symptoms of intermittent neurogenic claudication, secondary to a confirmed diagnosis of moderate degenerative lumbar spinal stenosis at one or two contiguous levels from L1 to L5."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 269, "end": 543, "score": 1, "text": "The Superion\u00ae was evaluated in the treatment of subjects aged 45 years or older suffering from symptoms of intermittent neurogenic claudication, secondary to a confirmed diagnosis of moderate degenerative lumbar spinal stenosis at one or two contiguous levels from L1 to L5.", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 97, "end": 254, "score": 1, "text": "The device was used for patients dealing with moderate lower back spinal degeneration, which was approved for testing by the US Food and Drug Administration.", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 4687242, "edit_id": "4cc4b8610e1f682995b42523c1cb9b87", "source": "INTRODUCTION.\nAshwagandha (Withania somnifera [L.] Dunal) has been traditionally used for various actions ranging from vitalizer, improve endurance and stamina, promote longevity, improve immunity, and male and female fertility. However, clinical studies are needed to prove the clinical efficacy of this herb, especially in cardiovascular endurance and physical performance.\n\nAIMS.\nThis prospective, double-blind, randomized, and placebo-controlled study evaluated the efficacy of Ashwagandha roots extract in enhancing cardiorespiratory endurance and improving the quality of life (QOL) in 50 healthy male/female athletic adults.\n\nMATERIALS AND METHODS.\nCardiorespiratory endurance was assessed by measuring the oxygen consumption at peak physical exertion (VO2 max) levels during a 20 m shuttle run test. The World Health Organization self-reported QOL questionnaire (physical health, psychological health, social relationships, and environmental factors) was used to assess the QOL. Student's t-test was used to compare the differences in a mean and change from baseline VO2 max levels, whereas Wilcoxon signed-rank test was used to assess changes in QOL scores from baseline in the two groups.\n\nRESULTS.\nThere was a greater increase from baseline (P < 0.0001) in the mean VO2 max with KSM-66 Ashwagandha (n = 24) compared to placebo (n = 25) at 8 weeks (4.91 and 1.42, respectively) and at 12 weeks (5.67 and 1.86 respectively). The QOL scores for all subdomains significantly improved to a greater extent in the Ashwagandha group at 12 weeks compared to placebo (P < 0.05).\n\nCONCLUSION.\nThe findings suggest that Ashwagandha root extract enhances the cardiorespiratory endurance and improves QOL in healthy athletic adults.", "target": "INTRODUCTION.\nAshwagandha is a plant that has been traditionally used for a variety of health benefits. These benefits include increasing energy, improving the immune system, and aiding both male and female fertility. Clinical studies are continuing to explore the benefits of Ashwagandha, particularly in improving cardiovascular health and physical performance.\n\nPURPOSE OF THE STUDY.\nThis study focused on finding out if Ashwagandha root extract can improve cardiovascular fitness and quality of life in 50 healthy athletic adults (both men and women). It involved comparing the effects of Ashwagandha and a placebo (a substance with no therapeutic effect).\n\nMETHOD.\nTo measure cardiovascular fitness, we tested how much oxygen the subjects used during a physical exercise test. We also used a questionnaire by the World Health Organization to measure the subjects' quality of life, including physical health, psychological health, social relationships, and environment.\n\nRESULTS.\nThe use of the Ashwagandha root extract showed a significant improvement in the subjects' cardiovascular fitness over the 8 and 12-week periods, compared to the placebo group. Additionally, the quality of life scores improved more for the group taking Ashwagandha than the group on the placebo, across all categories.\n\nCONCLUSION.\nThe study suggests that Ashwagandha root extract can improve cardiovascular fitness and quality of life in healthy athletic adults.", "question": "How was the World Health Organization's questionnaire administered?", "answer": "The questionnaire was self-reported, meaning the participants filled it out themselves based on their own perceptions of their quality of life."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 808, "end": 986, "score": 1, "text": "The World Health Organization self-reported QOL questionnaire (physical health, psychological health, social relationships, and environmental factors) was used to assess the QOL.", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 782, "end": 973, "score": 1, "text": "We also used a questionnaire by the World Health Organization to measure the subjects' quality of life, including physical health, psychological health, social relationships, and environment.", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 4717319, "edit_id": "4a99514dd68d958ac06d141b9b7cc365", "source": "OBJECTIVE.\nTo evaluate the effectiveness of lurasidone as maintenance treatment for schizophrenia.\n\nMETHOD.\nAdults experiencing an acute exacerbation of schizophrenia initially received 12\u201324 weeks of open-label treatment with lurasidone (40\u201380 mg/d, flexibly dosed). Patients who maintained clinical stability for \u2a7e12 weeks were randomized in double-blind fashion to placebo or lurasidone (40\u201380 mg/d, flexibly dosed) for an additional 28-week treatment period. The primary efficacy endpoint was time to relapse (based on Kaplan\u2013Meier survival analysis).\n\nRESULTS.\nA total of 676 patients enrolled in the open-label phase; 285 met protocol-specified stabilization criteria and were randomized to lurasidone (N=144) or placebo (N=141). During the open-label phase, mean Positive and Negative Syndrome Scale total score decreased from 90.1 to 54.4 in patients who met clinical stability criteria and were randomized. In the double-blind phase, lurasidone significantly delayed time to relapse compared with placebo (log-rank test, p=0.039), reflecting a 33.7% reduction in risk of relapse (Cox hazard ratio (95% confidence interval), 0.663 (0.447\u20130.983); p=0.041). Probability of relapse at the double-blind week 28 endpoint (based on Kaplan\u2013Meier analysis) was 42.2% in the lurasidone group and 51.2% in the placebo group. Minimal changes in weight, lipid, glucose, and prolactin were observed throughout the study.\n\nCONCLUSIONS.\nThis multicenter, placebo-controlled, randomized withdrawal study demonstrated the efficacy of lurasidone for the maintenance treatment of patients with schizophrenia.", "target": "GOAL:\nWe wanted to see how well lurasidone works as a long-term treatment for schizophrenia.\n\nMETHOD:\nWe first gave adults with a severe episode of schizophrenia a 12-24 week treatment with lurasidone. After 12 weeks, those who showed improvement were then divided into two groups. One group continued using lurasidone and the other group was given a placebo (a substance with no medical effect) for an additional 28 weeks. We then checked the time it took before their symptoms came back.\n\nRESULTS:\nWe had 676 patients in the first phase and 285 showed improvement. These were then divided into the lurasidone (144 patients) and placebo (141 patients) groups. During the first phase, there was a decrease in the severity of symptoms in those who showed improvement. In the next phase, patients using lurasidone took longer before their symptoms came back compared to the placebo group. This was a 33.7% reduction in the risk of symptoms coming back. At the end of the 28 weeks, 42.2% of the lurasidone group and 51.2% of the placebo group had their symptoms return. During the study, the patients only had minor changes in weight, fat levels, sugar levels, and hormone levels.\n\nCONCLUSIONS:\nThis study, which involved multiple treatment centers and used a placebo control group, showed that lurasidone works well in keeping schizophrenia symptoms from returning.", "question": "Did the study observe any changes in patients' lipid levels?", "answer": "Yes, the study monitored changes in the patients' lipid levels, which are fats in the blood."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 566, "end": 735, "score": 1, "text": "A total of 676 patients enrolled in the open-label phase; 285 met protocol-specified stabilization criteria and were randomized to lurasidone (N=144) or placebo (N=141).", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 4717319, "edit_id": "e67096b40d14e641101f02d804fb7649", "source": "OBJECTIVE.\nTo evaluate the effectiveness of lurasidone as maintenance treatment for schizophrenia.\n\nMETHOD.\nAdults experiencing an acute exacerbation of schizophrenia initially received 12\u201324 weeks of open-label treatment with lurasidone (40\u201380 mg/d, flexibly dosed). Patients who maintained clinical stability for \u2a7e12 weeks were randomized in double-blind fashion to placebo or lurasidone (40\u201380 mg/d, flexibly dosed) for an additional 28-week treatment period. The primary efficacy endpoint was time to relapse (based on Kaplan\u2013Meier survival analysis).\n\nRESULTS.\nA total of 676 patients enrolled in the open-label phase; 285 met protocol-specified stabilization criteria and were randomized to lurasidone (N=144) or placebo (N=141). During the open-label phase, mean Positive and Negative Syndrome Scale total score decreased from 90.1 to 54.4 in patients who met clinical stability criteria and were randomized. In the double-blind phase, lurasidone significantly delayed time to relapse compared with placebo (log-rank test, p=0.039), reflecting a 33.7% reduction in risk of relapse (Cox hazard ratio (95% confidence interval), 0.663 (0.447\u20130.983); p=0.041). Probability of relapse at the double-blind week 28 endpoint (based on Kaplan\u2013Meier analysis) was 42.2% in the lurasidone group and 51.2% in the placebo group. Minimal changes in weight, lipid, glucose, and prolactin were observed throughout the study.\n\nCONCLUSIONS.\nThis multicenter, placebo-controlled, randomized withdrawal study demonstrated the efficacy of lurasidone for the maintenance treatment of patients with schizophrenia.", "target": "GOAL:\nWe wanted to see how well lurasidone works as a long-term treatment for schizophrenia.\n\nMETHOD:\nWe first gave adults with a severe episode of schizophrenia a 12-24 week treatment with lurasidone. After 12 weeks, those who showed improvement were then divided into two groups. One group continued using lurasidone and the other group was given a placebo (a substance with no medical effect) for an additional 28 weeks. We then checked the time it took before their symptoms came back.\n\nRESULTS:\nWe had 676 patients in the first phase and 285 showed improvement. These were then divided into the lurasidone (144 patients) and placebo (141 patients) groups. During the first phase, there was a decrease in the severity of symptoms in those who showed improvement. In the next phase, patients using lurasidone took longer before their symptoms came back compared to the placebo group. This was a 33.7% reduction in the risk of symptoms coming back. At the end of the 28 weeks, 42.2% of the lurasidone group and 51.2% of the placebo group had their symptoms return. During the study, the patients only had minor changes in weight, fat levels, sugar levels, and hormone levels.\n\nCONCLUSIONS:\nThis study, which involved multiple treatment centers and used a placebo control group, showed that lurasidone works well in keeping schizophrenia symptoms from returning.", "question": "What was the reduction in symptoms observed during the open-label phase?", "answer": "The mean Positive and Negative Syndrome Scale total score decreased from 90.1 to 54.4 in patients who met clinical stability criteria and were randomized during the open-label phase."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 736, "end": 915, "score": 1, "text": "During the open-label phase, mean Positive and Negative Syndrome Scale total score decreased from 90.1 to 54.4 in patients who met clinical stability criteria and were randomized.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 4717319, "edit_id": "671542336715303b4a9ae45b104f78b2", "source": "OBJECTIVE.\nTo evaluate the effectiveness of lurasidone as maintenance treatment for schizophrenia.\n\nMETHOD.\nAdults experiencing an acute exacerbation of schizophrenia initially received 12\u201324 weeks of open-label treatment with lurasidone (40\u201380 mg/d, flexibly dosed). Patients who maintained clinical stability for \u2a7e12 weeks were randomized in double-blind fashion to placebo or lurasidone (40\u201380 mg/d, flexibly dosed) for an additional 28-week treatment period. The primary efficacy endpoint was time to relapse (based on Kaplan\u2013Meier survival analysis).\n\nRESULTS.\nA total of 676 patients enrolled in the open-label phase; 285 met protocol-specified stabilization criteria and were randomized to lurasidone (N=144) or placebo (N=141). During the open-label phase, mean Positive and Negative Syndrome Scale total score decreased from 90.1 to 54.4 in patients who met clinical stability criteria and were randomized. In the double-blind phase, lurasidone significantly delayed time to relapse compared with placebo (log-rank test, p=0.039), reflecting a 33.7% reduction in risk of relapse (Cox hazard ratio (95% confidence interval), 0.663 (0.447\u20130.983); p=0.041). Probability of relapse at the double-blind week 28 endpoint (based on Kaplan\u2013Meier analysis) was 42.2% in the lurasidone group and 51.2% in the placebo group. Minimal changes in weight, lipid, glucose, and prolactin were observed throughout the study.\n\nCONCLUSIONS.\nThis multicenter, placebo-controlled, randomized withdrawal study demonstrated the efficacy of lurasidone for the maintenance treatment of patients with schizophrenia.", "target": "GOAL:\nWe wanted to see how well lurasidone works as a long-term treatment for schizophrenia.\n\nMETHOD:\nWe first gave adults with a severe episode of schizophrenia a 12-24 week treatment with lurasidone. After 12 weeks, those who showed improvement were then divided into two groups. One group continued using lurasidone and the other group was given a placebo (a substance with no medical effect) for an additional 28 weeks. We then checked the time it took before their symptoms came back.\n\nRESULTS:\nWe had 676 patients in the first phase and 285 showed improvement. These were then divided into the lurasidone (144 patients) and placebo (141 patients) groups. During the first phase, there was a decrease in the severity of symptoms in those who showed improvement. In the next phase, patients using lurasidone took longer before their symptoms came back compared to the placebo group. This was a 33.7% reduction in the risk of symptoms coming back. At the end of the 28 weeks, 42.2% of the lurasidone group and 51.2% of the placebo group had their symptoms return. During the study, the patients only had minor changes in weight, fat levels, sugar levels, and hormone levels.\n\nCONCLUSIONS:\nThis study, which involved multiple treatment centers and used a placebo control group, showed that lurasidone works well in keeping schizophrenia symptoms from returning.", "question": "How was the severity of schizophrenia symptoms measured and what was the change in this measurement for patients who showed improvement?", "answer": "The severity of schizophrenia symptoms was measured using the Positive and Negative Syndrome Scale. For patients who showed improvement, the total score on this scale decreased from 90.1 to 54.4."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 770, "end": 846, "score": 1, "text": "Positive and Negative Syndrome Scale total score decreased from 90.1 to 54.4", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 4769147, "edit_id": "4faab4c813ee26c72df786fcf460d151", "source": "OBJECTIVES.\nBreastfeeding is known to reduce infant morbidity and improve well-being. Nevertheless, breastfeeding rates remain low despite public health efforts. Our study aims to investigate the effect of controlled limited formula usage during birth hospitalisation on breastfeeding, using the primary hypothesis that early limited formula feeds in infants with early weight loss will not adversely affect the rate of exclusive or any breastfeeding as measured at discharge, 3 and 6 months of age.\n\nMATERIAL AND METHODS.\nWe randomly assigned 104 healthy term infants, 24 to 48 hours old, with \u2265 5% loss of birth weight to controlled limited formula (CLF) intervention (10 ml formula by syringe after each breastfeeding, discontinued at onset of lactation) or control group (standard approach, SA). Groups were compared for demographic data and breastfeeding rates at discharge, 3 months and 6 months of age (p-values adjusted for multiple testing).\n\nRESULTS.\nFifty newborns were analysed in CLF and 50 in SA group. There were no differences in demographic data or clinical characteristics between groups. We found no evidence of difference between treatment groups in the rates of exclusive as well as any breastfeeding at discharge (p-value 0.2 and >0.99 respectively), 3 months (p-value 0.12 and 0.10) and 6 months of infants\u2019 age (p-value 0.45 and 0.34 respectively). The percentage weight loss during hospitalisation was significantly higher in the SA group (7.3% in CLF group, 8.4% in SA group, p = 0.002).\n\nCONCLUSION.\nThe study shows that controlled limited formula use does not have an adverse effect on rates of breastfeeding in the short and long term. Larger studies are needed to confirm a possible potential in controlled limited formula use to support establishing breastfeeding and to help to improve the rates of breastfeeding overall.\n\nTRIAL REGISTRATION.\nISRCTN registry ISRCTN61915183", "target": "GOAL OF THE STUDY.\nBreastfeeding is good for a baby's health and overall wellbeing-- but not enough women do it. We wanted to see if giving newborns a small amount of baby formula right after birth would hurt or help breastfeeding rates. We also wanted to know whether this approach would hinder breastfeeding when the baby is three or six months old.\n\nHOW THE STUDY WAS DONE.\nWe picked 104 healthy babies that had lost more than 5% of their birth weight and were between one and two days old. We split them into two groups. In one group, we gave the babies 10 ml of baby formula feed after each breastfeeding session (this was stopped as soon as the mother's milk came in). The other group followed the standard approach. We tracked breastfeeding rates when the babies left the hospital, and then checked in when they were three and six months old.\n\nWHAT WE FOUND.\nIn both groups, 50 newborns were examined. The groups were similar in terms of demographic data and clinical characteristics. There was no noticeable difference in breastfeeding rates at hospital discharge, at three months, or at six months between the two groups. One thing that did differ, was the amount of weight the babies lost in the hospital - babies in the standard approach lost more weight.\n\nWHAT THIS MEANS.\nOur study shows that giving newborns a small amount of baby formula feed doesn't seem to hurt breastfeeding rates in the short or long term. More studies need to be done to see if this approach can help more moms breastfeed and keep breastfeeding for longer.\n\nTRIAL REGISTRATION DETAILS.\nThe study is registered with the ISRCTN under the number ISRCTN61915183.\n", "question": "What exactly did the CLF intervention entail?", "answer": "During the CLF intervention, each baby was given a small amount of baby formula (10 ml) after every breastfeeding session. This was given using a syringe."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 523, "end": 799, "score": 1, "text": "We randomly assigned 104 healthy term infants, 24 to 48 hours old, with \u2265 5% loss of birth weight to controlled limited formula (CLF) intervention (10 ml formula by syringe after each breastfeeding, discontinued at onset of lactation) or control group (standard approach, SA).", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 4877819, "edit_id": "72cfabc2cbc864d05f3b777531f64886", "source": "BACKGROUND.\nAndrographis paniculata (A. paniculata), a medicinal plant, has shown anti-inflammatory, neuroprotective and antifibrotic effects in animal models as well as clinical efficacy in different studies, including an anti-fatigue effect in autoimmune diseases such as rheumatoid arthritis. In multiple sclerosis (MS), fatigue is rated as one of the most common and disabling symptoms. In the present trial, we investigated the effect of A. paniculata on relapse rate and fatigue in relapsing-remitting MS (RRMS) patients receiving interferon beta.\n\nMETHODS.\nA randomised double-blind placebo-controlled trial assessed the effects of 170 mg of A. paniculata dried extract tablet b.i.d. p.o. on relapse rate and fatigue using the Fatigue Severity Scores (FSS) over 12 months in RRMS patients receiving interferon. The Expanded Disability Status Scale (EDSS) score, inflammatory parameters and radiological findings were also investigated. Twenty-five patients were enrolled, and twenty-two patients were ultimately analysed and randomised to the active or placebo group.\n\nRESULTS.\nPatients treated with A. paniculata showed a significant reduction in their FSS score as compared to the placebo, equivalent to a 44 % reduction at 12 months. No statistically significant differences were observed for relapse rate, EDSS or inflammatory parameters, with a trend in reducing new lesions among the A. paniculata group. One patient in the A. paniculata group presented with a mild and transient skin rash, which was alleviated with anti-histamine treatment for three weeks.\n\nCONCLUSION.\nA. paniculata was well tolerated in patients and no changes in clinical parameters were observed. A. paniculata significantly reduces fatigue in patients with RRMS receiving interferon beta in comparison to placebo and only interferon beta treatment.\n\nTRIAL REGISTRATION.\nClinicalTrials.gov Identifier: NCT02280876; Trial registration date: 20.10.2014.", "target": "BACKGROUND.\nAndrographis paniculata (A. paniculata), a medicinal plant, has shown potential benefits in treating inflammation, nerve damage, and scarring in experiments involving animals. It is also known to be effective in reducing fatigue in autoimmune diseases such as rheumatoid arthritis. Fatigue is a common symptom in Multiple Sclerosis (MS) patients. We conducted a study to see if A. paniculata could help reduce fatigue and the recurrence of symptoms in MS patients who are already taking a drug called interferon beta.\n\nMETHODS.\nWe conducted a blind study\u2014meaning neither the patients nor the researchers knew who was receiving what treatment\u2014where we gave MS patients who were already taking a drug called interferon beta either a 170 mg tablet of A. paniculata extract or a sugar pill twice a day for a year. We then monitored them for instances where their symptoms came back and gauged their fatigue levels. We also performed tests to measure disability, inflammation, and to check for changes in the brain. We initially selected 25 patients, but 3 dropped out, so we ended with information on 22 patients.\n\nRESULTS.\nPatients who were given the A. paniculata extract experienced a significant decrease in fatigue when compared to those who received the sugar pill. This reduction was by almost half over the course of a year. There were no significant changes in the recurrence of symptoms, disability, or inflammation in either group. The group that took A. paniculata showed signs of having fewer new brain lesions. One patient taking A. paniculata did develop a mild, temporary skin rash, but this went away after three weeks of taking an allergy medication.\n\nCONCLUSION.\nThe A. paniculata extract was well received by patients and caused no noticeable changes in their clinical examinations. The extract notably reduced fatigue in MS patients who are already taking interferon beta compared to those who took only the sugar pill and the drug.\n\nTRIAL REGISTRATION.\nThis clinical trial was registered under the identifier NCT02280876 on October 20, 2014.", "question": "What is the most common and disabling symptom in MS?", "answer": "In MS, fatigue is one of the most common and disabling symptoms."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 296, "end": 390, "score": 1, "text": "In multiple sclerosis (MS), fatigue is rated as one of the most common and disabling symptoms.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 4941128, "edit_id": "24356909d7a3528a32fef657fb43e1c0", "source": "INTRODUCTION & OBJECTIVES.\nAdaptive deep brain stimulation (aDBS) uses feedback from brain signals to guide stimulation. A recent acute trial of unilateral aDBS showed that aDBS can lead to substantial improvements in contralateral hemibody Unified Parkinson's Disease Rating Scale (UPDRS) motor scores and may be superior to conventional continuous DBS in Parkinson's disease (PD). We test whether potential benefits are retained with bilateral aDBS and in the face of concurrent medication.\n\nMETHODS.\nWe applied bilateral aDBS in 4 patients with PD undergoing DBS of the subthalamic nucleus. aDBS was delivered bilaterally with independent triggering of stimulation according to the amplitude of \u03b2 activity at the corresponding electrode. Mean stimulation voltage was 3.0\u00b10.1 volts. Motor assessments consisted of double-blinded video-taped motor UPDRS scores that included both limb and axial features.\n\nRESULTS.\nUPDRS scores were 43% (p=0.04; Cohen's d=1.62) better with aDBS than without stimulation. Motor improvement with aDBS occurred despite an average time on stimulation (ToS) of only 45%. Levodopa was well tolerated during aDBS and led to further reductions in ToS.\n\nCONCLUSION.\nBilateral aDBS can improve both axial and limb symptoms and can track the need for stimulation across drug states.", "target": "INTRODUCTION & OBJECTIVES.\nThis research is about a deep brain stimulation method, known as adaptive deep brain stimulation (aDBS), where we use feedback from the brain to guide the process. From previous trials, we saw that aDBS had a strong positive impact on people with Parkinson's disease. Now, we wanted to check if these benefits can be achieved with bilateral aDBS (applied to both sides of the brain) when the patient is also on medication.\n\nMETHODS.\nWe used this therapy on 4 Parkinson's patients. The aDBS therapy was administered to both sides of their brains independently, depending on the level of their brain activity. We primarily looked at how this treatment affected the patients' movement and coordination, measured using a specific scoring system.\n\nRESULTS. \nThe treatment, aDBS, lead to a 43% improvement in the patients' coordination and movement scores. Interestingly, the improvements observed were achieved even though the treatment was used only 45% of the time. Furthermore, the commonly used Parkinson's disease medication (Levodopa) worked well with aDBS, leading to additional improvements.\n\nCONCLUSION.\nSo, we conclude that using aDBS on both sides of the brain improves certain symptoms of Parkinson's disease. It's also able to adjust to the need for stimulation in patients taking medication.", "question": "What was measured during the adaptive deep brain stimulation procedure in this study?", "answer": "The stimulation voltage, which is the power of the electrical signals being sent to the brain, was measured during the aDBS procedure in this study."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 741, "end": 784, "score": 1, "text": "Mean stimulation voltage was 3.0\u00b10.1 volts.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 4967511, "edit_id": "eda63db1c687d01849e8da270458da57", "source": "BACKGROUND.\nProgrammes based on the World Health Organization\u2019s Health Promoting Schools framework (HPS) have been implemented in several countries but for evidence-based policy-making more research is required to determine the effectiveness of the HPS approach.\n\nMETHODS.\nWe conducted a cluster randomised controlled trial. The units of randomisation were primary school classes recruited in May 2010. Eligible participants were Year 3 primary school classes in Lower Austria that had not participated in a similar programme during the last two years. After baseline assessment in September 2010, 53 classes from 45 primary schools in Lower Austria were randomly assigned to an intervention (n\u2009=\u200926 classes, 432 children) or waiting control arm (n\u2009=\u200927 classes, 493 children aged 8.7\u00a0years +/- 4\u00a0months). Over the course of 1.5 academic years, participating teachers received on-the-job training (20\u00a0h) and two workshops (8\u00a0h) to promote health related behaviour in students such as physical activity during the school day and to improve the quality of regular physical education classes. We assessed 15 outcomes grouped into five categories: Emotional and Social Experience in School, Physical Activity, Well-being, and Attention Performance measured by validated and standardised questionnaire and Motor Skills measured by validated and standardised motoric and coordination tests in the school gym. The primary outcome was Classroom Climate and part of the outcomecategory Emotional and Social Experience in School. The final assessment took place in April 2012. All assessors were blinded to the allocation of classes. Multilevel growth modelling was used to investigate programme effectiveness.\n\nRESULTS.\nWe could not detect any statistically significant differences between groups for the outcomecategories Emotional and Social Experience in school (p\u2009=\u20090.22 to 0.78), Physical Activity, Well-being, and Attention Performance. Significant differences between groups were limited to the outcomecategory Motor Skills (Complex Reaction Ability, Spatial Orientation Skills, Coordination with Precision) which were higher in the intervention group (P\u2009<\u2009.05).\n\nCONCLUSIONS.\nDespite small statistically significant differences in Motor Skills, our study could not detect any clinically relevant improvements in the Emotional and Social Experience at School (including the primary outcome ClassroomClimate), Physical Activity, Well-being, Motor Skills and Attention Performance of students.\n\nTRIAL REGISTRATION.\nGerman register of clinical studies: DRKS00000622. Retrospectively registered: 03.12.2010. Approved by the Ethics Committee of Lower Austria (GS4-EK-4/107-2010).", "target": "BACKGROUND.\nThis summary is about a study of the Health Promoting Schools program, a model from the World Health Organization. This program has started in various countries, but we need more data to see whether it works really well.\n\nMETHODS.\nTo see if this program is effective, we tested it with Year 3 students in primary schools in Lower Austria. We picked 53 classes from 45 schools and divided them into two groups. One group used the program right away (432 children) and the other group waited to start the program (493 children). We checked how things were in September 2010 before the program started. Then, teachers in the first group were trained to promote healthy behaviors like exercising during the day and running better gym classes. After one and a half school years, we checked 15 different things grouped into five categories: 1. Feelings and social activities in school, 2. Physical activity, 3. Well-being, 4. Concentration, and 5. Physical skills measured in gym class. The main thing we wanted to learn was about the classroom atmosphere. We repeated the checks in April 2012.\n\nRESULTS.\nThe data did not show a big difference between the two groups in feelings and social activities at school, physical activity, well-being, and concentration. There was a noticeable difference only in physical skills, where the group that received the program performed a bit better.\n\nCONCLUSIONS.\nEven though the children who participated in the program had slightly better physical skills, we didn't see substantial improvements in their feelings and social interaction at school, their physical activity, well-being, or their focus. \n\nTRIAL REGISTRATION.\nThis study was registered in the German register of clinical studies, was recorded after it had started, and was approved by the Ethics Committee of Lower Austria.", "question": "How long did the study last and how much training did the teachers receive?", "answer": "The study lasted for 1.5 academic years. During this time, the participating teachers received 20 hours of on-the-job training and attended two workshops that lasted 8 hours each."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 806, "end": 927, "score": 1, "text": "Over the course of 1.5 academic years, participating teachers received on-the-job training (20\u00a0h) and two workshops (8\u00a0h)", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 4967511, "edit_id": "4582bd8f767c6547cdf356a60c70387a", "source": "BACKGROUND.\nProgrammes based on the World Health Organization\u2019s Health Promoting Schools framework (HPS) have been implemented in several countries but for evidence-based policy-making more research is required to determine the effectiveness of the HPS approach.\n\nMETHODS.\nWe conducted a cluster randomised controlled trial. The units of randomisation were primary school classes recruited in May 2010. Eligible participants were Year 3 primary school classes in Lower Austria that had not participated in a similar programme during the last two years. After baseline assessment in September 2010, 53 classes from 45 primary schools in Lower Austria were randomly assigned to an intervention (n\u2009=\u200926 classes, 432 children) or waiting control arm (n\u2009=\u200927 classes, 493 children aged 8.7\u00a0years +/- 4\u00a0months). Over the course of 1.5 academic years, participating teachers received on-the-job training (20\u00a0h) and two workshops (8\u00a0h) to promote health related behaviour in students such as physical activity during the school day and to improve the quality of regular physical education classes. We assessed 15 outcomes grouped into five categories: Emotional and Social Experience in School, Physical Activity, Well-being, and Attention Performance measured by validated and standardised questionnaire and Motor Skills measured by validated and standardised motoric and coordination tests in the school gym. The primary outcome was Classroom Climate and part of the outcomecategory Emotional and Social Experience in School. The final assessment took place in April 2012. All assessors were blinded to the allocation of classes. Multilevel growth modelling was used to investigate programme effectiveness.\n\nRESULTS.\nWe could not detect any statistically significant differences between groups for the outcomecategories Emotional and Social Experience in school (p\u2009=\u20090.22 to 0.78), Physical Activity, Well-being, and Attention Performance. Significant differences between groups were limited to the outcomecategory Motor Skills (Complex Reaction Ability, Spatial Orientation Skills, Coordination with Precision) which were higher in the intervention group (P\u2009<\u2009.05).\n\nCONCLUSIONS.\nDespite small statistically significant differences in Motor Skills, our study could not detect any clinically relevant improvements in the Emotional and Social Experience at School (including the primary outcome ClassroomClimate), Physical Activity, Well-being, Motor Skills and Attention Performance of students.\n\nTRIAL REGISTRATION.\nGerman register of clinical studies: DRKS00000622. Retrospectively registered: 03.12.2010. Approved by the Ethics Committee of Lower Austria (GS4-EK-4/107-2010).", "target": "BACKGROUND.\nThis summary is about a study of the Health Promoting Schools program, a model from the World Health Organization. This program has started in various countries, but we need more data to see whether it works really well.\n\nMETHODS.\nTo see if this program is effective, we tested it with Year 3 students in primary schools in Lower Austria. We picked 53 classes from 45 schools and divided them into two groups. One group used the program right away (432 children) and the other group waited to start the program (493 children). We checked how things were in September 2010 before the program started. Then, teachers in the first group were trained to promote healthy behaviors like exercising during the day and running better gym classes. After one and a half school years, we checked 15 different things grouped into five categories: 1. Feelings and social activities in school, 2. Physical activity, 3. Well-being, 4. Concentration, and 5. Physical skills measured in gym class. The main thing we wanted to learn was about the classroom atmosphere. We repeated the checks in April 2012.\n\nRESULTS.\nThe data did not show a big difference between the two groups in feelings and social activities at school, physical activity, well-being, and concentration. There was a noticeable difference only in physical skills, where the group that received the program performed a bit better.\n\nCONCLUSIONS.\nEven though the children who participated in the program had slightly better physical skills, we didn't see substantial improvements in their feelings and social interaction at school, their physical activity, well-being, or their focus. \n\nTRIAL REGISTRATION.\nThis study was registered in the German register of clinical studies, was recorded after it had started, and was approved by the Ethics Committee of Lower Austria.", "question": "How was the study designed?", "answer": "The study was a cluster randomized controlled trial, meaning that the units of randomization were primary school classes and the participants were randomly assigned to either an intervention group or a control group."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 273, "end": 324, "score": 1, "text": "We conducted a cluster randomised controlled trial.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 5002324, "edit_id": "98194bdac081e820f1d7cd51285b316c", "source": "BACKGROUND.\nThe present study examined the effects of a balance-based exergaming intervention using the Kinect sensor on postural stability and balance in people with Parkinson's disease (PD).\n\nMETHODS.\nWe conducted a subject-blinded, randomized controlled study. Twenty people with PD (Hoehn and Yahr stages I through III) were recruited and randomly assigned to either a balance-based exergaming group (N = 10) or a balance training group (N = 10) for an 8-week balance training period. Postural stability was assessed using the limits of stability (LOS) and one-leg stance (OLS) tests. Balance was assessed using the Berg Balance Scale (BBS) and the timed up and go (TUG) test. Participants were assessed pre- and post-training.\n\nRESULTS.\nAfter training, participants in the balance-based exergaming group showed significant improvements in LOS performance, and in the eyes-closed condition of the OLS test. Both training programs led to improvements in BBS and TUG performance. Furthermore, balance-based exergaming training resulted in significantly better performance in directional control in the LOS test (78.9 \u00b1 7.65 %) compared with conventional balance training (70.6 \u00b1 9.37 %).\n\nCONCLUSIONS.\nBalance-based exergaming training resulted in a greater improvement in postural stability compared with conventional balance training. Our results support the therapeutic use of exergaming aided by the Kinect sensor in people with PD.\n\nTRIAL REGISTRATION.\nClinicalTrials.gov.NCT02671396\n\nELECTRONIC SUPPLEMENTARY MATERIAL.\nThe online version of this article (doi:10.1186/s12984-016-0185-y) contains supplementary material, which is available to authorized users.", "target": "BACKGROUND.\nWe did a study to see if a special type of exercise game, called exergaming, that uses the Kinect sensor could help improve balance and stability in people with Parkinson's disease.\n\nMETHODS.\nWe performed a study where the participants didn't know what group they were in, and it was all decided randomly. We had twenty people with Parkinson's disease take part. These people were either at the early, middle or later stages of the disease. Half of them were put into a group that did the Kinect exergame for balance, and the other half were put into a group that did traditional balance training. This went on for 8 weeks. We used certain tests (LOS, OLS, BBS and TUG) to measure their balance and stability before and after the training.\n\nRESULTS.\nAfter the training, we found that the group that did the Kinect exergame had better results in some stability tests. Both groups improved in the BBS and TUG balance tests. In one of the LOS tests, the exergaming group did much better than the traditional training group.\n\nCONCLUSIONS.\nThe group that did the Kinect exergame improved more in their stability than the group that did traditional training. Our study suggests that these kind of exercise games can be helpful for people with Parkinson's disease.\n\nTRIAL REGISTRATION.\nThe details of the trial can be found on ClinicalTrials.gov.NCT02671396\n\nADDITIONAL MATERIAL.\nThere's more information online in the supplement of the article. Only certain users are allowed to access this.", "question": "In what aspect did the group that did the Kinect exergame improve more than the group that did traditional training?", "answer": "The group that did the Kinect exergame showed a greater improvement in postural stability compared to the group that did traditional training."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 1204, "end": 1338, "score": 1, "text": "Balance-based exergaming training resulted in a greater improvement in postural stability compared with conventional balance training.", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 1047, "end": 1164, "score": 1, "text": "The group that did the Kinect exergame improved more in their stability than the group that did traditional training.", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 5002324, "edit_id": "9a0aae4591d9d188beb23650cd29fc7b", "source": "BACKGROUND.\nThe present study examined the effects of a balance-based exergaming intervention using the Kinect sensor on postural stability and balance in people with Parkinson's disease (PD).\n\nMETHODS.\nWe conducted a subject-blinded, randomized controlled study. Twenty people with PD (Hoehn and Yahr stages I through III) were recruited and randomly assigned to either a balance-based exergaming group (N = 10) or a balance training group (N = 10) for an 8-week balance training period. Postural stability was assessed using the limits of stability (LOS) and one-leg stance (OLS) tests. Balance was assessed using the Berg Balance Scale (BBS) and the timed up and go (TUG) test. Participants were assessed pre- and post-training.\n\nRESULTS.\nAfter training, participants in the balance-based exergaming group showed significant improvements in LOS performance, and in the eyes-closed condition of the OLS test. Both training programs led to improvements in BBS and TUG performance. Furthermore, balance-based exergaming training resulted in significantly better performance in directional control in the LOS test (78.9 \u00b1 7.65 %) compared with conventional balance training (70.6 \u00b1 9.37 %).\n\nCONCLUSIONS.\nBalance-based exergaming training resulted in a greater improvement in postural stability compared with conventional balance training. Our results support the therapeutic use of exergaming aided by the Kinect sensor in people with PD.\n\nTRIAL REGISTRATION.\nClinicalTrials.gov.NCT02671396\n\nELECTRONIC SUPPLEMENTARY MATERIAL.\nThe online version of this article (doi:10.1186/s12984-016-0185-y) contains supplementary material, which is available to authorized users.", "target": "BACKGROUND.\nWe did a study to see if a special type of exercise game, called exergaming, that uses the Kinect sensor could help improve balance and stability in people with Parkinson's disease.\n\nMETHODS.\nWe performed a study where the participants didn't know what group they were in, and it was all decided randomly. We had twenty people with Parkinson's disease take part. These people were either at the early, middle or later stages of the disease. Half of them were put into a group that did the Kinect exergame for balance, and the other half were put into a group that did traditional balance training. This went on for 8 weeks. We used certain tests (LOS, OLS, BBS and TUG) to measure their balance and stability before and after the training.\n\nRESULTS.\nAfter the training, we found that the group that did the Kinect exergame had better results in some stability tests. Both groups improved in the BBS and TUG balance tests. In one of the LOS tests, the exergaming group did much better than the traditional training group.\n\nCONCLUSIONS.\nThe group that did the Kinect exergame improved more in their stability than the group that did traditional training. Our study suggests that these kind of exercise games can be helpful for people with Parkinson's disease.\n\nTRIAL REGISTRATION.\nThe details of the trial can be found on ClinicalTrials.gov.NCT02671396\n\nADDITIONAL MATERIAL.\nThere's more information online in the supplement of the article. Only certain users are allowed to access this.", "question": "What were the results of the study in terms of balance improvement?", "answer": "The study found that the group that did the Kinect exergame had better results in some stability tests, specifically in the directional control test (LOS) with a significant difference in performance between the two groups (78.9 \u00b1 7.65 % for the exergaming group and 70.6 \u00b1 9.37 % for the conventional balance training group)."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 995, "end": 1189, "score": 1, "text": "balance-based exergaming training resulted in significantly better performance in directional control in the LOS test (78.9 \u00b1 7.65 %) compared with conventional balance training (70.6 \u00b1 9.37 %).", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 934, "end": 1032, "score": 1, "text": "In one of the LOS tests, the exergaming group did much better than the traditional training group.", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 5018291, "edit_id": "aeec34fa9814018a6c175cd8bf00087e", "source": "BACKGROUND.\nRecently, the use of ketamine as a systemic and local analgesic drug in reducing post-operative pain is studied more frequently.\n\nOBJECTIVES.\nThe aim of the present study was to assess the analgesic efficacy of IV ketamine injection inaddition to nephrostomy tract infiltration of ketamine-bupivacaine on postoperative pain relief after tubeless percutaneous nephrolithotomy (PCNL).\n\nPATIENTS AND METHODS.\nPatients (n = 100), with renal stone who were candidates for PCNL were randomized to five groups with 20 cases in each: Group C, 10 mL of saline solution was infiltrated into the nephrostomy tract; Group B, 10 mL of 0.25% bupivacaine was infiltrated into the nephrostomy tract; Group BK1, 10 mL of 0.25% bupivacaine plus 0.5 mg/kg ketamine was infiltrated into the nephrostomy tract; Group BK2, 10 mL of 0.25% bupivacaine plus 1.5 mg/kg ketamine was infiltrated into the nephrostomy tract; Group K, 10 mL of saline solution containing 0.5 mg/kg ketamine was intravenously administered. Post-operative pain scores were compared between groups as the primary objective. Comparison of Sedation Scores, rescue analgesic consumption, time to the first rescue analgesics administration, hemodynamic and SpO2 values were regarded as the secondary objective.\n\nRESULTS.\nMean VAS scores in the first 30 min and total analgesic consumption in the first 24 h of post-operative period were significantly lower in groups BK1 and BK2 in comparison with the other groups (P < 0.05). Also, time to first rescue analgesics administration was longer in the same groups (P < 0.05).\n\nCONCLUSIONS.\nInfiltration of ketamine plus bupivacaine provides superior analgesic effects in PCNL surgery compared with other methods.", "target": "BACKGROUND:\nResearchers have been increasingly exploring the use of ketamine - a drug known to relieve pain - for reducing post-surgery discomfort.\n\nOBJECTIVES:\nThis study aimed to evaluate the effectiveness of injecting ketamine directly into the bloodstream, in addition to combined use with another painkiller called bupivacaine, in subsiding pain after a specific kidney stone removal surgery (tubeless percutaneous nephrolithotomy).\n\nPATIENTS AND METHODS:\n100 patients slated for kidney stone removal were randomly categorized into five groups. Each group received different treatment procedures - some received saline solutions, some received bupivacaine, while others were given varying doses of ketamine or a mix of ketamine and bupivacaine. The main goal was to compare the different groups' pain levels after surgery. Other factors such as the level of consciousness, the use of extra painkillers, timing of additional painkiller use, and their overall vital signs were also inspected.\n\nRESULTS:\nPatients that received a combination of bupivacaine and ketamine (both in lower and higher doses) reported lower pain levels within the first half-hour following surgery, and consumed fewer additional painkillers during the first day after surgery, compared to other groups. After surgery, these patients also were granted a longer time before needing extra painkillers.\n\nCONCLUSIONS:\nApplying a mix of ketamine and bupivacaine proved better at relieving pain after kidney stone removal compared to other methods.", "question": "How was the ketamine and bupivacaine combined in the study?", "answer": "The ketamine and bupivacaine were mixed together and infiltrated into the nephrostomy tract."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 259, "end": 313, "score": 1, "text": "nephrostomy tract infiltration of ketamine-bupivacaine", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 717, "end": 748, "score": 1, "text": "mix of ketamine and bupivacaine", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 5019463, "edit_id": "401618eb0e0cc581b315426ef63485ae", "source": "PURPOSE.\nPatients with glaucoma who do not keep their follow-up eye care appointments are at risk for developing more severe ocular disease. The primary aim of the current study was to evaluate whether the use of a patient navigator altered adherence to follow-up eye care appointments in community-versus office-based settings.\n\nPATIENTS AND METHODS.\nPatients diagnosed with a glaucoma-related condition following a comprehensive eye examination at 43 community sites in Philadelphia, PA, USA, were enrolled in this prospective, randomized, controlled trial. Patients were randomized into three groups for a 1-year period: Group 1 (G1) received follow-up eye care in a community-based setting with assistance from a patient navigator; Group 2 (G2) received follow-up eye care in an office-based setting with assistance from a patient navigator; and Group 3 (G3) received follow-up eye care in an office-based setting without a patient navigator (usual care). Adherence rates were compared among these three groups using a chi-squared test at a significance level of 0.05.\n\nRESULTS.\nA total of 155 patients with glaucoma-related diagnoses were enrolled. The mean age (\u00b1standard deviation) was 71.2 (\u00b110.0) years. Patients were predominantly female (65.8%, n=102/155) and African-American (71.6%, n=111/155). The mean (\u00b1standard deviation) number of follow-up visits during the 1-year study period was 1.3 (\u00b11.3) for G1, 1.6 (\u00b11.3) for G2, and 1.3 (\u00b11.1) for G3 (P=0.48). Appointment adherence, defined as attendance of \u22651 follow-up visit, was 69.8% (n=37/53) for G1, 82.5% (n=47/57) for G2, and 73.3% (n=33/45) for G3, (P=0.28). Sub-analysis of adherence rates for patients who attended \u22652 follow-up visits were 91.3% (n=21/23) for G1, 74.3% (n=26/35) for G2, and 66.7% (n=18/27) for G3, (P=0.11).\n\nCONCLUSION.\nHelp from a patient navigator did not increase the likelihood of keeping \u22651 follow-up appointment in an office-based setting. Adherence rates for follow-up appointments reached close to 70% or above in a self-selected patient population.", "target": "PURPOSE.\nThis study looked at how having a 'patient navigator' - a person who helps guide a patient through their healthcare journey - could change how regularly patients with glaucoma go to their follow-up eye check-ups. This is important because missed appointments can lead to worse vision problems. \n\nPATIENTS AND METHODS. \nThe study used people who were diagnosed with some form of glaucoma after taking an eye test in Philadelphia, USA. These people were put into three groups for one year: one group got their check-ups in their community with a patient navigator, the next group got check-ups in an office with a navigator, and the final group got office check-ups but without a navigator. Then, they compared how well each group stuck to their appointment schedule. \n\nRESULTS.\n155 patients were included in this study. They were generally around 71 years old, mostly women, and primarily African-American. The number of follow-up visits during the year was about the same between the three groups. Around 70% to 82% of patients in all groups attended at least one follow-up visit. When looking at only the people who attended two or more follow-up visits, the group with a patient navigator within the community had the highest turn out. \n\nCONCLUSION.\nEven though having a patient navigator didn't make people more likely to go to an office for their check-ups, people did have a decent rate of attendance at their follow-up visits on their own. It is unclear if the community-based care with a navigator helped with the higher rate of attendance for two or more check-ups, which suggests more study is needed.", "question": "What was the average number of follow-up visits for the group that received their check-ups in a community setting with a navigator (G1)?", "answer": "The average number of follow-up visits for G1, the group that had their check-ups in their community with a patient navigator, was 1.3 times in the year."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 1308, "end": 1470, "score": 1, "text": "The mean (\u00b1standard deviation) number of follow-up visits during the 1-year study period was 1.3 (\u00b11.3) for G1, 1.6 (\u00b11.3) for G2, and 1.3 (\u00b11.1) for G3 (P=0.48).", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 5043523, "edit_id": "0102b85a65656c8015210a7620b6d040", "source": "BACKGROUND.\nIt is hypothesised that individuals with knowledge of their genetic risk are more likely to make health-promoting dietary and lifestyle changes. The present study aims to test this hypothesis using data from the Food4Me study. This was a 6-month Internet-based randomised controlled trial conducted across seven centres in Europe where individuals received either general healthy eating advice or varying levels of personalised nutrition advice. Participants who received genotype-based personalised advice were informed whether they had the risk (CT/TT) (n = 178) or non-risk (CC) (n = 141) alleles of the methylenetetrahydrofolate reductase (MTHFR) gene in relation to cardiovascular health and the importance of a sufficient intake of folate. General linear model analysis was used to assess changes in folate intake between the MTHFR risk, MTHFR non-risk and control groups from baseline to month 6 of the intervention.\n\nRESULTS.\nThere were no differences between the groups for age, gender or BMI. However, there was a significant difference in country distribution between the groups (p = 0.010). Baseline folate intakes were 412 \u00b1 172, 391 \u00b1 190 and 410 \u00b1 186 \u03bcg per 10 MJ for the risk, non-risk and control groups, respectively. There were no significant differences between the three groups in terms of changes in folate intakes from baseline to month 6. Similarly, there were no changes in reported intake of food groups high in folate.\n\nCONCLUSIONS.\nThese results suggest that knowledge of MTHFR 677C \u2192 T genotype did not improve folate intake in participants with the risk variant compared with those with the non-risk variant.\n\nTRIAL REGISTRATION.\nClinicalTrials.gov NCT01530139\n\nELECTRONIC SUPPLEMENTARY MATERIAL.\nThe online version of this article (doi:10.1186/s12263-016-0539-x) contains supplementary material, which is available to authorized users.", "target": "BACKGROUND.\nThe researchers wanted to see if knowing about your personal genetic risks would encourage you to make healthier diet and lifestyle choices. They ran a 6-month online trial across seven locations in Europe. Some people received general healthy eating advice while others received advice tailored to their personal nutrition needs. One specific group learned whether they had a certain gene variant that increased their risk of heart disease. They were told about the importance of eating enough folate, a type of B vitamin. The researchers then analyzed changes in their folate intake over six months. \n\nRESULTS.\nThere wasn't any difference in age, gender, or body weight between the groups. Although, the number of participants from each country was not evenly spread across the groups. The amount of folate the groups ate at the start of the trial was about the same. Over six months, no group's folate intake changed significantly. \n\nCONCLUSIONS.\nThe finding implies that just knowing if you have a risky gene variant does not necessarily encourage you to eat more folate. \n\nTRIAL REGISTRATION.\nThis trial is recorded on ClinicalTrials.gov under the number NCT01530139\n\nELECTRONIC SUPPLEMENTARY MATERIAL.\nThere is additional information online for this study, which can be accessed by authorized individuals.", "question": "How many participants had the risk variants of the MTHFR gene?", "answer": "There were 178 participants in the study who had the risk variants (CT or TT) of the MTHFR gene."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 458, "end": 757, "score": 1, "text": "Participants who received genotype-based personalised advice were informed whether they had the risk (CT/TT) (n = 178) or non-risk (CC) (n = 141) alleles of the methylenetetrahydrofolate reductase (MTHFR) gene in relation to cardiovascular health and the importance of a sufficient intake of folate.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 5125808, "edit_id": "6f92aff53a19aaf5dd33abca642239a0", "source": "PURPOSE.\nTo evaluate the blood pressure (BP) lowering efficacy and safety of CKD-828, a fixed-dose combination of S-amlodipine (the more active isomer of amlodipine besylate, which is calcium channel blocker) and telmisartan (long acting angiotensin receptor blocker), in patients with hypertension inadequately controlled with S-amlodipine monotherapy.\n\nPATIENTS AND METHODS.\nEligible patients (N=187) who failed to respond after 4-week S-amlodipine 2.5 mg monotherapy (sitting diastolic blood pressure [sitDBP] \u226590 mmHg) to receive CKD-828 2.5/40 mg (n=63), CKD-828 2.5/80 mg (n=63), or S-amlodipine 2.5 mg (n=61) for 8 weeks. The primary efficacy endpoint, mean sitDBP change from baseline to Week 8, was compared between the combination (CKD-828 2.5/40 mg and CKD-828 2.5/80 mg) and S-amlodipine monotherapy groups. The safety was assessed based on adverse events, vital signs, and physical examination findings.\n\nRESULTS.\nAfter the 8-week treatment, changes in sitDBP/systolic BP (SBP) were \u22129.67\u00b16.50/\u221212.89\u00b111.78, \u221210.72\u00b16.19/\u221213.79\u00b19.41, and \u22124.93\u00b17.26/\u22124.55\u00b111.27 mmHg in the CKD-828 2.5/40 mg (P<0.0001/P<0.0001), CKD-828 2.5/80 mg (P<0.0001/P<0.0001), and S-amlodipine 2.5 mg (P<0.0001/P=0.0027) groups, respectively, which were all significant BP reductions. At Week 8, the CKD-828 2.5/40 mg (sitDBP/SBP: P=0.0002/P<0.0001) and CKD-828 2.5/80 mg (sitDBP/SBP: P=0.0001/P<0.0001) showed superior BP-lowering effects to S-amlodipine 2.5 mg (P<0.001). At Week 4, all groups showed significant antihypertensive effects but both CKD-828 combinations (CKD-828 2.5/40 mg and CKD-828 2.5/80 mg) exhibited superior BP-lowering effects to that of S-amlodipine 2.5 mg (sitDBP/SBP: P=0.0028/P=0.0001 and P<0.0001/P=0.0012, respectively). The adverse event incidence was significantly lower in the CKD-828 2.5/40 mg (9.52%, P=0.0086) than in the S-amlodipine 2.5 mg group (27.87%) and increasing the telmisartan dose induced no unexpected adverse events, suggesting the safety of CKD-828.\n\nCONCLUSION.\nCKD-828 is an effective and safe option for patients with inadequate responses to S-amlodipine monotherapy.", "target": "PURPOSE.\nThis study was done to check how well CKD-828, a mix of two blood pressure medicines, works and how safe it is for patients with high blood pressure who did not respond well to treatment with only one of these drugs (S-amlodipine).\n\nPATIENTS AND METHODS.\nWe tested 187 patients who still had high blood pressure after taking S-amlodipine for 4 weeks. They were given either CKD-828 in two different doses, or they continued on S-amlodipine. This was done for 8 weeks. We then compared how well the two treatments worked by looking at changes in blood pressure. Side effects, changes in vital signs, and physical exam results were looked at for safety.\n\nRESULTS.\nAfter 8 weeks, all treatments helped to lower blood pressure. However, the CKD-828 treatment in both doses worked better than S-amlodipine alone, both at 4 weeks and 8 weeks. There were also fewer side effects with one dose of CKD-828 compared to S-amlodipine. Increasing the dose of one component of CKD-828 did not lead to any unexpected side effects, indicating that it is safe.\n\nCONCLUSION.\nCKD-828 seems to be both effective and safe for patients with high blood pressure who haven't seen enough improvement with S-amlodipine alone.", "question": "What are the components of CKD-828 and what are their functions?", "answer": "CKD-828 is a combination of S-amlodipine and telmisartan. S-amlodipine is the more active isomer of amlodipine besylate, which is a calcium channel blocker. Telmisartan is a long-acting angiotensin receptor blocker. Both of these drugs are used to lower blood pressure."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 114, "end": 267, "score": 1, "text": "S-amlodipine (the more active isomer of amlodipine besylate, which is calcium channel blocker) and telmisartan (long acting angiotensin receptor blocker)", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 5433398, "edit_id": "6ff3ef348363c82740194c02c2a3514b", "source": "BACKGROUND.\nDisabled multiple sclerosis (MS) patients often need intervention of multiple specialists, resulting in a complex organization of care. How this multidisciplinary care should be organized and structured has not been studied.\n\nOBJECTIVE.\nThe objective of this article is to address the effectiveness of an integrated multidisciplinary approach versus usual care in MS patients.\n\nMETHODS.\nThis is a prospective, randomized, controlled, monocentric clinical trial in MS patients. Two treatment strategies were compared: (i) an integrated multidisciplinary (IMD) approach, consisting of a half-day individually tailored comprehensive assessment in the MS clinic; and (ii) a standard care. The primary outcome was the impact of the strategy on quality of life (QoL) measured using the MSIS-29 scale at inclusion and after six months.\n\nRESULTS.\nFifty MS patients were included. Median MSIS 29 score decreased over six months in the control group (\u22124.89) and increased in the IMD group (+2.00), with a significant difference between the two groups (p = 0.03). However, in the multivariate analysis, after adjustment of HAD-D and INTERMED score, this difference was no longer significant.\n\nCONCLUSIONS.\nThis prospective, randomized study is the first attempt to evaluate the multidisciplinary approach in MS patients. The results show that, contrary to our expectations, an integrated multidisciplinary approach is not superior to usual care on QoL.", "target": "BACKGROUND.\nPeople with multiple sclerosis (MS) often require care from many different doctors, which can create a complex system for managing their health. We don't yet know the best way to organize this type of team-based care.\n\nOBJECTIVE.\nThis study aims to find out if coordinating these multiple specialists in an integrated approach is more effective than the regular forms of care for MS patients.\n\nMETHODS.\nWe conducted a study with MS patients, comparing two different methods of care. The first method was a new, integrated team approach where the patients would spend a half-day at the MS clinic going through a comprehensive personal health assessment. The second method was the normal standard of care. We looked at how these two methods affected patients' quality of life (QoL), which was measured with a specific scale, at the start of the trial and after six months.\n\nRESULTS.\nWe involved 50 MS patients in our study. At the end of six months, the regular care group's quality of life score decreased a little, while the integrated care group's quality of life score increased a little. This difference looked significant at first glance. But, when we adjusted for other variables, the difference didn't stand out.\n\nCONCLUSIONS.\nThis is the first study trying to evaluate the use of a team-based approach to care for MS patients. Contrary to what we thought, the results show that coordinating multiple specialists in an integrated approach doesn't seem to make a big difference in improving quality of life compared to regular care.", "question": "What kind of patients were included in the study?", "answer": "The study included patients with multiple sclerosis (MS) who required care from multiple specialists."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 12, "end": 147, "score": 1, "text": "Disabled multiple sclerosis (MS) patients often need intervention of multiple specialists, resulting in a complex organization of care.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 5442667, "edit_id": "44f3e879c9940f127f0c3d68c34d3fab", "source": "BACKGROUND.\nThe complexity of medication therapy in older adults with multiple comorbidities often leads to inappropriate prescribing. Drugs with anticholinergic properties are of particular interest because many are not recognized for this property; their use may lead to increased anticholinergic burden resulting in significant health risks, as well as negatively impacting cognition. Medication therapy management (MTM) interventions showed promise in addressing inappropriate medication use, but the effectiveness of targeted multidisciplinary team interventions addressing anticholinergic medications in older populations is yet to be determined.\n\nMETHODS.\nWe conducted an 8-week, parallel-arm, randomized trial to evaluate whether a targeted patient-centered pharmacist\u2013physician team MTM intervention (\"targeted MTM intervention\") reduced the use of inappropriate anticholinergic medications in older patients enrolled in a longitudinal cohort at University of Kentucky's Alzheimer's Disease Center. Study outcomes included changes in the medication appropriateness index (MAI) targeting anticholinergic medications and in the anticholinergic drug scale (ADS) score from baseline to the end of study.\n\nRESULTS.\nBetween October 1, 2014 and September 30, 2015 we enrolled and randomized 50 participants taking at least one medication with anticholinergic properties. Of these, 35 (70%) were women, 45 (90%) were white, and 33 (66%) were cognitively intact (clinical dementia rating [CDR] = 0); mean age was 77.7 \u00b1 6.6 years. At baseline, the mean MAI was 12.6 \u00b1 6.3; 25 (50%) of the participants used two or more anticholinergics, and the mean ADS score was 2.8 \u00b1 1.6. After randomization, although no statistically significant difference was noted between groups, we identified a potentially meaningful imbalance as the intervention group had more participants with intact cognition, and thus included CDR in all of the analyses. The targeted MTM intervention resulted in statistically significant CDR adjusted differences between groups with regard to improved MAI (change score of 3.6 (1.1) for the MTM group as compared with 1.0 (0.9) for the control group, p = 0.04) and ADS (change score of 1.0 (0.3) for the MTM group as compared with 0.2 (0.3) for the control group, p = 0.03).\n\nCONCLUSIONS.\nOur targeted MTM intervention resulted in improvement in anticholinergic medication appropriateness and reduced the use of inappropriate anticholinergic medications in older patients. Our results show promise in an area of great importance to ensure optimum outcomes for medications used in older adults.\n\nTRIAL REGISTRATION.\nClinicalTrials.gov NCT02172612. Registered 20 June 2014.\n\nELECTRONIC SUPPLEMENTARY MATERIAL.\nThe online version of this article (doi:10.1186/s13195-017-0263-9) contains supplementary material, which is available to authorized users.", "target": "BACKGROUND.\nOlder adults with several health problems often get prescribed too many medications. One group of drugs, known as anticholinergics, can be especially dangerous if overused, as they can have harmful effects on health and brain function. We wanted to see whether a special type of coordinated care between doctors and pharmacists could help reduce the use of these drugs. \n\nMETHODS.\nWe had older patients at the University of Kentucky's Alzheimer's Disease Center, who were taking at least one anticholinergic drug, participate in an 8-week study. We split them into two groups. One group received extra help and advice from a team of a pharmacist and a doctor, while the other group received usual care. We then compared how the groups changed in their use of anticholinergic drugs over the course of the study.\n\nRESULTS.\nWe recruited 50 patients between October 2014 and September 2015. Most were women, white, and with normal brain function. On average, they were around 78 years old. At the start of the study, half of them were taking two or more anticholinergic drugs. After the study,  the group that received extra care saw improved medication appropriateness and reduced their use of anticholinergic drugs. \n\nCONCLUSIONS.\nOur results suggest that the additional support from a doctor and pharmacist team can help older adults reduce their use of potentially harmful medications. This finding is an important step toward helping older adults take only the medications that benefit them the most. \n\nTRIAL REGISTRATION.\nThe study has been legally registered on ClinicalTrials.gov. \n\nELECTRONIC SUPPLEMENTARY MATERIAL.\nMore information about this study can be found online if you're authorized to access it.", "question": "What were the exact demographic details of the participants in the study?", "answer": "Of the 50 participants in the study, 70% (35 participants) were women, 90% (45 participants) were white, and 66% (33 participants) had normal brain function, as indicated by a clinical dementia rating of 0. The average age of the participants was 77.7 years."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 1219, "end": 1530, "score": 1, "text": "Between October 1, 2014 and September 30, 2015 we enrolled and randomized 50 participants taking at least one medication with anticholinergic properties. Of these, 35 (70%) were women, 45 (90%) were white, and 33 (66%) were cognitively intact (clinical dementia rating [CDR] = 0); mean age was 77.7 \u00b1 6.6 years.", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 833, "end": 997, "score": 1, "text": "We recruited 50 patients between October 2014 and September 2015. Most were women, white, and with normal brain function. On average, they were around 78 years old.", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 5442667, "edit_id": "9a0cb9f4c9be703b19b10eb7b085e5bb", "source": "BACKGROUND.\nThe complexity of medication therapy in older adults with multiple comorbidities often leads to inappropriate prescribing. Drugs with anticholinergic properties are of particular interest because many are not recognized for this property; their use may lead to increased anticholinergic burden resulting in significant health risks, as well as negatively impacting cognition. Medication therapy management (MTM) interventions showed promise in addressing inappropriate medication use, but the effectiveness of targeted multidisciplinary team interventions addressing anticholinergic medications in older populations is yet to be determined.\n\nMETHODS.\nWe conducted an 8-week, parallel-arm, randomized trial to evaluate whether a targeted patient-centered pharmacist\u2013physician team MTM intervention (\"targeted MTM intervention\") reduced the use of inappropriate anticholinergic medications in older patients enrolled in a longitudinal cohort at University of Kentucky's Alzheimer's Disease Center. Study outcomes included changes in the medication appropriateness index (MAI) targeting anticholinergic medications and in the anticholinergic drug scale (ADS) score from baseline to the end of study.\n\nRESULTS.\nBetween October 1, 2014 and September 30, 2015 we enrolled and randomized 50 participants taking at least one medication with anticholinergic properties. Of these, 35 (70%) were women, 45 (90%) were white, and 33 (66%) were cognitively intact (clinical dementia rating [CDR] = 0); mean age was 77.7 \u00b1 6.6 years. At baseline, the mean MAI was 12.6 \u00b1 6.3; 25 (50%) of the participants used two or more anticholinergics, and the mean ADS score was 2.8 \u00b1 1.6. After randomization, although no statistically significant difference was noted between groups, we identified a potentially meaningful imbalance as the intervention group had more participants with intact cognition, and thus included CDR in all of the analyses. The targeted MTM intervention resulted in statistically significant CDR adjusted differences between groups with regard to improved MAI (change score of 3.6 (1.1) for the MTM group as compared with 1.0 (0.9) for the control group, p = 0.04) and ADS (change score of 1.0 (0.3) for the MTM group as compared with 0.2 (0.3) for the control group, p = 0.03).\n\nCONCLUSIONS.\nOur targeted MTM intervention resulted in improvement in anticholinergic medication appropriateness and reduced the use of inappropriate anticholinergic medications in older patients. Our results show promise in an area of great importance to ensure optimum outcomes for medications used in older adults.\n\nTRIAL REGISTRATION.\nClinicalTrials.gov NCT02172612. Registered 20 June 2014.\n\nELECTRONIC SUPPLEMENTARY MATERIAL.\nThe online version of this article (doi:10.1186/s13195-017-0263-9) contains supplementary material, which is available to authorized users.", "target": "BACKGROUND.\nOlder adults with several health problems often get prescribed too many medications. One group of drugs, known as anticholinergics, can be especially dangerous if overused, as they can have harmful effects on health and brain function. We wanted to see whether a special type of coordinated care between doctors and pharmacists could help reduce the use of these drugs. \n\nMETHODS.\nWe had older patients at the University of Kentucky's Alzheimer's Disease Center, who were taking at least one anticholinergic drug, participate in an 8-week study. We split them into two groups. One group received extra help and advice from a team of a pharmacist and a doctor, while the other group received usual care. We then compared how the groups changed in their use of anticholinergic drugs over the course of the study.\n\nRESULTS.\nWe recruited 50 patients between October 2014 and September 2015. Most were women, white, and with normal brain function. On average, they were around 78 years old. At the start of the study, half of them were taking two or more anticholinergic drugs. After the study,  the group that received extra care saw improved medication appropriateness and reduced their use of anticholinergic drugs. \n\nCONCLUSIONS.\nOur results suggest that the additional support from a doctor and pharmacist team can help older adults reduce their use of potentially harmful medications. This finding is an important step toward helping older adults take only the medications that benefit them the most. \n\nTRIAL REGISTRATION.\nThe study has been legally registered on ClinicalTrials.gov. \n\nELECTRONIC SUPPLEMENTARY MATERIAL.\nMore information about this study can be found online if you're authorized to access it.", "question": "What are MTM interventions?", "answer": "MTM interventions are a type of coordinated care between doctors and pharmacists that aims to improve medication use and reduce the risk of adverse effects."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 388, "end": 437, "score": 1, "text": "Medication therapy management (MTM) interventions", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 291, "end": 339, "score": 1, "text": "coordinated care between doctors and pharmacists", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 5518918, "edit_id": "cf857da4a84ab4bfa5380b657a319346", "source": "AIM.\nAlthough cardiac rehabilitation improves physical fitness after a cardiac event, many eligible patients do not participate in cardiac rehabilitation and the beneficial effects of cardiac rehabilitation are often not maintained over time. Home-based training with telemonitoring guidance could improve participation rates and enhance long-term effectiveness.\n\nMETHODS AND RESULTS.\nWe randomised 90 low-to-moderate cardiac risk patients entering cardiac rehabilitation to three months of either home-based training with telemonitoring guidance or centre-based training. Although training adherence was similar between groups, satisfaction was higher in the home-based group (p = 0.02). Physical fitness improved at discharge (p < 0.01) and at one-year follow-up (p < 0.01) in both groups, without differences between groups (home-based p = 0.31 and centre-based p = 0.87). Physical activity levels did not change during the one-year study period (centre-based p = 0.38, home-based p = 0.80). Healthcare costs were statistically non-significantly lower in the home-based group (\u20ac437 per patient, 95% confidence interval \u2013562 to 1436, p = 0.39). From a societal perspective, a statistically non-significant difference of \u20ac3160 per patient in favour of the home-based group was found (95% confidence interval \u2013460 to 6780, p = 0.09) and the probability that it was more cost-effective varied between 97% and 75% (willingness-to-pay of \u20ac0 and \u20ac100,000 per quality-adjusted life-years, respectively).\n\nCONCLUSION.\nWe found no differences between home-based training with telemonitoring guidance and centre-based training on physical fitness, physical activity level or health-related quality of life. However, home-based training was associated with a higher patient satisfaction and appears to be more cost-effective than centre-based training. We conclude that home-based training with telemonitoring guidance can be used as an alternative to centre-based training for low-to-moderate cardiac risk patients entering cardiac rehabilitation.", "target": "GOAL: \nWe wanted to see whether following a heart-related event, at-home fitness programs with virtual support could help more patients stick with their exercise routines and possibly get better results. \n\nMETHODS AND RESULTS:\nWe tried this with 90 patients who had medium or low risk for future heart issues. We divided them into two groups: one group did their rehab exercises at home with virtual support, and the other group did the same exercises but at a rehab center. \n\nWe found out that both groups stuck to their workouts equally well. However, the people who exercised at home were happier. Also, everyone in both groups got more fit after rehab and kept that up after one year, with no big difference between the two groups. \n\nExercise levels didn't change within one year. Although not statistically significant, it seemed to cost less for the healthcare system if patients exercised at home, by an average of \u20ac437 per patient. When we looked at the bigger picture, we also found that the home-based training might save more money \u2013 around \u20ac3160 per patient. \n\nCONCLUSION:\nOverall, we didn't find a big difference in fitness gains, physical activity levels, or life quality between at-home workouts with virtual help and center-based workouts. But with the folks at home, they liked their workouts more and it cost less overall. So, we believe that for patients with low-to-medium heart disease risk, using at-home workouts with virtual support works just as well as doing workouts at a rehab center.", "question": "What type of training did the patients receive at home?", "answer": "The patients received home-based training with telemonitoring guidance, which involves remote monitoring and guidance by healthcare professionals."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 243, "end": 291, "score": 1, "text": "Home-based training with telemonitoring guidance", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 1194, "end": 1228, "score": 1, "text": "at-home workouts with virtual help", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 5545112, "edit_id": "4959bc91503ce12e716d595e9f59f886", "source": "AIM.\nTo prospectively evaluate the effects of vitamin D3 on disease activity and quality of life in ulcerative colitis (UC) patients with hypovitaminosis D.\n\nMETHODS.\nThe study was a prospective double-blinded, randomized trial conducted at Community Regional Medical Center, Fresno, CA from 2012\u20132013. Patients with UC and a serum 25(OH)D level <30\u00a0ng/ml were eligible for the study. Enrolled subjects were randomized to receive either 2,000 IU or 4,000 IU of oral vitamin D3 daily for a total of 90 days. The Short IBD Questionnaire (SIBDQ) for quality of life, the Partial Mayo Score for UC disease activity and serum lab tests were compared between the two treatment groups. Matched pair t-tests were computed to assess differences between the vitamin D levels, CRP, UC disease activity and SIBDQ scores before and after vitamin D3 therapy using SPSS version 21.\n\nRESULTS.\nEight UC patients received 2,000 IU/daily and ten UC patients received 4,000 IU/daily of vitamin D3 for 90 days. Vitamin D levels increased after 90 days of oral vitamin D3 in both dose groups. However, the increase in vitamin D levels after 90 days of oral vitamin D3, in the 4,000 IU group was significantly higher 16.80\u00a0\u00b1\u00a09.15 (p\u00a0<\u00a00.001) compared to the 2,000 IU group of vitamin D 5.00\u00a0\u00b1\u00a03.12 (p\u00a0=\u00a00.008). Normal vitamin D levels (>30 ng/dl) were achieved in four out of the ten UC patients (40%) in the 4,000 IU group and in one out of the eight UC patients (12%) in the 2,000 IU group. In the group receiving 4,000 IU/day of vitamin D3 the increase in quality life scores (SIBDQ) was significant 1.0\u00a0\u00b1\u00a01.0 (p\u00a0=\u00a00.017) but not in the 2,000 IU vitamin D3 group 0.1\u00a0\u00b1\u00a01.0 (p\u00a0=\u00a00.87). In the 2,000 IU of vitamin D3 group the mean decrease in the Partial Mayo UC Score was \u22120.5\u00a0\u00b1\u00a01.5 (p\u00a0=\u00a00.38) compared to \u22121.3\u00a0\u00b1\u00a02.9 (p\u00a0=\u00a00.19) in the 4,000 IU vitamin D3 group but this was not statistically significant. CRP levels decreased after 90 days of daily vitamin D3 in both the 2,000 IU group and 4,000 IU group by \u22123.0\u00a0\u00b1\u00a09.4 (p\u00a0=\u00a00.4) and \u221210.8\u00a0\u00b1\u00a035.0 (p\u00a0=\u00a00.36) respectively.\n\nCONCLUSION.\nVitamin D3 at 4,000 IU/day is more effective than 2,000 IU/day in increasing vitamin D to sufficient levels in UC patients with hypovitaminosis D, however higher doses or treatment beyond ninety days may be required. Vitamin D3 may improve the quality of life in UC patients but clinically significant improvement is not yet established. The effect of vitamin D3 on UC disease activity is still unclear. Further larger studies are needed to investigate the effects of vitamin D in ulcerative\u00a0colitis.", "target": "GOAL:\nThis study looks at whether taking vitamin D3 can affect a particular form of bowel disease (ulcerative colitis) and improve the lives of patients with low levels of vitamin D.\n\nMETHODS:\nThe study was carried out at a medical center in Fresno, California, between 2012 and 2013. Patients with this disease and low vitamin D levels were included. Participants were randomly given either 2,000 IU or 4,000 IU of vitamin D3 daily for 90 days. Researchers used surveys about participant\u2019s quality of life and a score system for disease severity. Lab tests were done and compared between the two groups. Researchers also checked if their vitamin D levels, inflammation, and scores changed before and after taking the vitamin D3.\n\nRESULTS:\nEight patients got 2,000 IU/daily and ten got 4,000 IU/daily of vitamin D3 for three months. Vitamin D levels went up in both groups, but more so in the group taking the higher dose. Healthy vitamin D levels were reached in four out of the ten patients (40%) in the high dose group and one out of eight patients (12%) in the low dose group. The quality of life score also improved significantly in the high dose group, but not in the low dose group. The severity scores of the disease didn\u2019t change significantly in either group. Taking vitamin D3 also seemed to lower inflammation in both groups.\n\nCONCLUSION:\nTaking 4,000 IU/day of vitamin D3 is more likely to increase vitamin D levels in patients with low levels of vitamin D. However, higher doses or longer time may be needed. Vitamin D3 might improve the quality of life in these patients, but it isn't proven yet. The effect on the severity of the disease is still not clear. More research is needed to better understand the impact of vitamin D in this bowel disease.", "question": "What was the aim of the study?", "answer": "The aim of the study was to evaluate the effects of vitamin D3 on disease activity and quality of life in ulcerative colitis (UC) patients with hypovitaminosis D."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 0, "end": 4, "score": 1, "text": "AIM.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 5545112, "edit_id": "a770380e7d192dd8a49b1aad3eca0578", "source": "AIM.\nTo prospectively evaluate the effects of vitamin D3 on disease activity and quality of life in ulcerative colitis (UC) patients with hypovitaminosis D.\n\nMETHODS.\nThe study was a prospective double-blinded, randomized trial conducted at Community Regional Medical Center, Fresno, CA from 2012\u20132013. Patients with UC and a serum 25(OH)D level <30\u00a0ng/ml were eligible for the study. Enrolled subjects were randomized to receive either 2,000 IU or 4,000 IU of oral vitamin D3 daily for a total of 90 days. The Short IBD Questionnaire (SIBDQ) for quality of life, the Partial Mayo Score for UC disease activity and serum lab tests were compared between the two treatment groups. Matched pair t-tests were computed to assess differences between the vitamin D levels, CRP, UC disease activity and SIBDQ scores before and after vitamin D3 therapy using SPSS version 21.\n\nRESULTS.\nEight UC patients received 2,000 IU/daily and ten UC patients received 4,000 IU/daily of vitamin D3 for 90 days. Vitamin D levels increased after 90 days of oral vitamin D3 in both dose groups. However, the increase in vitamin D levels after 90 days of oral vitamin D3, in the 4,000 IU group was significantly higher 16.80\u00a0\u00b1\u00a09.15 (p\u00a0<\u00a00.001) compared to the 2,000 IU group of vitamin D 5.00\u00a0\u00b1\u00a03.12 (p\u00a0=\u00a00.008). Normal vitamin D levels (>30 ng/dl) were achieved in four out of the ten UC patients (40%) in the 4,000 IU group and in one out of the eight UC patients (12%) in the 2,000 IU group. In the group receiving 4,000 IU/day of vitamin D3 the increase in quality life scores (SIBDQ) was significant 1.0\u00a0\u00b1\u00a01.0 (p\u00a0=\u00a00.017) but not in the 2,000 IU vitamin D3 group 0.1\u00a0\u00b1\u00a01.0 (p\u00a0=\u00a00.87). In the 2,000 IU of vitamin D3 group the mean decrease in the Partial Mayo UC Score was \u22120.5\u00a0\u00b1\u00a01.5 (p\u00a0=\u00a00.38) compared to \u22121.3\u00a0\u00b1\u00a02.9 (p\u00a0=\u00a00.19) in the 4,000 IU vitamin D3 group but this was not statistically significant. CRP levels decreased after 90 days of daily vitamin D3 in both the 2,000 IU group and 4,000 IU group by \u22123.0\u00a0\u00b1\u00a09.4 (p\u00a0=\u00a00.4) and \u221210.8\u00a0\u00b1\u00a035.0 (p\u00a0=\u00a00.36) respectively.\n\nCONCLUSION.\nVitamin D3 at 4,000 IU/day is more effective than 2,000 IU/day in increasing vitamin D to sufficient levels in UC patients with hypovitaminosis D, however higher doses or treatment beyond ninety days may be required. Vitamin D3 may improve the quality of life in UC patients but clinically significant improvement is not yet established. The effect of vitamin D3 on UC disease activity is still unclear. Further larger studies are needed to investigate the effects of vitamin D in ulcerative\u00a0colitis.", "target": "GOAL:\nThis study looks at whether taking vitamin D3 can affect a particular form of bowel disease (ulcerative colitis) and improve the lives of patients with low levels of vitamin D.\n\nMETHODS:\nThe study was carried out at a medical center in Fresno, California, between 2012 and 2013. Patients with this disease and low vitamin D levels were included. Participants were randomly given either 2,000 IU or 4,000 IU of vitamin D3 daily for 90 days. Researchers used surveys about participant\u2019s quality of life and a score system for disease severity. Lab tests were done and compared between the two groups. Researchers also checked if their vitamin D levels, inflammation, and scores changed before and after taking the vitamin D3.\n\nRESULTS:\nEight patients got 2,000 IU/daily and ten got 4,000 IU/daily of vitamin D3 for three months. Vitamin D levels went up in both groups, but more so in the group taking the higher dose. Healthy vitamin D levels were reached in four out of the ten patients (40%) in the high dose group and one out of eight patients (12%) in the low dose group. The quality of life score also improved significantly in the high dose group, but not in the low dose group. The severity scores of the disease didn\u2019t change significantly in either group. Taking vitamin D3 also seemed to lower inflammation in both groups.\n\nCONCLUSION:\nTaking 4,000 IU/day of vitamin D3 is more likely to increase vitamin D levels in patients with low levels of vitamin D. However, higher doses or longer time may be needed. Vitamin D3 might improve the quality of life in these patients, but it isn't proven yet. The effect on the severity of the disease is still not clear. More research is needed to better understand the impact of vitamin D in this bowel disease.", "question": "Where was this study conducted?", "answer": "The study was conducted at Community Regional Medical Center."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 167, "end": 302, "score": 1, "text": "The study was a prospective double-blinded, randomized trial conducted at Community Regional Medical Center, Fresno, CA from 2012\u20132013.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 5588713, "edit_id": "8d122e102d23aea0ede7ada743674444", "source": "BACKGROUND.\nInhalation of particulate matter, as part of air pollution, is associated with increased morbidity and mortality. Nanoparticles (< 100 nm) are likely candidates for triggering inflammatory responses and activation of coagulation pathways because of their ability to enter lung cells and pass bronchial mucosa. We tested the hypothesis that bronchial segmental instillation of carbon nanoparticles causes inflammation and activation of coagulation pathways in healthy humans in vivo.\n\nMETHODS.\nThis was an investigator-initiated, randomized controlled, dose-escalation study in 26 healthy males. Participants received saline (control) in one lung segment and saline (placebo) or carbon nanoparticles 10 \u03bcg, 50 \u03bcg, or 100 \u03bcg in the contra-lateral lung. Six hours later, blood and bronchoalveolar lavage fluid (BALF) was collected for inflammation and coagulation parameters.\n\nRESULTS.\nThere was a significant dose-dependent increase in blood neutrophils (p = 0.046) after challenge with carbon nanoparticles. The individual top-dose of 100 \u03bcg showed a significant (p = 0.05) increase in terms of percentage neutrophils in blood as compared to placebo.\n\nCONCLUSIONS.\nThis study shows a dose-dependent effect of bronchial segmental challenge with carbon nanoparticles on circulating neutrophils of healthy volunteers. This suggests that nanoparticles in the respiratory tract induce systemic inflammation.\n\nTRIAL REGISTRATION.\nDutch Trial Register no. 2976. 11 July 2011. http://www.trialregister.nl/trialreg/admin/rctview.asp?TC=2976\n\nELECTRONIC SUPPLEMENTARY MATERIAL.\nThe online version of this article (10.1186/s12890-017-0463-x) contains supplementary material, which is available to authorized users.", "target": "BACKGROUND.\nBreathing in tiny pieces of dust in the air, or air pollution, is linked with greater risks of illness and death. Extra-small particles, termed nanoparticles, may cause health problems like inflammation and blood clotting because they can enter lung cells and pass through lung mucus. We tested the idea that purposely putting carbon nanoparticles in certain areas of the lungs can cause inflammation and trigger blood clotting in healthy people.\n\nMETHODS.\nWe ran a study where we controlled the amount of carbon nanoparticles we gave to 26 healthy men. These participants had saltwater (a control substance) put in one part of their lungs and either more saltwater (a placebo) or different amounts of carbon nanoparticles in the other part. After 6 hours, we collected samples of their blood and washings from lung fluid to test for signs of inflammation and blood clotting.\n\nRESULTS.\nWe found that the more carbon nanoparticles we used, the more white blood cells (cells that fight infection) appeared in the blood samples. Additionally, using the highest amount of nanoparticles caused a significant increase in these cells compared to using the placebo.\n\nCONCLUSIONS.\nThis study shows that purposely sending carbon nanoparticles into certain parts of the lungs of healthy people can increase the number of infection-fighting cells in their blood. This suggests that small particles in the lungs can cause body-wide inflammation.\n\nTRIAL REGISTRATION.\nThis study was registered with the Dutch Trial Register on July 11, 2011. The registration number is 2976. Further information can be found online.\n\nADDITIONAL MATERIAL.\nThe online article of this study (10.1186/s12890-017-0463-x) has additional content, which can be accessed by authorized users.", "question": "What is the link between inhaling tiny particles in the air and health risks?", "answer": "Inhaling tiny particles in the air, or air pollution, is linked with greater risks of illness and death."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 12, "end": 125, "score": 1, "text": "Inhalation of particulate matter, as part of air pollution, is associated with increased morbidity and mortality.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 5771057, "edit_id": "1b7e9955f14249223f370779d68a39e4", "source": "PURPOSE.\nThis study examines whether cognitive function, as measured by the subtests of the Woodcock\u2013Johnson III (WCJ-III) assessment, predicts listening-effort performance during dual tasks across the adults of varying ages.\n\nMATERIALS AND METHODS.\nParticipants were divided into two groups. Group 1 consisted of 14 listeners (number of females\u2009=\u200911) who were 41\u201361 years old [mean\u2009=\u200953.18; standard deviation (SD)\u2009=\u20095.97]. Group 2 consisted of 15 listeners (number of females\u2009=\u20099) who were 63\u201381 years old (mean\u2009=\u200972.07; SD\u2009=\u20095.11). Participants were administered the WCJ-III Memory for Words, Auditory Working Memory, Visual Matching, and Decision Speed subtests. All participants were tested in each of the following three dual-task experimental conditions, which were varying in complexity: (1) auditory word recognition\u2009+\u2009visual processing, (2) auditory working memory (word)\u2009+\u2009visual processing, and (3) auditory working memory (sentence)\u2009+\u2009visual processing in noise.\n\nRESULTS.\nA repeated measures analysis of variance revealed that task complexity significantly affected the performance measures of auditory accuracy, visual accuracy, and processing speed. Linear regression revealed that the cognitive subtests of the WCJ-III test significantly predicted performance across dependent variable measures.\n\nCONCLUSION.\nListening effort is significantly affected by task complexity, regardless of age. Performance on the WCJ-III test may predict listening effort in adults and may assist speech-language pathologist (SLPs) to understand challenges faced by participants when subjected to noise.", "target": "PURPOSE.\nThis study aims to establish if a test we often use to assess thinking skills can also help us understand how hard adults of different ages find it to listen and do something else at the same time.\n\nMATERIALS AND METHODS.\nWe had two groups of volunteers. The first group, made up of 14 people mostly women (11 out of 14), were aged between 41 and 61 years. The second group had 15 people, only nine women, aged between 63 and 81. We asked these people to do a few tests from the Woodcock\u2013Johnson III. This is an assessment tool we typically use to evaluate how the brain processes information. Then our volunteers had to do two tasks at the same time. These tasks were a bit different for each round, but the idea was always the same: listen to something while also watching something.\n\nRESULTS.\nLooking at the results, it became clear that the difficulty of the task influences how well people did in terms of hearing accurately, seeing accurately, and how quickly they processed information. Additionally, the certain thinking-related subtests from the taken test could potentially help predict how well people performed in complex tests.\n\nCONCLUSION.\nIt turns out that the more difficult the task, the harder it can be for anyone, regardless of their age, to listen and do another task at the same time. Also, the better someone does on the specific Woodcock\u2013Johnson III test, the easier they might find doing two things at once. This information may help speech-language experts understand the problems individuals might run into when there's background noise.", "question": "How was it determined that the cognitive subtests of the WCJ-III test could predict performance?", "answer": "Linear regression was used to determine that the cognitive subtests of the WCJ-III test could predict performance across dependent variable measures."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 1166, "end": 1312, "score": 1, "text": "Linear regression revealed that the cognitive subtests of the WCJ-III test significantly predicted performance across dependent variable measures.", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 1003, "end": 1149, "score": 1, "text": "Additionally, the certain thinking-related subtests from the taken test could potentially help predict how well people performed in complex tests.", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 5827507, "edit_id": "c0880424e77a96bf54461f5194f9decb", "source": "CONTEXT.\nDentinal hypersensitivity (DH) is a chronic disorder in which patients report sharp and acute pain to a variety of stimuli. Till date, a standardized procedure to treat DH is missing, though several alternative treatment strategies have been designed, including laser therapies.\n\nAIM.\nThe aim of the study was to treat DH with minimum chemical concentration and least laser energy level with longer follow-up period.\n\nMATERIALS AND METHODS.\nOne hundred and twenty patients were randomly divided into four groups: (i) Group 1-5% potassium nitrate (KNO3); (ii) Group 2 - gallium-aluminum-arsenide diode laser (62.2 J/cm2, wavelength - 980 nm, noncontact pulse mode, and power wattage - 0.5 W); (iii) Group 3 - combined 5% KNO3 and the diode laser; and (iv) Group 4 - placebo (control). The visual analog scale (VAS) scores were recorded, analyzed, and compared to tactile stimuli, cold water, and air blast tests at different intervals for 6 weeks.\n\nRESULTS.\nSynergistic use of 5% KNO3 and diode laser (Group 3) significantly reduced the DH pain, which was almost negligible after 6th week (97%\u201399% of the pain was reported to be relieved) and showed promising results than any other studied groups. Further, the diode laser (Group 2) showed better results than 5% KNO3 (Group 1). One-way ANOVA and Bonferroni correction post hoc test revealed the combination of groups with significant differences in the mean VAS scores at the different interval of time (P < 0.01).\n\nCONCLUSIONS.\nConvincingly, the combined application of 5% KNO3 with the diode laser can be recommended for treating DH patients.", "target": "CONTEXT.\nPeople who experience sensitivity in their teeth (also known as dentinal hypersensitivity or DH) often feel a sharp pain when they eat certain foods or drink certain liquids. Up to now, there hasn't been a universal treatment for this type of tooth sensitivity, though some doctors have been using various methods, including laser treatments.\n\nAIM.\nThe goal of this study was to find a way to treat tooth sensitivity using the smallest amount possible of a particular chemical and a low level of laser energy, and then keep track of those patients for a long period of time. \n\nMATERIALS AND METHODS.\nOne hundred and twenty patients were randomly split into four groups: one group was treated with potassium nitrate; a second group had a procedure done with a specific type of laser; a third group both received the chemical and the laser treatment; the fourth group received a placebo or fake treatment. They measured the levels of the patients' tooth sensitivity by asking them to describe their pain before and after the treatment. This was done using tests with different materials and temperatures over a period of 6 weeks. \n\nRESULTS.\nThe group where we combined the chemical and laser treatment (Group 3) reported a significant decrease in their tooth sensitivity. In fact, by the 6th week, almost all of the patients in that group no longer felt the pain (97%-99% of them reported relief). This group performed better than the other treatment groups. \n\nCONCLUSIONS.\nConsidering these results, using a combination of low-dose potassium nitrate and laser treatment seems to be an effective way to treat tooth sensitivity.", "question": "What type of laser was used in the study and what were its specifications?", "answer": "A gallium-aluminum-arsenide diode laser was used in the study. It had a power density of 62.2 J/cm2, a wavelength of 980 nm, was used in noncontact pulse mode, and had a power wattage of 0.5 W."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 578, "end": 699, "score": 1, "text": "gallium-aluminum-arsenide diode laser (62.2 J/cm2, wavelength - 980 nm, noncontact pulse mode, and power wattage - 0.5 W)", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 5861369, "edit_id": "92dd3fbd2d47dcdd6acea9753532458e", "source": "BACKGROUND/AIMS.\nPolycystic ovary syndrome (PCOS) is associated with insulin resistance, adrenal hyperactivity and decreased mental health. We aimed to investigate the changes in adrenal activity, metabolic status and mental health in PCOS during treatment with escitalopram or placebo.\n\nMETHODS.\nForty-two overweight premenopausal women with PCOS and no clinical depression were randomized to 12-week SSRI (20\u2009mg escitalopram/day, n\u2009=\u200921) or placebo (n\u2009=\u200921). Patients underwent clinical examination, fasting blood samples, adrenocorticotroph hormone (ACTH) test, 3-h oral glucose tolerance test (OGTT) and filled in questionnaires regarding mental health and health-related quality of life (HRQoL): WHO Well-Being Index (WHO-5), Major Depression Inventory (MDI), Short Form 36 (SF-36) and PCOS questionnaire.\n\nRESULTS.\nIncluded women were aged 31 (6) years (mean (s.d.)) and had body mass index (BMI) 35.8 (6.5)\u2009kg/m2 and waist 102 (12)\u2009cm. Escitalopram was associated with increased waist (median (quartiles) change 1 (0; 3) cm), P\u2009=\u20090.005 vs change during placebo and increased cortisol levels (cortisol 0, cortisol 60, peak cortisol and area under the curve for cortisol during ACTH test), all P\u2009<\u20090.05 vs changes during placebo. Escitalopram had no significant effect on measures of insulin sensitivity, insulin secretion, fasting lipids, mental health or HRQoL.\n\nCONCLUSION.\nWaist circumference and cortisol levels increased during treatment with escitalopram in women with PCOS and no clinical depression, whereas metabolic risk markers, mental health and HRQol were unchanged.", "target": "BACKGROUND/AIMS.\nThis study looks into polycystic ovary syndrome (PCOS), a condition often paired with insulin resistance, high adrenal activity and decreased mental wellbeing. It tests the effects of a drug called escitalopram (or a placebo) on these issues in women with PCOS.\n\nMETHODS.\nThe trial involved 42 overweight women with PCOS who were not experiencing clinical depression. They were split into two groups \u2013 one group took 20mg of escitalopram daily for 12 weeks, the other took a placebo. The women underwent physical exams, blood tests, and completed questionnaires about their mental health and quality of life. \n\nRESULTS.\nThe average participant was 31 years old, had a BMI of 35.8 and a waist measurement of 102cm. Escitalopram was found to be related to an increase in waist size and cortisol (stress hormone) levels, compared to the placebo group. However, the drug didn't significantly affect insulin levels, lipid levels, mental health or the overall quality of life.\n\nCONCLUSION.\nIn women with PCOS but without clinical depression, escitalopram increased waist circumference and cortisol levels. However, it didn't noticeable alter metabolic risk factors, mental wellbeing or quality of life.", "question": "What specific tests were conducted on the patients during the study?", "answer": "The patients underwent an adrenocorticotroph hormone (ACTH) test, which measures the levels of ACTH in the blood and can help find problems with the adrenal and pituitary glands. They also underwent a 3-hour oral glucose tolerance test (OGTT), which measures the body's ability to use glucose, a type of sugar."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 525, "end": 603, "score": 1, "text": "adrenocorticotroph hormone (ACTH) test, 3-h oral glucose tolerance test (OGTT)", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 5861369, "edit_id": "ded513204eb0cfbb7111b3a3c683b535", "source": "BACKGROUND/AIMS.\nPolycystic ovary syndrome (PCOS) is associated with insulin resistance, adrenal hyperactivity and decreased mental health. We aimed to investigate the changes in adrenal activity, metabolic status and mental health in PCOS during treatment with escitalopram or placebo.\n\nMETHODS.\nForty-two overweight premenopausal women with PCOS and no clinical depression were randomized to 12-week SSRI (20\u2009mg escitalopram/day, n\u2009=\u200921) or placebo (n\u2009=\u200921). Patients underwent clinical examination, fasting blood samples, adrenocorticotroph hormone (ACTH) test, 3-h oral glucose tolerance test (OGTT) and filled in questionnaires regarding mental health and health-related quality of life (HRQoL): WHO Well-Being Index (WHO-5), Major Depression Inventory (MDI), Short Form 36 (SF-36) and PCOS questionnaire.\n\nRESULTS.\nIncluded women were aged 31 (6) years (mean (s.d.)) and had body mass index (BMI) 35.8 (6.5)\u2009kg/m2 and waist 102 (12)\u2009cm. Escitalopram was associated with increased waist (median (quartiles) change 1 (0; 3) cm), P\u2009=\u20090.005 vs change during placebo and increased cortisol levels (cortisol 0, cortisol 60, peak cortisol and area under the curve for cortisol during ACTH test), all P\u2009<\u20090.05 vs changes during placebo. Escitalopram had no significant effect on measures of insulin sensitivity, insulin secretion, fasting lipids, mental health or HRQoL.\n\nCONCLUSION.\nWaist circumference and cortisol levels increased during treatment with escitalopram in women with PCOS and no clinical depression, whereas metabolic risk markers, mental health and HRQol were unchanged.", "target": "BACKGROUND/AIMS.\nThis study looks into polycystic ovary syndrome (PCOS), a condition often paired with insulin resistance, high adrenal activity and decreased mental wellbeing. It tests the effects of a drug called escitalopram (or a placebo) on these issues in women with PCOS.\n\nMETHODS.\nThe trial involved 42 overweight women with PCOS who were not experiencing clinical depression. They were split into two groups \u2013 one group took 20mg of escitalopram daily for 12 weeks, the other took a placebo. The women underwent physical exams, blood tests, and completed questionnaires about their mental health and quality of life. \n\nRESULTS.\nThe average participant was 31 years old, had a BMI of 35.8 and a waist measurement of 102cm. Escitalopram was found to be related to an increase in waist size and cortisol (stress hormone) levels, compared to the placebo group. However, the drug didn't significantly affect insulin levels, lipid levels, mental health or the overall quality of life.\n\nCONCLUSION.\nIn women with PCOS but without clinical depression, escitalopram increased waist circumference and cortisol levels. However, it didn't noticeable alter metabolic risk factors, mental wellbeing or quality of life.", "question": "What were the specific metabolic risk markers that were measured in the study?", "answer": "The study measured insulin sensitivity, insulin secretion, fasting lipids, and cortisol levels as metabolic risk markers."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 1522, "end": 1544, "score": 1, "text": "metabolic risk markers", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 5863413, "edit_id": "238a64604c9935cd4db7e54bacc8cdc8", "source": "INTRODUCTION.\nLichen planus (LP) is a chronic inflammatory, autoimmune, mucocutaneous disease of unknown etiology. The first line of treatment for oral LP (OLP) has been corticosteroids, but because of their adverse effects, alternative therapeutic approaches are being carried out, of which the recent natural alternative is propolis.\n\nAIM.\nThis study aims to evaluate the efficacy of topical propolis in the management of OLP.\n\nMATERIALS AND METHODS.\nThe research group consisted of 27 patients diagnosed with symptomatic OLP, among which 15 patients were in the control group and the rest 12 were in the study group. The patients in the control group received triamcinolone acetonide 0.1% (topical application) while the patients in the study group received propolis gel. Both the groups were evaluated for pain and erythema at baseline (1st visit), first follow-up (7th day), and second follow-up (14th day) using numerical rating scale and modified oral mucositis index.\n\nRESULTS.\nThe patients in both the study and control groups showed a statistically significant reduction (P = 0.000 for the study group and P = 0.000 for the control group) in pain and erythema scores from baseline to second follow-up visit. However, on comparison of the reduction in pain and erythema scores between the two groups, the difference was found to be statistically insignificant (P = 0.255).\n\nSTATISTICAL ANALYSIS USED.\nChi-square and Cramer's V test were used.\n\nCONCLUSION.\nThe topical propolis was found to be of comparative effectiveness with respect to triamcinolone acetonide 0.1% in the management of OLP.", "target": "INTRODUCTION.\nLichen planus is a lasting skin disease that we don't know the cause of and is often treated with steroids. These steroids can have negative side effects, so researchers are trying to find other ways to treat it. Right now, they're looking into using propolis, which is a natural product created by bees.\n\nAIM.\nThe goal of this study is to see if propolis can be used effectively to treat lichen planus.\n\nMATERIALS AND METHODS.\nThe study involved 27 people who have been diagnosed with a type of lichen planus that affects the inside of the mouth. Fifteen of these people were given a common treatment (a 0.1% mix of a steroid), while the other twelve were given a gel made from propolis. Over two weeks, both groups were regularly checked for pain and redness.\n\nRESULTS.\nBoth groups - those treated with steroids and those treated with propolis - showed a significant decrease in pain and redness by the end of two weeks. The decrease in these symptoms between the two groups wasn't significant enough to be conclusive.\n\nSTATISTICAL ANALYSIS USED.\nChi-square and Cramer's V test were used to analyze the results.\n\nCONCLUSION.\nIn conclusion, propolis (the product made by bees) seemed to be as effective as steroids in treating this type of lichen planus.", "question": "What treatment did the control group receive?", "answer": "The control group received a topical application of triamcinolone acetonide 0.1%."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 620, "end": 713, "score": 1, "text": "The patients in the control group received triamcinolone acetonide 0.1% (topical application)", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 5866486, "edit_id": "b7c68eebd64788bf18e30c042bc3a164", "source": "INTRODUCTION.\nVestibular rehabilitation is a treatment option for the management of vertigo and unsteadiness, which are very common in head trauma patients and more challenging in the early months after trauma. This study evaluated the effectiveness of a vestibular rehabilitation program in the recovery of acute and sub-acute head trauma patients. The goal of this study was evaluation of the effect of early vestibular rehabilitation on patients with acute and sub-acute head trauma.\n\nMATERIALS AND METHODS.\nThis study was performed in 20 head trauma patients with vertigo and unsteadiness. The patients were randomly divided into two groups: one group received medical therapy (Betaserc) and the other received rehabilitation and medical therapy. An individualized vestibular rehabilitation program was designed that was then revised and verified by a joint committee of vestibular rehabilitation groups. The effectiveness of interventions was measured using the Dizziness Handicap Inventory (DHI) by comparing the results before and after therapy.\n\nRESULTS: .\nThe physical conditions and DHI scores of patients in both groups were similar at baseline. After 1 month of rehabilitation, patients receiving vestibular rehabilitation and medication showed greater progress than patients receiving medication only (P=0.000).\n\nCONCLUSION.\nVestibular rehabilitation can aid in the recovery from vertigo and increase the stability of head trauma patients. Simultaneous treatment with medicine and vestibular rehabilitation exercises can result in quicker and better therapeutic effects.", "target": "INTRODUCTION.\nThis study explores a type of treatment for balance problems and dizziness, which are common after head injuries and can be particularly tricky to manage in the first few months after the injury. The researchers looked at how well this treatment, called vestibular rehabilitation, helps in recovering from head injuries in the early stages.\n\nMATERIALS AND METHODS.\nThe participants were 20 people who had suffered head injuries and were experiencing dizziness and balance problems. They were split into two groups - one group was given medicine to help with the symptoms, while the other group was given the same medicine but also went through the vestibular rehabilitation treatment. This treatment was tailored to each individual person and was checked and approved by a team of specialists. To see how well the treatments worked, the researchers used a test called the Dizziness Handicap Inventory, which measures how much the dizziness and balance problems are affecting a person's life, both before the treatment and after.\n\nRESULTS: \nWhen the study started, both groups of patients had similar physical conditions and scores on the Dizziness Handicap Inventory. But after one month of treatment, the group that went through the vestibular rehabilitation and took the medicine showed more improvement than the group that just took the medicine.\n\nCONCLUSION. \nThe study found that vestibular rehabilitation can help people who've had head injuries recover from dizziness and balance problems. It works better and faster when used together with medication.", "question": "What type of head trauma patients did the study focus on?", "answer": "The study focused on patients with acute and sub-acute head trauma."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 211, "end": 349, "score": 1, "text": "This study evaluated the effectiveness of a vestibular rehabilitation program in the recovery of acute and sub-acute head trauma patients.", "labels": ["omission"]}}]}]}, {"data": {"doc_id": 5966460, "edit_id": "fa8e16247f144c176d151317b23f83f0", "source": "Topical microbicides are being explored as an HIV prevention method for individuals who practice receptive anal intercourse. In vivo studies of these microbicides are critical to confirm safety. Here, we evaluated the impact of a rectal microbicide containing the antiviral lectin, Griffithsin (GRFT), on the rectal mucosal proteome and microbiome. Using a randomized, crossover placebo-controlled design, six rhesus macaques received applications of hydroxyethylcellulose (HEC)- or carbopol-formulated 0.1% GRFT gels. Rectal mucosal samples were then evaluated by label-free tandem MS/MS and 16 S rRNA gene amplicon sequencing, for proteomics and microbiome analyses, respectively. Compared to placebo, GRFT gels were not associated with any significant changes to protein levels at any time point (FDR < 5%), but increased abundances of two common and beneficial microbial taxa after 24 hours were observed in HEC-GRFT gel (p < 2E-09). Compared to baseline, both placebo formulations were associated with alterations to proteins involved in proteolysis, activation of the immune response and inflammation after 2 hours (p < 0.0001), and increases in beneficial Faecalibacterium spp. after 24 hours in HEC placebo gel (p = 4.21E-15). This study supports the safety profile of 0.1% GRFT gel as an anti-HIV microbicide and demonstrates that current placebo formulations may associate with changes to rectal proteome and microbiota.", "target": "Researchers are testing a special gel, known as a microbicide, to prevent HIV during anal intercourse. It's vital to ensure this gel is safe before it can be used by people. The gel in question contains a substance called Griffithsin (GRFT), which helps fight against viruses. \n\nIn our study, we tested the gel on six macaque monkeys. We applied two different versions of the gel and compared these to a dummy gel (placebo). We studied samples from the monkeys to see what effects the gel had on proteins and microbes (tiny organisms that live in our bodies). \n\nWe found that the Griffithsin gel didn't significantly change protein levels at any point. However, it did increase the levels of two helpful types of microbes after 24 hours. On the other hand, the dummy gels caused changes in proteins linked to immunity and inflammation after 2 hours, and also increased beneficial microbes after 24 hours. \n\nIn plain terms, our study shows that the Griffithsin gel doesn't harm the rectum's proteins or microbes, implying it's safe to use. However, it's important to note that even the dummy gels can cause changes to the rectum's proteins and microbes. This means we must be careful when interpreting the results of such tests.", "question": "What specific microbial taxa were increased in the HEC-GRFT gel and how did the researchers determine that the increase was statistically significant?", "answer": "The study found that the HEC-GRFT gel increased the abundances of two common and beneficial microbial taxa, Faecalibacterium spp., after 24 hours. The researchers used a statistical method called the paired t-test to determine that the increase was statistically significant, with a p-value of <2E-09."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 815, "end": 937, "score": 1, "text": "increased abundances of two common and beneficial microbial taxa after 24 hours were observed in HEC-GRFT gel (p < 2E-09).", "labels": ["concept"]}}, {"id": "1", "from_name": "target_label", "to_name": "target", "type": "labels", "value": {"start": 662, "end": 737, "score": 1, "text": "it did increase the levels of two helpful types of microbes after 24 hours.", "labels": ["concept"]}}]}]}, {"data": {"doc_id": 5985618, "edit_id": "1b2251e46096ccdbeacb67612d8be05f", "source": "INTRODUCTION.\nHalitosis and foreign body sensation are two common and disturbing symptoms of chronic caseous tonsillitis (CCT). The aim of this study was to compare the efficacy and safety of temperature-controlled radiofrequency (TC-RF) tonsil ablation with CO2-laser cryptolysis (CO2-LC) in the treatment of patients with halitosis caused by CCT.\n\nMATERIALS AND METHODS.\nSixty-two patients who suffered from halitosis and/or foreign body sensation due to CCT were enrolled in the present randomized clinical trial, and were randomly assigned into two groups. Group A underwent TC-RF tonsil ablation and Group B received CO2-LC. The severity of symptoms including halitosis and foreign body sensation was reported 7 days, 1 month, and 6 months after the procedure. Patient pain levels and amount of bleeding were evaluated as safety outcome measures. Pain levels were evaluated during the intervention, and at Day 1, 3, and 7 following the procedure using a visual analog scale (VAS).\n\nRESULTS.\nMean rank of pain score in the RF tonsil ablation group was found to be higher than in the CO2-LC group at all measured timepoints following the procedure. The amount of bleeding in the LC group was found to be significantly less than in the RF group (P<0.05). No significant difference was found between the groups regarding duration of procedure (P=0.157).\n\nCONCLUSION.\nBoth procedures were found to be effective and safe in the treatment of CT-associated halitosis. However, LC showed better results based on lower pain levels, lower incidence of bleeding, and faster progression to a routine diet.", "target": "INTRODUCTION.\nBad breath and a sensation of a foreign body are common symptoms of a chronic issue called tonsillitis where there's a cheesy substance in the throat. This study aimed to compare two treatments: one using controlled temperature radio waves and the other using a type of laser, to treat bad breath caused by this condition.\n\nMATERIALS AND METHODS.\nWe had 62 people in the study who had bad breath and/or these feelings from their throat issue. They were split into two groups. One group received the treatment with radio waves and the other with the laser. We monitored how severe the symptoms were after a week, a month, and then six months after treatment. We also noted any pain suffered and any bleeding as measures of how safe it was. The pain was measured when the treatment was happening and on days 1, 3, and 7 after the treatment using a rating scale.\n\nRESULTS.\nWe found that the group treated with radio waves suffered more pain than the laser group at all times we checked after the procedure. The laser group had less bleeding than the radio wave group, a significant difference. However, the time for both procedures to complete wasn't significantly different.\n\nCONCLUSION.\nBoth treatments were found to be effective and safe for treating chronic tonsillitis-associated bad breath. However, the laser showed better results as it caused less pain, less bleeding, and allowed patients to return to their normal diet sooner.", "question": "How were pain levels evaluated?", "answer": "Pain levels were evaluated during the intervention and at Day 1, 3, and 7 following the procedure using a visual analog scale (VAS)."}, "predictions": [{"model_version": "info_loss_model", "score": 1, "result": [{"id": "0", "from_name": "source_label", "to_name": "source", "type": "labels", "value": {"start": 852, "end": 985, "score": 1, "text": "Pain levels were evaluated during the intervention, and at Day 1, 3, and 7 following the procedure using a visual analog scale (VAS).", "labels": ["omission"]}}]}]}]