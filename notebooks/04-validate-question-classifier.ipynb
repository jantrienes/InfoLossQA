{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7258553f-ddb7-4a76-91f2-a7246f0ca992",
   "metadata": {},
   "source": [
    "# Validate GPT-4 Question Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355a66d8-6930-432f-beda-ef5a62eb8ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import openai\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3605b48c-8c3a-494c-9b29-521898c4f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "from info_loss import gpt4_classify_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb1f91a7-afc9-4f4e-903f-377a10a93a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24004985-f9f6-45e0-ba9d-68b367dbb2f9",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04af7791-09b0-43cf-80a3-684d4dcc1d1a",
   "metadata": {},
   "source": [
    "Manually labeled validation set of 50 questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63d50578-d20d-4bfe-8f51-614a7f69efd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2774638-keziah-concept-4</td>\n",
       "      <td>What questionnaire was used for this study?</td>\n",
       "      <td>The 46-item calcium-focused food frequency que...</td>\n",
       "      <td>procedural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5442667-kathryn-omission-2</td>\n",
       "      <td>How reliable are the results about improvement...</td>\n",
       "      <td>There was a meaningful imbalance in the clinic...</td>\n",
       "      <td>extent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2699714-kathryn-concept-6</td>\n",
       "      <td>How does etanercept help children with newly d...</td>\n",
       "      <td>The study suggests that etanercept helps with ...</td>\n",
       "      <td>consequence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4069047-keziah-concept-1</td>\n",
       "      <td>What kind of melatonin is being analyzed in th...</td>\n",
       "      <td>This study looks at endogenous melatonin, mean...</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4555141-keziah-concept-5</td>\n",
       "      <td>What tests did girls generally score higher on...</td>\n",
       "      <td>The girls displayed higher scores on the Wechs...</td>\n",
       "      <td>comparison</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  question_id  \\\n",
       "0    2774638-keziah-concept-4   \n",
       "1  5442667-kathryn-omission-2   \n",
       "2   2699714-kathryn-concept-6   \n",
       "3    4069047-keziah-concept-1   \n",
       "4    4555141-keziah-concept-5   \n",
       "\n",
       "                                            question  \\\n",
       "0        What questionnaire was used for this study?   \n",
       "1  How reliable are the results about improvement...   \n",
       "2  How does etanercept help children with newly d...   \n",
       "3  What kind of melatonin is being analyzed in th...   \n",
       "4  What tests did girls generally score higher on...   \n",
       "\n",
       "                                              answer        label  \n",
       "0  The 46-item calcium-focused food frequency que...   procedural  \n",
       "1  There was a meaningful imbalance in the clinic...       extent  \n",
       "2  The study suggests that etanercept helps with ...  consequence  \n",
       "3  This study looks at endogenous melatonin, mean...      concept  \n",
       "4  The girls displayed higher scores on the Wechs...   comparison  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qs = pd.read_csv(\"../data/raw/info-loss-question-types-50.csv\")\n",
    "df_qs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec91aef0-d61d-4090-811b-54e9f2170a1d",
   "metadata": {},
   "source": [
    "## Run classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b34714-152c-494d-a951-6042c25e1f8f",
   "metadata": {},
   "source": [
    "Aggregate results over 5 runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c2b1f6f-3d5a-4fc3-85e6-84aa4b1fb9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e348934e1c62489a942f98b5ec949c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1555064655c249cf9f727689736c3d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4ef856d45fd44859721f385309553a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f7d736b23a40b5a7c81dc4c1360283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a99f78533d42668d1e6060b89ab5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred1 = gpt4_classify_questions.predict_batched(\n",
    "    df_qs[\"question\"],\n",
    "    batch_size=32,\n",
    "    cache_dir=\"../output/question-clf-validation/run1/\",\n",
    ")\n",
    "y_pred2 = gpt4_classify_questions.predict_batched(\n",
    "    df_qs[\"question\"],\n",
    "    batch_size=32,\n",
    "    cache_dir=\"../output/question-clf-validation/run2/\",\n",
    ")\n",
    "y_pred3 = gpt4_classify_questions.predict_batched(\n",
    "    df_qs[\"question\"],\n",
    "    batch_size=32,\n",
    "    cache_dir=\"../output/question-clf-validation/run3/\",\n",
    ")\n",
    "y_pred4 = gpt4_classify_questions.predict_batched(\n",
    "    df_qs[\"question\"],\n",
    "    batch_size=32,\n",
    "    cache_dir=\"../output/question-clf-validation/run4/\",\n",
    ")\n",
    "y_pred5 = gpt4_classify_questions.predict_batched(\n",
    "    df_qs[\"question\"],\n",
    "    batch_size=32,\n",
    "    cache_dir=\"../output/question-clf-validation/run5/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a0c1195-28b3-40c6-8b30-1b37561b83e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 runs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision  recall     f1\n",
       "0      0.845   0.871  0.846\n",
       "1      0.885   0.871  0.871\n",
       "2      0.898   0.891  0.887\n",
       "3      0.898   0.891  0.887\n",
       "4      0.885   0.871  0.871"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average over 5 runs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "precision    0.88\n",
       "recall       0.88\n",
       "f1           0.87\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_true = df_qs[\"label\"]\n",
    "df_scores = pd.DataFrame(\n",
    "    [\n",
    "        precision_recall_fscore_support(y_true, y_pred1, average=\"macro\"),\n",
    "        precision_recall_fscore_support(y_true, y_pred2, average=\"macro\"),\n",
    "        precision_recall_fscore_support(y_true, y_pred3, average=\"macro\"),\n",
    "        precision_recall_fscore_support(y_true, y_pred4, average=\"macro\"),\n",
    "        precision_recall_fscore_support(y_true, y_pred5, average=\"macro\"),\n",
    "    ],\n",
    "    columns=[\"precision\", \"recall\", \"f1\", \"support\"],\n",
    ")\n",
    "df_scores = df_scores.drop(\"support\", axis=1)\n",
    "\n",
    "print(\"5 runs:\")\n",
    "display(df_scores.round(3))\n",
    "\n",
    "print(\"Average over 5 runs:\")\n",
    "display(df_scores.mean().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2ab911f-ce62-4195-a3e4-3e92d0715246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       cause       1.00      1.00      1.00         2\n",
      "  comparison       1.00      0.75      0.86         4\n",
      "     concept       0.70      1.00      0.82         7\n",
      " consequence       0.71      0.71      0.71         7\n",
      "     example       1.00      1.00      1.00         1\n",
      "      extent       0.90      0.75      0.82        12\n",
      "  procedural       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.89      0.87      0.87        50\n",
      "weighted avg       0.85      0.84      0.84        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
