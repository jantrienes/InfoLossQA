{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd9b990-71d3-4c0a-809b-0d9fdaa20854",
   "metadata": {},
   "source": [
    "# Inter-Annotator Agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da0e6ef-a3a0-47be-a7d4-f2da2ebcb7d7",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2647cfc-12ea-496e-8910-c122823dfa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from info_loss import iaa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e4fbf4-a568-4c54-9cc8-31b7b0835150",
   "metadata": {},
   "source": [
    "## Calculate Agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4034eeb5-84b5-4639-a534-84f313f841dc",
   "metadata": {},
   "source": [
    "### Accuracy-oriented eval (Angle 1, Angle 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ad44b5d-661c-419e-a529-357c1a8c01fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance_source</th>\n",
       "      <th>relevance_target</th>\n",
       "      <th>accuracy_snippet</th>\n",
       "      <th>accuracy_answer</th>\n",
       "      <th>hallucinations_answer</th>\n",
       "      <th>givenness_phrasing</th>\n",
       "      <th>givenness_location</th>\n",
       "      <th>simplicity_jargon</th>\n",
       "      <th>simplicity_standalone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relevance_source_1</td>\n",
       "      <td>relevance_target_1</td>\n",
       "      <td>accuracy_snippet_1</td>\n",
       "      <td>accuracy_answer_1</td>\n",
       "      <td>hallucinations_answer_1</td>\n",
       "      <td>givenness_phrasing_2</td>\n",
       "      <td>givenness_location_1</td>\n",
       "      <td>simplicity_jargon_4</td>\n",
       "      <td>simplicity_standalone_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relevance_source_1</td>\n",
       "      <td>relevance_target_3</td>\n",
       "      <td>accuracy_snippet_1</td>\n",
       "      <td>accuracy_answer_1</td>\n",
       "      <td>hallucinations_answer_1</td>\n",
       "      <td>givenness_phrasing_1</td>\n",
       "      <td>givenness_location_3</td>\n",
       "      <td>simplicity_jargon_4</td>\n",
       "      <td>simplicity_standalone_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     relevance_source    relevance_target    accuracy_snippet  \\\n",
       "0  relevance_source_1  relevance_target_1  accuracy_snippet_1   \n",
       "1  relevance_source_1  relevance_target_3  accuracy_snippet_1   \n",
       "\n",
       "     accuracy_answer    hallucinations_answer    givenness_phrasing  \\\n",
       "0  accuracy_answer_1  hallucinations_answer_1  givenness_phrasing_2   \n",
       "1  accuracy_answer_1  hallucinations_answer_1  givenness_phrasing_1   \n",
       "\n",
       "     givenness_location    simplicity_jargon    simplicity_standalone  \n",
       "0  givenness_location_1  simplicity_jargon_4  simplicity_standalone_1  \n",
       "1  givenness_location_3  simplicity_jargon_4  simplicity_standalone_1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance_source</th>\n",
       "      <th>relevance_target</th>\n",
       "      <th>accuracy_snippet</th>\n",
       "      <th>accuracy_answer</th>\n",
       "      <th>hallucinations_answer</th>\n",
       "      <th>givenness_phrasing</th>\n",
       "      <th>givenness_location</th>\n",
       "      <th>simplicity_jargon</th>\n",
       "      <th>simplicity_standalone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relevance_source_1</td>\n",
       "      <td>relevance_target_1</td>\n",
       "      <td>accuracy_snippet_1</td>\n",
       "      <td>accuracy_answer_1</td>\n",
       "      <td>hallucinations_answer_1</td>\n",
       "      <td>givenness_phrasing_2</td>\n",
       "      <td>givenness_location_1</td>\n",
       "      <td>simplicity_jargon_3</td>\n",
       "      <td>simplicity_standalone_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relevance_source_3</td>\n",
       "      <td>relevance_target_3</td>\n",
       "      <td>accuracy_snippet_1</td>\n",
       "      <td>accuracy_answer_2</td>\n",
       "      <td>hallucinations_answer_1</td>\n",
       "      <td>givenness_phrasing_2</td>\n",
       "      <td>givenness_location_3</td>\n",
       "      <td>simplicity_jargon_4</td>\n",
       "      <td>simplicity_standalone_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     relevance_source    relevance_target    accuracy_snippet  \\\n",
       "0  relevance_source_1  relevance_target_1  accuracy_snippet_1   \n",
       "1  relevance_source_3  relevance_target_3  accuracy_snippet_1   \n",
       "\n",
       "     accuracy_answer    hallucinations_answer    givenness_phrasing  \\\n",
       "0  accuracy_answer_1  hallucinations_answer_1  givenness_phrasing_2   \n",
       "1  accuracy_answer_2  hallucinations_answer_1  givenness_phrasing_2   \n",
       "\n",
       "     givenness_location    simplicity_jargon    simplicity_standalone  \n",
       "0  givenness_location_1  simplicity_jargon_3  simplicity_standalone_1  \n",
       "1  givenness_location_3  simplicity_jargon_4  simplicity_standalone_2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance_source</th>\n",
       "      <th>relevance_target</th>\n",
       "      <th>accuracy_snippet</th>\n",
       "      <th>accuracy_answer</th>\n",
       "      <th>hallucinations_answer</th>\n",
       "      <th>givenness_phrasing</th>\n",
       "      <th>givenness_location</th>\n",
       "      <th>simplicity_jargon</th>\n",
       "      <th>simplicity_standalone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relevance_source_3</td>\n",
       "      <td>relevance_target_2</td>\n",
       "      <td>accuracy_snippet_1</td>\n",
       "      <td>accuracy_answer_1</td>\n",
       "      <td>hallucinations_answer_1</td>\n",
       "      <td>givenness_phrasing_2</td>\n",
       "      <td>givenness_location_1</td>\n",
       "      <td>simplicity_jargon_4</td>\n",
       "      <td>simplicity_standalone_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relevance_source_3</td>\n",
       "      <td>relevance_target_3</td>\n",
       "      <td>accuracy_snippet_3</td>\n",
       "      <td>accuracy_answer_3</td>\n",
       "      <td>hallucinations_answer_1</td>\n",
       "      <td>givenness_phrasing_2</td>\n",
       "      <td>givenness_location_na</td>\n",
       "      <td>simplicity_jargon_4</td>\n",
       "      <td>simplicity_standalone_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     relevance_source    relevance_target    accuracy_snippet  \\\n",
       "0  relevance_source_3  relevance_target_2  accuracy_snippet_1   \n",
       "1  relevance_source_3  relevance_target_3  accuracy_snippet_3   \n",
       "\n",
       "     accuracy_answer    hallucinations_answer    givenness_phrasing  \\\n",
       "0  accuracy_answer_1  hallucinations_answer_1  givenness_phrasing_2   \n",
       "1  accuracy_answer_3  hallucinations_answer_1  givenness_phrasing_2   \n",
       "\n",
       "      givenness_location    simplicity_jargon    simplicity_standalone  \n",
       "0   givenness_location_1  simplicity_jargon_4  simplicity_standalone_1  \n",
       "1  givenness_location_na  simplicity_jargon_4  simplicity_standalone_2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance_source</th>\n",
       "      <th>relevance_target</th>\n",
       "      <th>accuracy_snippet</th>\n",
       "      <th>accuracy_answer</th>\n",
       "      <th>hallucinations_answer</th>\n",
       "      <th>givenness_phrasing</th>\n",
       "      <th>givenness_location</th>\n",
       "      <th>simplicity_jargon</th>\n",
       "      <th>simplicity_standalone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relevance_source_1</td>\n",
       "      <td>relevance_target_2</td>\n",
       "      <td>accuracy_snippet_2</td>\n",
       "      <td>accuracy_answer_1</td>\n",
       "      <td>hallucinations_answer_1</td>\n",
       "      <td>givenness_phrasing_2</td>\n",
       "      <td>givenness_location_1</td>\n",
       "      <td>simplicity_jargon_3</td>\n",
       "      <td>simplicity_standalone_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relevance_source_3</td>\n",
       "      <td>relevance_target_3</td>\n",
       "      <td>accuracy_snippet_3</td>\n",
       "      <td>accuracy_answer_2</td>\n",
       "      <td>hallucinations_answer_1</td>\n",
       "      <td>givenness_phrasing_2</td>\n",
       "      <td>givenness_location_na</td>\n",
       "      <td>simplicity_jargon_4</td>\n",
       "      <td>simplicity_standalone_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     relevance_source    relevance_target    accuracy_snippet  \\\n",
       "0  relevance_source_1  relevance_target_2  accuracy_snippet_2   \n",
       "1  relevance_source_3  relevance_target_3  accuracy_snippet_3   \n",
       "\n",
       "     accuracy_answer    hallucinations_answer    givenness_phrasing  \\\n",
       "0  accuracy_answer_1  hallucinations_answer_1  givenness_phrasing_2   \n",
       "1  accuracy_answer_2  hallucinations_answer_1  givenness_phrasing_2   \n",
       "\n",
       "      givenness_location    simplicity_jargon    simplicity_standalone  \n",
       "0   givenness_location_1  simplicity_jargon_3  simplicity_standalone_1  \n",
       "1  givenness_location_na  simplicity_jargon_4  simplicity_standalone_2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "criteria = [\n",
    "    \"relevance_source\",\n",
    "    \"relevance_target\",\n",
    "    \"accuracy_snippet\",\n",
    "    \"accuracy_answer\",\n",
    "    \"hallucinations_answer\",\n",
    "    \"givenness_phrasing\",\n",
    "    \"givenness_location\",\n",
    "    \"simplicity_jargon\",\n",
    "    \"simplicity_standalone\",\n",
    "]\n",
    "\n",
    "rater_a = pd.read_json(\"../data/infolossqa-v1.0/evals-accuracy/rater-a.json\")[criteria]\n",
    "rater_b = pd.read_json(\"../data/infolossqa-v1.0/evals-accuracy/rater-b.json\")[criteria]\n",
    "\n",
    "path = Path(\"../output/gpt-eval/gpt-4o-2024-05-13/\")\n",
    "rater_gpt4 = pd.concat([pd.read_json(path / f\"{c}.json\")[c] for c in criteria], axis=1)\n",
    "\n",
    "path = Path(\"../output/gpt-eval/llama-3-70b-chat-hf/\")\n",
    "rater_llama3 = pd.concat(\n",
    "    [pd.read_json(path / f\"{c}.json\")[c] for c in criteria], axis=1\n",
    ")\n",
    "\n",
    "display(rater_a.head(2))\n",
    "display(rater_b.head(2))\n",
    "display(rater_gpt4.head(2))\n",
    "display(rater_llama3.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e5eb6cf-c39c-4e58-8a25-09686936e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iaa_humans(rater_a, rater_b, criteria):\n",
    "    agreement = {}\n",
    "    for c in criteria:\n",
    "        agreement[c] = iaa.kappa(raters=[rater_a[c], rater_b[c]], method=\"randolph\")\n",
    "    return agreement\n",
    "\n",
    "\n",
    "def iaa_model_vs_human_raters(rater_a, rater_b, model, criteria):\n",
    "    agreement = {}\n",
    "    for c in criteria:\n",
    "        model_vs_a = iaa.kappa(raters=[rater_a[c], model[c]], method=\"randolph\")\n",
    "        model_vs_b = iaa.kappa(raters=[rater_b[c], model[c]], method=\"randolph\")\n",
    "        agreement[c] = (model_vs_a + model_vs_b) / 2\n",
    "    return agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fea7d83-5868-43f1-9840-f1ebe3ac213b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Human</th>\n",
       "      <th>GPT-4o</th>\n",
       "      <th>Llama3-70B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>relevance_source</th>\n",
       "      <td>0.605651</td>\n",
       "      <td>0.683047</td>\n",
       "      <td>0.659091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relevance_target</th>\n",
       "      <td>0.498771</td>\n",
       "      <td>0.325553</td>\n",
       "      <td>0.242629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_snippet</th>\n",
       "      <td>0.712531</td>\n",
       "      <td>0.649877</td>\n",
       "      <td>0.524570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_answer</th>\n",
       "      <td>0.679361</td>\n",
       "      <td>0.627764</td>\n",
       "      <td>0.574324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hallucinations_answer</th>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.813268</td>\n",
       "      <td>0.724816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>givenness_phrasing</th>\n",
       "      <td>0.793612</td>\n",
       "      <td>0.302211</td>\n",
       "      <td>0.238329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>givenness_location</th>\n",
       "      <td>0.803440</td>\n",
       "      <td>0.182637</td>\n",
       "      <td>0.064701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simplicity_jargon</th>\n",
       "      <td>0.574120</td>\n",
       "      <td>0.341523</td>\n",
       "      <td>0.426699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simplicity_standalone</th>\n",
       "      <td>0.690418</td>\n",
       "      <td>0.206388</td>\n",
       "      <td>-0.304668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Human    GPT-4o  Llama3-70B\n",
       "relevance_source       0.605651  0.683047    0.659091\n",
       "relevance_target       0.498771  0.325553    0.242629\n",
       "accuracy_snippet       0.712531  0.649877    0.524570\n",
       "accuracy_answer        0.679361  0.627764    0.574324\n",
       "hallucinations_answer  0.891892  0.813268    0.724816\n",
       "givenness_phrasing     0.793612  0.302211    0.238329\n",
       "givenness_location     0.803440  0.182637    0.064701\n",
       "simplicity_jargon      0.574120  0.341523    0.426699\n",
       "simplicity_standalone  0.690418  0.206388   -0.304668"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iaa_accuracy = pd.DataFrame(\n",
    "    [\n",
    "        iaa_humans(rater_a, rater_b, criteria),\n",
    "        iaa_model_vs_human_raters(rater_a, rater_b, rater_gpt4, criteria),\n",
    "        iaa_model_vs_human_raters(rater_a, rater_b, rater_llama3, criteria),\n",
    "    ],\n",
    "    index=[\"Human\", \"GPT-4o\", \"Llama3-70B\"],\n",
    ").T\n",
    "df_iaa_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7eaed5-7da5-4663-a9b5-e84e2a5bd43b",
   "metadata": {},
   "source": [
    "### Recall-oriented eval (Angle 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75221c12-567b-457f-a550-3f9336dd4989",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_rater_a = pd.read_json(\"../data/infolossqa-v1.0/evals-recall/rater-a.json\")\n",
    "recall_rater_a = recall_rater_a.rename({\"rating\": \"recall\"}, axis=1)\n",
    "recall_rater_b = pd.read_json(\"../data/infolossqa-v1.0/evals-recall/rater-b.json\")\n",
    "recall_rater_b = recall_rater_b.rename({\"rating\": \"recall\"}, axis=1)\n",
    "\n",
    "recall_rater_gpt4 = pd.read_json(\"../output/gpt-eval/gpt-4o-2024-05-13/recall.json\")\n",
    "recall_rater_llama3 = pd.read_json(\"../output/gpt-eval/llama-3-70b-chat-hf/recall.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85c7bca4-1d28-4856-bf5a-0ef8f781c187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Human</th>\n",
       "      <th>GPT-4o</th>\n",
       "      <th>Llama3-70B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.700231</td>\n",
       "      <td>0.666795</td>\n",
       "      <td>0.469639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Human    GPT-4o  Llama3-70B\n",
       "recall  0.700231  0.666795    0.469639"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iaa_recall = pd.DataFrame(\n",
    "    [\n",
    "        iaa_humans(recall_rater_a, recall_rater_b, [\"recall\"]),\n",
    "        iaa_model_vs_human_raters(\n",
    "            recall_rater_a, recall_rater_b, recall_rater_gpt4, [\"recall\"]\n",
    "        ),\n",
    "        iaa_model_vs_human_raters(\n",
    "            recall_rater_a, recall_rater_b, recall_rater_llama3, [\"recall\"]\n",
    "        ),\n",
    "    ],\n",
    "    index=[\"Human\", \"GPT-4o\", \"Llama3-70B\"],\n",
    ").T\n",
    "df_iaa_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9902a5c0-ea1b-4d3b-8bd3-13c8db7aa6b2",
   "metadata": {},
   "source": [
    "### Merge results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec1b05f6-96a5-4f41-96c6-5a8a69bfa56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Human</th>\n",
       "      <th>GPT-4o</th>\n",
       "      <th>Llama3-70B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q is Answerable w/ X_src</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q is Answerable w/ X_tgt</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy - Evidence (E)</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy - Answer (A)</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hallucinations (A)</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Givenness (Q)</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rationale Localization (R)</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jargon (A)</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standalone (A)</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall of human QA</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Human  GPT-4o  Llama3-70B\n",
       "Q is Answerable w/ X_src     0.61    0.68        0.66\n",
       "Q is Answerable w/ X_tgt     0.50    0.33        0.24\n",
       "Accuracy - Evidence (E)      0.71    0.65        0.52\n",
       "Accuracy - Answer (A)        0.68    0.63        0.57\n",
       "Hallucinations (A)           0.89    0.81        0.72\n",
       "Givenness (Q)                0.79    0.30        0.24\n",
       "Rationale Localization (R)   0.80    0.18        0.06\n",
       "Jargon (A)                   0.57    0.34        0.43\n",
       "Standalone (A)               0.69    0.21       -0.30\n",
       "Recall of human QA           0.70    0.67        0.47\n",
       "Average                      0.70    0.48        0.36"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criteria_rename = {\n",
    "    \"relevance_source\": \"Q is Answerable w/ X_src\",\n",
    "    \"relevance_target\": \"Q is Answerable w/ X_tgt\",\n",
    "    \"accuracy_snippet\": \"Accuracy - Evidence (E)\",\n",
    "    \"accuracy_answer\": \"Accuracy - Answer (A)\",\n",
    "    \"hallucinations_answer\": \"Hallucinations (A)\",\n",
    "    \"givenness_phrasing\": \"Givenness (Q)\",\n",
    "    \"givenness_location\": \"Rationale Localization (R)\",\n",
    "    \"simplicity_jargon\": \"Jargon (A)\",\n",
    "    \"simplicity_standalone\": \"Standalone (A)\",\n",
    "    \"recall\": \"Recall of human QA\",\n",
    "}\n",
    "\n",
    "df_iaa = pd.concat([df_iaa_accuracy, df_iaa_recall])\n",
    "df_iaa.loc[\"Average\"] = df_iaa.mean()\n",
    "df_iaa = df_iaa.round(2)\n",
    "df_iaa = df_iaa.rename(criteria_rename)\n",
    "df_iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "842727c7-c420-426a-9adf-fa6b73e17bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[t]\n",
      "\\centering\n",
      "\\caption{TODO}\n",
      "\\label{tab:iaa-evaluation}\n",
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "\\textbf{index} & \\textbf{Human} & \\textbf{GPT-4o} & \\textbf{Llama3-70B} \\\\\n",
      "\\midrule\n",
      "Q is Answerable w/ X_src & 0.61 & 0.68 & 0.66 \\\\\n",
      "Q is Answerable w/ X_tgt & 0.50 & 0.33 & 0.24 \\\\\n",
      "Accuracy - Evidence (E) & 0.71 & 0.65 & 0.52 \\\\\n",
      "Accuracy - Answer (A) & 0.68 & 0.63 & 0.57 \\\\\n",
      "Hallucinations (A) & 0.89 & 0.81 & 0.72 \\\\\n",
      "Givenness (Q) & 0.79 & 0.30 & 0.24 \\\\\n",
      "Rationale Localization (R) & 0.80 & 0.18 & 0.06 \\\\\n",
      "Jargon (A) & 0.57 & 0.34 & 0.43 \\\\\n",
      "Standalone (A) & 0.69 & 0.21 & -0.30 \\\\\n",
      "Recall of human QA & 0.70 & 0.67 & 0.47 \\\\\n",
      "Average & 0.70 & 0.48 & 0.36 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df_iaa.reset_index()\n",
    "tex = (\n",
    "    df.style.format(precision=2)\n",
    "    .hide(axis=0)\n",
    "    .to_latex(\n",
    "        position=\"t\",\n",
    "        position_float=\"centering\",\n",
    "        hrules=True,\n",
    "        caption=\"TODO\",\n",
    "        label=\"tab:iaa-evaluation\",\n",
    "    )\n",
    ")\n",
    "for c in df.columns:\n",
    "    tex = tex.replace(c, \"\\\\textbf{\" + c + \"}\")\n",
    "print(tex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6b9555-f375-4eb3-aa07-03c81b230d56",
   "metadata": {},
   "source": [
    "## Evaluation Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3de24598-396c-4d32-8447-8f1924b5c2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-2024-05-13\n",
      "accuracy_answer        :  1.57$\n",
      "relevance_source       :  1.50$\n",
      "relevance_target       :  2.34$\n",
      "accuracy_snippet       :  1.59$\n",
      "givenness_location     :  2.50$\n",
      "recall                 :  5.45$\n",
      "hallucinations_answer  :  1.54$\n",
      "simplicity_jargon      :  1.46$\n",
      "simplicity_standalone  :  1.34$\n",
      "givenness_phrasing     :  1.42$\n",
      "===============================\n",
      "total                  : 20.71$\n",
      "\n",
      "llama-3-70b-chat-hf\n",
      "accuracy_answer        :  0.25$\n",
      "relevance_source       :  0.24$\n",
      "relevance_target       :  0.39$\n",
      "accuracy_snippet       :  0.26$\n",
      "givenness_location     :  0.43$\n",
      "recall                 :  0.88$\n",
      "hallucinations_answer  :  0.25$\n",
      "simplicity_jargon      :  0.24$\n",
      "simplicity_standalone  :  0.21$\n",
      "givenness_phrasing     :  0.23$\n",
      "===============================\n",
      "total                  :  3.36$\n"
     ]
    }
   ],
   "source": [
    "from litellm import completion_cost\n",
    "\n",
    "\n",
    "def report_costs(result_path, custom_cost_per_token):\n",
    "    # API responses are in separate directory for criteria\n",
    "    # Get the list of criteria\n",
    "    criteria = [x.name for x in result_path.iterdir() if x.is_dir()]\n",
    "    costs = defaultdict(float)\n",
    "\n",
    "    # Open each response and calculate costs via `usage`\n",
    "    for criterion in criteria:\n",
    "        responses = (path / criterion).glob(\"*.json\")\n",
    "        for r in responses:\n",
    "            with open(r) as fin:\n",
    "                response = json.load(fin)\n",
    "                costs[criterion] += completion_cost(\n",
    "                    response, custom_cost_per_token=custom_cost_per_token\n",
    "                )\n",
    "\n",
    "    total = sum(costs.values())\n",
    "\n",
    "    for c in criteria:\n",
    "        print(f\"{c:<23}: {costs[c]:5.2f}$\")\n",
    "    print(\"=\" * 31)\n",
    "    print(f\"{'total':<23}: {total:5.2f}$\")\n",
    "\n",
    "\n",
    "# GPT-4o as of May 29, 2024\n",
    "costs = {\"input_cost_per_token\": 5 / 1_000_000, \"output_cost_per_token\": 15 / 1_000_000}\n",
    "path = Path(\"../output/gpt-eval/gpt-4o-2024-05-13/\")\n",
    "print(\"gpt-4o-2024-05-13\")\n",
    "report_costs(path, costs)\n",
    "print()\n",
    "\n",
    "# LLama3-70B on Together.ai as of May 29, 2024\n",
    "costs = {\n",
    "    \"input_cost_per_token\": 0.9 / 1_000_000,\n",
    "    \"output_cost_per_token\": 0.9 / 1_000_000,\n",
    "}\n",
    "path = Path(\"../output/gpt-eval/llama-3-70b-chat-hf/\")\n",
    "print(\"llama-3-70b-chat-hf\")\n",
    "report_costs(path, costs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ts-info-loss]",
   "language": "python",
   "name": "conda-env-ts-info-loss-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
